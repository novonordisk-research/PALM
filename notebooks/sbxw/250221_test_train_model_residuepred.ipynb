{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "76c7d51c-67ee-4062-a2f3-12c9322b25c5",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Train sequence level ESM model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4e914966-f529-4a31-abde-bd0cd98b45e5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/nfs_home/users/sbxw/mambaforge/condabin/conda run --no-capture-output -n mlbp python /novo/projects/departments/cdd/molecular_ai/sbxw/repos/ML-BP-Domino/src/cli/training.py mlflow=lovelace persistence=lovelace dataset.use_predefined_split=true dataset.data_name=sbxw_fibrillation_peptide_waltzdb-train-val_serrano-test dataset.task=classification_binary embedder=esm2_t6_8M embedder.mean_pool=false dimred=noreduction predictor=lightattention predictor.hparams.kernel_size=3 predictor.hparams.max_epochs=10 predictor.hparams.patience=200 predictor.hparams.batch_size=1000 predictor.hparams.learning_rate=0.0005 mlflow.experiment_name=ML-BP-Domino plots.generate_plots=false\n",
      "[2025-02-21 19:14:24,122][__main__][INFO] - Workflow configuration:\n",
      "\n",
      "general:\n",
      "  run_mode: train\n",
      "  abs_repo_path: null\n",
      "  composite_model_name: null\n",
      "  composite_model_path: null\n",
      "  precomputed_embeddings_path: null\n",
      "  random_state: 42\n",
      "dataset:\n",
      "  data_name: sbxw_fibrillation_peptide_waltzdb-train-val_serrano-test\n",
      "  add_data_columns: false\n",
      "  data_columns_dimred: false\n",
      "  data_columns_standard: false\n",
      "  data_scaler: RobustScaler\n",
      "  rbf_encoder: RadialBasisFunctionGaussian\n",
      "  rbf_n_kernels: 10\n",
      "  task: classification_binary\n",
      "  use_predefined_split: true\n",
      "  use_sample_weights: false\n",
      "  residue_prediction_labels: null\n",
      "  data_split:\n",
      "    train: 0.8\n",
      "    val: 0.0\n",
      "    test: 0.2\n",
      "embedder:\n",
      "  class_name: ESM\n",
      "  model_name: esm2_t6_8M_UR50D\n",
      "  model_path: null\n",
      "  standardize: false\n",
      "  scalar_type: StandardScaler\n",
      "  hparams: null\n",
      "  n_copies: 1\n",
      "  chain_break: poly-gly-linker\n",
      "  buffer_scale_factor: 2.0\n",
      "  max_batch_size: 400\n",
      "  simple_batching: false\n",
      "  strict: true\n",
      "  verbose: false\n",
      "  mean_pool: false\n",
      "dimred:\n",
      "  class_name: NoReduction\n",
      "  transform_name: null\n",
      "  fraction_variance_explained: null\n",
      "predictor:\n",
      "  class_name: LightAttention\n",
      "  model_name: null\n",
      "  model_type: classification_binary\n",
      "  mem_per_job: null\n",
      "  residue_prediction_mode: false\n",
      "  hparams:\n",
      "    kernel_size: 3\n",
      "    dropout: 0.25\n",
      "    conv_dropout: 0.25\n",
      "    learning_rate: 0.0005\n",
      "    batch_size: 1000\n",
      "    max_epochs: 10\n",
      "    patience: 200\n",
      "    post_attention: mlp\n",
      "    conv1d_output_dim: -1\n",
      "    optimal_cutoff: 0.5\n",
      "persistence:\n",
      "  type: lovelace\n",
      "  data_root_folder: /novo/projects/departments/cdd/molecular_ai/mlbp/data\n",
      "  artifacts_root_folder: /novo/projects/departments/cdd/molecular_ai/mlbp/artifacts\n",
      "  training_data: static_input_data\n",
      "  pretrained_weights: static_pretrained_weights\n",
      "mlflow:\n",
      "  tracking_uri: DOMINO_TRACKING_URI\n",
      "  experiment_name: ML-BP-Domino\n",
      "plots:\n",
      "  generate_plots: false\n",
      "\n",
      "2025-02-21 19:14:45.924978: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2025-02-21 19:14:45.928460: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2025-02-21 19:14:46.271902: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2025-02-21 19:14:46.910840: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2025-02-21 19:15:00.408147: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "[2025-02-21 19:15:26,170][src.model.composite_model][INFO] - ANuPP: <class 'src.model.embedders.ANuPP'>\n",
      "[2025-02-21 19:15:26,170][src.model.composite_model][INFO] - Amorprot: <class 'src.model.embedders.Amorprot'>\n",
      "[2025-02-21 19:15:26,170][src.model.composite_model][INFO] - Ankh: <class 'src.model.embedders.Ankh'>\n",
      "[2025-02-21 19:15:26,170][src.model.composite_model][INFO] - Biophys: <class 'src.model.embedders.Biophys'>\n",
      "[2025-02-21 19:15:26,170][src.model.composite_model][INFO] - ESM: <class 'src.model.embedders.ESM'>\n",
      "[2025-02-21 19:15:26,170][src.model.composite_model][INFO] - Kmer: <class 'src.model.embedders.Kmer'>\n",
      "[2025-02-21 19:15:26,170][src.model.composite_model][INFO] - OneHot: <class 'src.model.embedders.OneHot'>\n",
      "[2025-02-21 19:15:26,170][src.model.composite_model][INFO] - PrecomputedDescriptors: <class 'src.model.embedders.PrecomputedDescriptors'>\n",
      "[2025-02-21 19:15:26,170][src.model.composite_model][INFO] - ProtT5: <class 'src.model.embedders.ProtT5'>\n",
      "[2025-02-21 19:15:26,173][src.model.composite_model][INFO] - NoReduction: <class 'src.model.dimred.NoReduction'>\n",
      "[2025-02-21 19:15:26,173][src.model.composite_model][INFO] - PCADimReduction: <class 'src.model.dimred.PCADimReduction'>\n",
      "[2025-02-21 19:15:26,920][src.model.composite_model][INFO] - KNearestNeighbors: <class 'src.model.predictors.KNearestNeighbors'>\n",
      "[2025-02-21 19:15:26,920][src.model.composite_model][INFO] - LSTM: <class 'src.model.predictors.LSTM'>\n",
      "[2025-02-21 19:15:26,920][src.model.composite_model][INFO] - LightAttention: <class 'src.model.predictors.LightAttention'>\n",
      "[2025-02-21 19:15:26,920][src.model.composite_model][INFO] - LogisticRegression: <class 'src.model.predictors.LogisticRegression'>\n",
      "[2025-02-21 19:15:26,920][src.model.composite_model][INFO] - MLP: <class 'src.model.predictors.MLP'>\n",
      "[2025-02-21 19:15:26,920][src.model.composite_model][INFO] - RandomForest: <class 'src.model.predictors.RandomForest'>\n",
      "[2025-02-21 19:15:26,920][src.model.composite_model][INFO] - RidgeRegression: <class 'src.model.predictors.RidgeRegression'>\n",
      "[2025-02-21 19:15:26,920][src.model.composite_model][INFO] - XGBoost: <class 'src.model.predictors.XGBoost'>\n",
      "[2025-02-21 19:15:26,921][src.model.dimred][INFO] - Load class (NoReduction): NoReduction\n",
      "[2025-02-21 19:15:26,921][src.model.abstract_components][INFO] - Load class (DimRed Model): NoReduction\n",
      "[2025-02-21 19:15:26,921][src.model.predictors][INFO] - Load class (LightAttention): LightAttention\n",
      "[2025-02-21 19:15:26,921][src.model.abstract_components][INFO] - Load class (TorchPredictorModel): LightAttention\n",
      "[2025-02-21 19:15:26,921][src.model.abstract_components][INFO] - Load class (Predictor Model): LightAttention\n",
      "[2025-02-21 19:15:26,922][src.model.composite_model][INFO] - Composite model name: esm2t68MUR50D_LightAttention_sbxwfibrillationpeptidewaltzdb-train-valserrano-test\n",
      "[2025-02-21 19:15:26,922][src.model.composite_model][INFO] - Initialized model: esm2t68MUR50D_LightAttention_sbxwfibrillationpeptidewaltzdb-train-valserrano-test in run_mode = train\n",
      "[2025-02-21 19:15:26,942][src.helpers.dataset][INFO] - Loading file: /novo/projects/departments/cdd/molecular_ai/mlbp/data/static_input_data/sbxw_fibrillation_peptide_waltzdb-train-val_serrano-test.csv\n",
      "[2025-02-21 19:15:26,943][src.helpers.dataset][INFO] - No additional data columns found while parsing.\n",
      "[2025-02-21 19:15:26,949][src.helpers.dataset][INFO] - Select data according to predetermined splits in the dataframe, train (N = 1122), validation (N = 277), test (N = 248)\n",
      "[2025-02-21 19:15:26,949][src.helpers.dataset][INFO] - Loaded columns: {}\n",
      "[2025-02-21 19:15:26,950][src.helpers.mlflow_helpers][INFO] - Setting up MLflow...\n",
      "[2025-02-21 19:15:26,950][src.helpers.mlflow_helpers][INFO] - Experiment name: ML-BP-Domino\n",
      "[2025-02-21 19:15:27,002][src.helpers.mlflow_helpers][INFO] - Setting MLflow experiment to ML-BP-Domino\n",
      "[2025-02-21 19:15:28,467][__main__][INFO] - Compute embeddings on-the-fly and train model\n",
      "[2025-02-21 19:15:28,468][src.model.abstract_components][INFO] - Load class (LLMEmbedderModel): ESM\n",
      "[2025-02-21 19:15:28,468][src.model.abstract_components][INFO] - Load class (Embedder Model): ESM\n",
      "[2025-02-21 19:15:28,469][src.model.embedders][INFO] - Using existing cache directory: /novo/projects/departments/cdd/molecular_ai/mlbp/data/static_pretrained_weights\n",
      "Using cache found in /novo/projects/departments/cdd/molecular_ai/mlbp/data/static_pretrained_weights/facebookresearch_esm_main\n",
      "[2025-02-21 19:15:29,140][src.model.embedders][INFO] - moving model to cuda\n",
      "[2025-02-21 19:15:30,623][src.model.abstract_components][INFO] - Total memory: 23.58378496GB\n",
      "Memory already allocated: 0.030069248GB\n",
      "[2025-02-21 19:15:31,959][src.model.embedders][INFO] - Final results len: 1122\n",
      "[2025-02-21 19:15:31,959][src.model.composite_model][INFO] - Residue embeddings\n",
      "[2025-02-21 19:15:31,959][src.model.abstract_components][INFO] - Total memory: 23.58378496GB\n",
      "Memory already allocated: 0.038758912GB\n",
      "[2025-02-21 19:15:31,998][src.model.embedders][INFO] - Final results len: 277\n",
      "/nfs_home/users/sbxw/mambaforge/envs/mlbp/lib/python3.10/site-packages/lightning/fabric/plugins/environments/slurm.py:204: The `srun` command is available on your system but is not used. HINT: If your intention is to run Lightning on SLURM, prepend your python command with `srun` like so: srun python /novo/projects/departments/cdd/molecular_ai/sbxw/rep ...\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/nfs_home/users/sbxw/mambaforge/envs/mlbp/lib/python3.10/site-packages/lightning/fabric/plugins/environments/slurm.py:204: The `srun` command is available on your system but is not used. HINT: If your intention is to run Lightning on SLURM, prepend your python command with `srun` like so: srun python /novo/projects/departments/cdd/molecular_ai/sbxw/rep ...\n",
      "[2025-02-21 19:15:35,615][pytorch_lightning.utilities.rank_zero][INFO] - You are using a CUDA device ('NVIDIA L4') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name                  | Type       | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | feature_convolution   | Conv1d     | 307 K  | train\n",
      "1 | attention_convolution | Conv1d     | 307 K  | train\n",
      "2 | softmax               | Softmax    | 0      | train\n",
      "3 | dropout               | Dropout    | 0      | train\n",
      "4 | sigmoid               | Sigmoid    | 0      | train\n",
      "5 | mlp                   | Sequential | 20.6 K | train\n",
      "6 | loss_fxn              | BCELoss    | 0      | train\n",
      "-------------------------------------------------------------\n",
      "635 K     Trainable params\n",
      "0         Non-trainable params\n",
      "635 K     Total params\n",
      "2.543     Total estimated model params size (MB)\n",
      "12        Modules in train mode\n",
      "0         Modules in eval mode\n",
      "/nfs_home/users/sbxw/mambaforge/envs/mlbp/lib/python3.10/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:424: The 'val_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=7` in the `DataLoader` to improve performance.\n",
      "/nfs_home/users/sbxw/mambaforge/envs/mlbp/lib/python3.10/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:424: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=7` in the `DataLoader` to improve performance.\n",
      "[2025-02-21 19:15:40,777][pytorch_lightning.utilities.rank_zero][INFO] - `Trainer.fit` stopped: `max_epochs=10` reached.\n",
      "\u001b[31m2025/02/21 19:16:37 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\u001b[0m\n",
      "[2025-02-21 19:16:37,590][src.model.abstract_components][INFO] - MODEL STOPPED BY EARLY STOPPER AT EPOCH 0\n",
      "[2025-02-21 19:16:37,590][src.model.abstract_components][INFO] - BEST MODEL VALIDATION LOSS IS 0.6759252548217773\n",
      "[2025-02-21 19:16:37,590][src.model.abstract_components][INFO] - BEST MODEL SAVED AT ./mlruns/672490144989501938/e17f3508da014378a0f8ddd4d145d36a/checkpoints/epoch=0-step=2.ckpt\n",
      "[2025-02-21 19:16:37,590][src.model.abstract_components][INFO] - FINAL MODEL SAVED AT ./mlruns\n",
      "[2025-02-21 19:16:38,298][src.model.predictors][INFO] - Moving embeddings to device: cuda\n",
      "[2025-02-21 19:16:38,438][src.model.predictors][INFO] - Optimal cutoff is: 0.31 with MCC: 0.15160031381035552\n",
      "[2025-02-21 19:16:38,454][src.model.predictors][INFO] - Moving embeddings to device: cuda\n",
      "[2025-02-21 19:16:38,463][src.model.predictors][INFO] - Moving embeddings to device: cuda\n",
      "[2025-02-21 19:16:38,465][src.model.composite_model][INFO] - This is the updated predictor name: lightattention_kernel_size_3_dropout_0.25_conv_dropout_0.25_learning_rate_0.0005_batch_size_1000_max_epochs_10_patience_200_post_attention_mlp_conv1d_output_dim_-1_optimal_cutoff_0.31\n",
      "[2025-02-21 19:16:38,465][src.model.composite_model][INFO] - Composite model name: esm2t68MUR50D_LightAttention_sbxwfibrillationpeptidewaltzdb-train-valserrano-test\n",
      "[2025-02-21 19:16:38,465][src.model.composite_model][INFO] - Best model is: kernel_size_3_dropout_0.25_conv_dropout_0.25_learning_rate_0.0005_batch_size_1000_max_epochs_10_patience_200_post_attention_mlp_conv1d_output_dim_-1_optimal_cutoff_0.31\n",
      "[2025-02-21 19:16:38,465][src.model.composite_model][INFO] - Moving to test mode\n",
      "[2025-02-21 19:16:38,466][src.model.composite_model][INFO] - Composite model name: esm2t68MUR50D_LightAttention_sbxwfibrillationpeptidewaltzdb-train-valserrano-test\n",
      "[2025-02-21 19:16:38,466][src.model.composite_model][INFO] - Saving model: esm2t68MUR50D_LightAttention_sbxwfibrillationpeptidewaltzdb-train-valserrano-test\n",
      "<RunInfo: artifact_uri='file:///novo/projects/departments/cdd/public/users/ehec/sbxw_files_2/mlruns/672490144989501938/e17f3508da014378a0f8ddd4d145d36a/artifacts', end_time=None, experiment_id='672490144989501938', lifecycle_stage='active', run_id='e17f3508da014378a0f8ddd4d145d36a', run_name='blushing-doe-588', run_uuid='e17f3508da014378a0f8ddd4d145d36a', start_time=1740165327860, status='RUNNING', user_id='sbxw'>\n",
      "[2025-02-21 19:16:38,540][src.model.abstract_components][INFO] - Total memory: 23.58378496GB\n",
      "Memory already allocated: 0.04823808GB\n",
      "[2025-02-21 19:16:38,627][src.model.embedders][INFO] - Final results len: 248\n",
      "[2025-02-21 19:16:38,627][src.model.composite_model][INFO] - Residue embeddings\n",
      "[2025-02-21 19:16:38,630][src.model.predictors][INFO] - Moving embeddings to device: cuda\n",
      "sequences: (1122,)\n",
      "sequence_embeddings: 1122\n",
      "predictions: (1122,)\n",
      "data_split: train\n",
      "labels: (1122,)\n",
      "predictions_probability: (1122,)\n",
      "residue_level_prediction: False\n",
      "sequences: (277,)\n",
      "sequence_embeddings: 277\n",
      "predictions: (277,)\n",
      "data_split: val\n",
      "labels: (277,)\n",
      "predictions_probability: (277,)\n",
      "residue_level_prediction: False\n",
      "sequences: (248,)\n",
      "sequence_embeddings: 248\n",
      "predictions: (248,)\n",
      "data_split: test\n",
      "labels: (248,)\n",
      "predictions_probability: (248,)\n",
      "residue_level_prediction: False\n",
      "[2025-02-21 19:16:39,191][src.model.composite_model][INFO] - Composite model name: esm2t68MUR50D_LightAttention_sbxwfibrillationpeptidewaltzdb-train-valserrano-test\n",
      "[2025-02-21 19:16:39,191][src.model.composite_model][INFO] - Composite model name: esm2t68MUR50D_LightAttention_sbxwfibrillationpeptidewaltzdb-train-valserrano-test\n",
      "[2025-02-21 19:16:39,253][src.model.composite_model][INFO] - Composite model name: esm2t68MUR50D_LightAttention_sbxwfibrillationpeptidewaltzdb-train-valserrano-test\n",
      "[2025-02-21 19:16:39,263][__main__][INFO] - Done!\n",
      "run_id: e17f3508da014378a0f8ddd4d145d36a\n",
      "artifacts: ['model/MLmodel', 'model/checkpoints', 'model/conda.yaml', 'model/data', 'model/python_env.yaml', 'model/requirements.txt']\n",
      "params: {'conv_dropout': '0.25', 'weight_decay': '0', 'predictor.hparams.conv_dropout': '0.25', 'general.random_state': '42', 'predictor.mem_per_job': 'None', 'dataset.data_name': 'sbxw_fibrillation_peptide_waltzdb-train-val_serrano-test', 'general.abs_repo_path': 'None', 'lr': '0.0005', 'embeddings_dim': '320', 'persistence.training_data': 'static_input_data', 'predictor.hparams.batch_size': '1000', 'kernel_size': '3', 'dataset.data_split.train': '0.8', 'general.composite_model_path': 'None', 'dataset.data_split.val': '0.0', 'dataset.use_predefined_split': 'True', 'predictor.hparams.post_attention': 'mlp', 'embedder.model_path': 'None', 'optimizer_name': 'SGD', 'predictor.hparams.learning_rate': '0.0005', 'predictor.hparams.conv1d_output_dim': '-1', 'predictor.model_type': 'classification_binary', 'persistence.pretrained_weights': 'static_pretrained_weights', 'dimred.class_name': 'NoReduction', 'embedder.chain_break': 'poly-gly-linker', 'predictor.class_name': 'LightAttention', 'embedder.mean_pool': 'False', 'dataset.data_scaler': 'RobustScaler', 'embedder.hparams': 'None', 'dataset.rbf_encoder': 'RadialBasisFunctionGaussian', 'predictor.hparams.patience': '200', 'embedder.class_name': 'ESM', 'mlflow.tracking_uri': 'DOMINO_TRACKING_URI', 'predictor.hparams.optimal_cutoff': '0.5', 'embedder.n_copies': '1', 'embedder.buffer_scale_factor': '2.0', 'dropout': '0.25', 'embedder.standardize': 'False', 'embedder.scalar_type': 'StandardScaler', 'learning_rate': '0.0005', 'dimred.transform_name': 'None', 'dataset.rbf_n_kernels': '10', 'epochs': '10', 'differentiable': 'False', 'post_attention': 'mlp', 'dataset.add_data_columns': 'False', 'embedder.model_name': 'esm2_t6_8M_UR50D', 'nesterov': 'False', 'general.composite_model_name': 'esm2t68MUR50D_LightAttention_sbxwfibrillationpeptidewaltzdb-train-valserrano-test', 'embedder.simple_batching': 'False', 'persistence.data_root_folder': '/novo/projects/departments/cdd/molecular_ai/mlbp/data', 'conv1d_output_dim': '-1', 'plots.generate_plots': 'False', 'dataset.data_split.test': '0.2', 'mlflow.experiment_name': 'ML-BP-Domino', 'maximize': 'False', 'predictor.hparams.max_epochs': '10', 'predictor.model_name': 'None', 'predictor.hparams.dropout': '0.25', 'dataset.task': 'classification_binary', 'fused': 'None', 'dataset.data_columns_standard': 'False', 'output_dim': '1', 'embedder.max_batch_size': '400', 'general.precomputed_embeddings_path': 'None', 'momentum': '0', 'persistence.type': 'lovelace', 'dataset.data_columns_dimred': 'False', 'embedder.verbose': 'False', 'dampening': '0', 'dataset.residue_prediction_labels': 'None', 'dimred.fraction_variance_explained': 'None', 'predictor.residue_prediction_mode': 'False', 'general.run_mode': 'train', 'predictor.hparams.kernel_size': '3', 'residue_prediction_mode': 'False', 'model_type': 'classification_binary', 'persistence.artifacts_root_folder': '/novo/projects/departments/cdd/molecular_ai/mlbp/artifacts', 'embedder.strict': 'True', 'foreach': 'None', 'dataset.use_sample_weights': 'False'}\n",
      "metrics: {'val.optimal_mcc': 0.25, 'test.optimal_mcc_cutoff': 0.1, 'test.matthews_corr_coef': -0.06946266596278866, 'epoch': 9.0, 'test.specificity': 0.0755813953488372, 'val.precision': 0.3712121212121212, 'test.optimal_mcc': 0.1, 'val_loss': 0.6805924773216248, 'train.f_score': 0.5210884353741496, 'test.recall': 0.881578947368421, 'test.f_score': 0.44370860927152317, 'val.loss': 0.6805924773216248, 'val.specificity': 0.062146892655367235, 'val.matthews_corr_coef': 0.0957146806582119, 'train.matthews_corr_coef': -0.021577230228192558, 'train.roc_auc_score': 0.46395079122351857, 'val.accuracy': 0.3935018050541516, 'train.optimal_mcc': 0.04, 'train.balanced_accuracy': 0.494991494991495, 'val.roc_auc_score': 0.4794350282485876, 'train.loss_step': 0.6818166971206665, 'val.balanced_accuracy': 0.5210734463276836, 'train.accuracy': 0.37254901960784315, 'val.f_score': 0.5384615384615384, 'train.optimal_mcc_cutoff': 0.04, 'val.optimal_mcc_cutoff': 0.25, 'test.balanced_accuracy': 0.4785801713586291, 'test.precision': 0.29646017699115046, 'train.specificity': 0.04895104895104895, 'train.recall': 0.941031941031941, 'test.roc_auc_score': 0.4438494492044064, 'test.accuracy': 0.3225806451612903, 'train.loss': 0.7007962465286255, 'val.recall': 0.98, 'train.loss_epoch': 0.7007962465286255, 'train.precision': 0.3603010348071496}\n",
      "tags: {'Mode': 'training'}\n",
      "results stored in /novo/projects/departments/cdd/molecular_ai/mlbp/artifacts/2025-02-21-1914_blushing-doe-588/esm2t68MUR50D_LightAttention_sbxwfibrillationpeptidewaltzdb-train-valserrano-test_final_stats.csv\n",
      "file:///novo/projects/departments/cdd/public/users/ehec/sbxw_files_2/mlruns/672490144989501938/e17f3508da014378a0f8ddd4d145d36a/artifacts\n",
      "\u001b[34mSystem information\u001b[0m: Linux #70~20.04.1-Ubuntu SMP Fri Jun 14 15:42:13 UTC 2024\n",
      "\u001b[34mPython version\u001b[0m: 3.10.14\n",
      "\u001b[34mMLflow version\u001b[0m: 2.20.2\n",
      "\u001b[34mMLflow module location\u001b[0m: /nfs_home/users/sbxw/mambaforge/envs/mlbp/lib/python3.10/site-packages/mlflow/__init__.py\n",
      "\u001b[34mTracking URI\u001b[0m: file:///novo/projects/departments/cdd/public/users/ehec/sbxw_files_2/mlruns\n",
      "\u001b[34mRegistry URI\u001b[0m: file:///novo/projects/departments/cdd/public/users/ehec/sbxw_files_2/mlruns\n",
      "\u001b[34mActive experiment ID\u001b[0m: 672490144989501938\n",
      "\u001b[34mActive run ID\u001b[0m: e17f3508da014378a0f8ddd4d145d36a\n",
      "\u001b[34mActive run artifact URI\u001b[0m: file:///novo/projects/departments/cdd/public/users/ehec/sbxw_files_2/mlruns/672490144989501938/e17f3508da014378a0f8ddd4d145d36a/artifacts\n",
      "\u001b[34mMLflow environment variables\u001b[0m: \n",
      "  MLFLOW_EXPERIMENT_ID: 672490144989501938\n",
      "  MLFLOW_TRACKING_URI: file:///novo/projects/departments/cdd/public/users/ehec/sbxw_files_2/mlruns\n",
      "\u001b[34mMLflow dependencies\u001b[0m: \n",
      "  Flask: 2.2.5\n",
      "  Jinja2: 3.1.4\n",
      "  aiohttp: 3.9.5\n",
      "  alembic: 1.13.1\n",
      "  boto3: 1.36.23\n",
      "  botocore: 1.36.23\n",
      "  docker: 7.0.0\n",
      "  graphene: 3.3\n",
      "  gunicorn: 22.0.0\n",
      "  markdown: 3.6\n",
      "  matplotlib: 3.9.0\n",
      "  mlflow-skinny: 2.20.2\n",
      "  numpy: 1.26.4\n",
      "  pandas: 2.2.2\n",
      "  pyarrow: 15.0.2\n",
      "  scikit-learn: 1.4.2\n",
      "  scipy: 1.13.0\n",
      "  sqlalchemy: 2.0.30\n",
      "  virtualenv: 20.26.2\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "repo_dir = '/novo/projects/departments/cdd/molecular_ai/sbxw/repos/ML-BP-Domino'\n",
    "conda_env_name = 'mlbp'\n",
    "\n",
    "# Create command (single set of params)\n",
    "cmd = [\n",
    "    f\"/nfs_home/users/sbxw/mambaforge/condabin/conda run --no-capture-output -n {conda_env_name} python\",\n",
    "    f\"{repo_dir}/src/cli/training.py\",\n",
    "    \"mlflow=lovelace\", \"persistence=lovelace\",\n",
    "    \"dataset.use_predefined_split=true\",\n",
    "    \"dataset.data_name=sbxw_fibrillation_peptide_waltzdb-train-val_serrano-test\", \"dataset.task=classification_binary\", \n",
    "    \"embedder=esm2_t6_8M\",\"embedder.mean_pool=false\",\n",
    "    \"dimred=noreduction\",\n",
    "    \"predictor=lightattention\",\n",
    "    \"predictor.hparams.kernel_size=3\", \"predictor.hparams.max_epochs=10\", \"predictor.hparams.patience=200\",\n",
    "    \"predictor.hparams.batch_size=1000\", \"predictor.hparams.learning_rate=0.0005\",\n",
    "    \"mlflow.experiment_name=ML-BP-Domino\",\n",
    "    \"plots.generate_plots=false\",\n",
    "]\n",
    "\n",
    "command_str = \" \".join(cmd)\n",
    "print(command_str)\n",
    "!PYTHONPATH=repo_dir; $command_str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "20ad5ef6-c6d0-466d-965c-33b29273552d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: AWS_ACCESS_KEY_ID=ASIATIJCHR3KA5YYSX4C\n",
      "env: AWS_SECRET_ACCESS_KEY=aPDRW7A6aUdgjnE2CdQeYG2IpZseMrimkIxc0H//\n",
      "env: AWS_SESSION_TOKEN=FwoGZXIvYXdzEMX//////////wEaDONh6B2GwAQwnkGFRSL0AwI0ymgCmmLalzZXga+CfvhC0RiboEHABvkZiIl6GOVwtQtrORvwMGFLYd5RwDFo+fKXDl5P3zXzI0hnN2nHWf9e+jNJ1wZVVr7JEmw1XZwZn7zyOMG0skT8+BYhtkkZPYUhZB+DPOrrszHfomSSbBuox+/5P/7M492NM2zMnLRPomrOHsCMpc5rTlpv2Qp/zMgP0wKud0NJLjgq46dZkJ7rr7STpYwqc3x+gQ0peDIDGWqtdgeX75v74lpSCBgLU1YwmhUFBBenqDWxFPnYZ+81Q8DAuwtGFABQAUHScu04lM352nNNDTM21nGW50KMXqubIFyBvNcwP7hK61HcxvDZtdXkOc0o/Rg/oVkfa3INcmwV3P8g8qsjmrWhWyfCi3zeXJmH4QJl4rksNLCPMNugzkljoFOxhXFW4dzcfjk/pIZ2RohVcbwsiVHpwR9SXVM+0YzFE2MYSSUomqt5ahlxuUyK2IAJRvggiGOlSBN0T3ADN45y0U+JIFpl92MoIGkaW6Tr0RNT8eIOEGPzBB4g9FILg+CfYT1tMPaVJmlKGkRY+/vJkaE3h4DelnO49JhB1wRJgdtwZlBuFgqRRAPatgbZwhG79EwkmwTTXd5i5AxMeqQymz8jVurFoMBfALEuASskEoLoZIIc65PA+n0xz422KLCh470GMpQBMYrXpVze1m5G2VeOYzklnn6hsbiLu63zI7T4XX5GLExc4eoffUYBO4hlZAvEKYKJoR1Rx+iNlFz2RoQNQAHbfydjTrp7srnbSTGcwtJP3pyxxuqwXIHpWw0wHWx0mAuxWrujzsSyReGInQd+bDpRYsHUTZBd7aHDPrUK7ctcczNzIiVwgFD8g1hroB4ZCAucGRTjjw==\n",
      "/nfs_home/users/sbxw/mambaforge/condabin/conda run --no-capture-output -n mlbp python /novo/projects/departments/cdd/molecular_ai/sbxw/repos/ML-BP-Domino/src/cli/training.py mlflow=datalab persistence=lovelace dataset.use_predefined_split=true dataset.data_name=sbxw_fibrillation_peptide_waltzdb-train-val_serrano-test dataset.task=classification_binary embedder=esm2_t6_8M embedder.mean_pool=false dimred=noreduction predictor=lightattention predictor.hparams.kernel_size=3 predictor.hparams.max_epochs=10 predictor.hparams.patience=200 predictor.hparams.batch_size=1000 predictor.hparams.learning_rate=0.0005 mlflow.experiment_name=ML-BP-Domino plots.generate_plots=false\n",
      "[2025-02-21 19:18:49,632][__main__][INFO] - Workflow configuration:\n",
      "\n",
      "general:\n",
      "  run_mode: train\n",
      "  abs_repo_path: null\n",
      "  composite_model_name: null\n",
      "  composite_model_path: null\n",
      "  precomputed_embeddings_path: null\n",
      "  random_state: 42\n",
      "dataset:\n",
      "  data_name: sbxw_fibrillation_peptide_waltzdb-train-val_serrano-test\n",
      "  add_data_columns: false\n",
      "  data_columns_dimred: false\n",
      "  data_columns_standard: false\n",
      "  data_scaler: RobustScaler\n",
      "  rbf_encoder: RadialBasisFunctionGaussian\n",
      "  rbf_n_kernels: 10\n",
      "  task: classification_binary\n",
      "  use_predefined_split: true\n",
      "  use_sample_weights: false\n",
      "  residue_prediction_labels: null\n",
      "  data_split:\n",
      "    train: 0.8\n",
      "    val: 0.0\n",
      "    test: 0.2\n",
      "embedder:\n",
      "  class_name: ESM\n",
      "  model_name: esm2_t6_8M_UR50D\n",
      "  model_path: null\n",
      "  standardize: false\n",
      "  scalar_type: StandardScaler\n",
      "  hparams: null\n",
      "  n_copies: 1\n",
      "  chain_break: poly-gly-linker\n",
      "  buffer_scale_factor: 2.0\n",
      "  max_batch_size: 400\n",
      "  simple_batching: false\n",
      "  strict: true\n",
      "  verbose: false\n",
      "  mean_pool: false\n",
      "dimred:\n",
      "  class_name: NoReduction\n",
      "  transform_name: null\n",
      "  fraction_variance_explained: null\n",
      "predictor:\n",
      "  class_name: LightAttention\n",
      "  model_name: null\n",
      "  model_type: classification_binary\n",
      "  mem_per_job: null\n",
      "  residue_prediction_mode: false\n",
      "  hparams:\n",
      "    kernel_size: 3\n",
      "    dropout: 0.25\n",
      "    conv_dropout: 0.25\n",
      "    learning_rate: 0.0005\n",
      "    batch_size: 1000\n",
      "    max_epochs: 10\n",
      "    patience: 200\n",
      "    post_attention: mlp\n",
      "    conv1d_output_dim: -1\n",
      "    optimal_cutoff: 0.5\n",
      "persistence:\n",
      "  type: lovelace\n",
      "  data_root_folder: /novo/projects/departments/cdd/molecular_ai/mlbp/data\n",
      "  artifacts_root_folder: /novo/projects/departments/cdd/molecular_ai/mlbp/artifacts\n",
      "  training_data: static_input_data\n",
      "  pretrained_weights: static_pretrained_weights\n",
      "mlflow:\n",
      "  tracking_uri: https://datalab.corp.novocorp.net/mlflow/\n",
      "  experiment_name: ML-BP-Domino\n",
      "plots:\n",
      "  generate_plots: false\n",
      "\n",
      "2025-02-21 19:18:50.392089: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2025-02-21 19:18:50.392136: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2025-02-21 19:18:50.393647: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2025-02-21 19:18:50.401099: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2025-02-21 19:18:53.954705: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "[2025-02-21 19:18:58,978][src.model.composite_model][INFO] - ANuPP: <class 'src.model.embedders.ANuPP'>\n",
      "[2025-02-21 19:18:58,978][src.model.composite_model][INFO] - Amorprot: <class 'src.model.embedders.Amorprot'>\n",
      "[2025-02-21 19:18:58,978][src.model.composite_model][INFO] - Ankh: <class 'src.model.embedders.Ankh'>\n",
      "[2025-02-21 19:18:58,978][src.model.composite_model][INFO] - Biophys: <class 'src.model.embedders.Biophys'>\n",
      "[2025-02-21 19:18:58,978][src.model.composite_model][INFO] - ESM: <class 'src.model.embedders.ESM'>\n",
      "[2025-02-21 19:18:58,978][src.model.composite_model][INFO] - Kmer: <class 'src.model.embedders.Kmer'>\n",
      "[2025-02-21 19:18:58,978][src.model.composite_model][INFO] - OneHot: <class 'src.model.embedders.OneHot'>\n",
      "[2025-02-21 19:18:58,978][src.model.composite_model][INFO] - PrecomputedDescriptors: <class 'src.model.embedders.PrecomputedDescriptors'>\n",
      "[2025-02-21 19:18:58,978][src.model.composite_model][INFO] - ProtT5: <class 'src.model.embedders.ProtT5'>\n",
      "[2025-02-21 19:18:58,980][src.model.composite_model][INFO] - NoReduction: <class 'src.model.dimred.NoReduction'>\n",
      "[2025-02-21 19:18:58,980][src.model.composite_model][INFO] - PCADimReduction: <class 'src.model.dimred.PCADimReduction'>\n",
      "[2025-02-21 19:18:59,054][src.model.composite_model][INFO] - KNearestNeighbors: <class 'src.model.predictors.KNearestNeighbors'>\n",
      "[2025-02-21 19:18:59,054][src.model.composite_model][INFO] - LSTM: <class 'src.model.predictors.LSTM'>\n",
      "[2025-02-21 19:18:59,054][src.model.composite_model][INFO] - LightAttention: <class 'src.model.predictors.LightAttention'>\n",
      "[2025-02-21 19:18:59,054][src.model.composite_model][INFO] - LogisticRegression: <class 'src.model.predictors.LogisticRegression'>\n",
      "[2025-02-21 19:18:59,054][src.model.composite_model][INFO] - MLP: <class 'src.model.predictors.MLP'>\n",
      "[2025-02-21 19:18:59,054][src.model.composite_model][INFO] - RandomForest: <class 'src.model.predictors.RandomForest'>\n",
      "[2025-02-21 19:18:59,055][src.model.composite_model][INFO] - RidgeRegression: <class 'src.model.predictors.RidgeRegression'>\n",
      "[2025-02-21 19:18:59,055][src.model.composite_model][INFO] - XGBoost: <class 'src.model.predictors.XGBoost'>\n",
      "[2025-02-21 19:18:59,055][src.model.dimred][INFO] - Load class (NoReduction): NoReduction\n",
      "[2025-02-21 19:18:59,055][src.model.abstract_components][INFO] - Load class (DimRed Model): NoReduction\n",
      "[2025-02-21 19:18:59,055][src.model.predictors][INFO] - Load class (LightAttention): LightAttention\n",
      "[2025-02-21 19:18:59,055][src.model.abstract_components][INFO] - Load class (TorchPredictorModel): LightAttention\n",
      "[2025-02-21 19:18:59,055][src.model.abstract_components][INFO] - Load class (Predictor Model): LightAttention\n",
      "[2025-02-21 19:18:59,056][src.model.composite_model][INFO] - Composite model name: esm2t68MUR50D_LightAttention_sbxwfibrillationpeptidewaltzdb-train-valserrano-test\n",
      "[2025-02-21 19:18:59,056][src.model.composite_model][INFO] - Initialized model: esm2t68MUR50D_LightAttention_sbxwfibrillationpeptidewaltzdb-train-valserrano-test in run_mode = train\n",
      "[2025-02-21 19:18:59,061][src.helpers.dataset][INFO] - Loading file: /novo/projects/departments/cdd/molecular_ai/mlbp/data/static_input_data/sbxw_fibrillation_peptide_waltzdb-train-val_serrano-test.csv\n",
      "[2025-02-21 19:18:59,062][src.helpers.dataset][INFO] - No additional data columns found while parsing.\n",
      "[2025-02-21 19:18:59,063][src.helpers.dataset][INFO] - Select data according to predetermined splits in the dataframe, train (N = 1122), validation (N = 277), test (N = 248)\n",
      "[2025-02-21 19:18:59,063][src.helpers.dataset][INFO] - Loaded columns: {}\n",
      "[2025-02-21 19:18:59,064][src.helpers.mlflow_helpers][INFO] - Setting up MLflow...\n",
      "[2025-02-21 19:18:59,064][src.helpers.mlflow_helpers][INFO] - Experiment name: ML-BP-Domino\n",
      "[2025-02-21 19:18:59,064][src.helpers.mlflow_helpers][INFO] - Setting MLflow tracking URI to https://datalab.corp.novocorp.net/mlflow/\n",
      "[2025-02-21 19:19:00,505][src.helpers.mlflow_helpers][INFO] - Setting MLflow experiment to ML-BP-Domino\n",
      "[2025-02-21 19:19:01,689][__main__][INFO] - Compute embeddings on-the-fly and train model\n",
      "[2025-02-21 19:19:01,690][src.model.abstract_components][INFO] - Load class (LLMEmbedderModel): ESM\n",
      "[2025-02-21 19:19:01,690][src.model.abstract_components][INFO] - Load class (Embedder Model): ESM\n",
      "[2025-02-21 19:19:01,690][src.model.embedders][INFO] - Using existing cache directory: /novo/projects/departments/cdd/molecular_ai/mlbp/data/static_pretrained_weights\n",
      "Using cache found in /novo/projects/departments/cdd/molecular_ai/mlbp/data/static_pretrained_weights/facebookresearch_esm_main\n",
      "[2025-02-21 19:19:02,065][src.model.embedders][INFO] - moving model to cuda\n",
      "[2025-02-21 19:19:02,322][src.model.abstract_components][INFO] - Total memory: 23.58378496GB\n",
      "Memory already allocated: 0.030069248GB\n",
      "[2025-02-21 19:19:02,922][src.model.embedders][INFO] - Final results len: 1122\n",
      "[2025-02-21 19:19:02,922][src.model.composite_model][INFO] - Residue embeddings\n",
      "[2025-02-21 19:19:02,922][src.model.abstract_components][INFO] - Total memory: 23.58378496GB\n",
      "Memory already allocated: 0.038758912GB\n",
      "[2025-02-21 19:19:02,961][src.model.embedders][INFO] - Final results len: 277\n",
      "/nfs_home/users/sbxw/mambaforge/envs/mlbp/lib/python3.10/site-packages/lightning/fabric/plugins/environments/slurm.py:204: The `srun` command is available on your system but is not used. HINT: If your intention is to run Lightning on SLURM, prepend your python command with `srun` like so: srun python /novo/projects/departments/cdd/molecular_ai/sbxw/rep ...\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/nfs_home/users/sbxw/mambaforge/envs/mlbp/lib/python3.10/site-packages/lightning/fabric/plugins/environments/slurm.py:204: The `srun` command is available on your system but is not used. HINT: If your intention is to run Lightning on SLURM, prepend your python command with `srun` like so: srun python /novo/projects/departments/cdd/molecular_ai/sbxw/rep ...\n",
      "[2025-02-21 19:19:04,272][pytorch_lightning.utilities.rank_zero][INFO] - You are using a CUDA device ('NVIDIA L4') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name                  | Type       | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | feature_convolution   | Conv1d     | 307 K  | train\n",
      "1 | attention_convolution | Conv1d     | 307 K  | train\n",
      "2 | softmax               | Softmax    | 0      | train\n",
      "3 | dropout               | Dropout    | 0      | train\n",
      "4 | sigmoid               | Sigmoid    | 0      | train\n",
      "5 | mlp                   | Sequential | 20.6 K | train\n",
      "6 | loss_fxn              | BCELoss    | 0      | train\n",
      "-------------------------------------------------------------\n",
      "635 K     Trainable params\n",
      "0         Non-trainable params\n",
      "635 K     Total params\n",
      "2.543     Total estimated model params size (MB)\n",
      "12        Modules in train mode\n",
      "0         Modules in eval mode\n",
      "/nfs_home/users/sbxw/mambaforge/envs/mlbp/lib/python3.10/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:424: The 'val_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=7` in the `DataLoader` to improve performance.\n",
      "/nfs_home/users/sbxw/mambaforge/envs/mlbp/lib/python3.10/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:424: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=7` in the `DataLoader` to improve performance.\n",
      "[2025-02-21 19:19:08,366][botocore.credentials][INFO] - Found credentials in environment variables.\n",
      "[2025-02-21 19:19:35,348][pytorch_lightning.utilities.rank_zero][INFO] - `Trainer.fit` stopped: `max_epochs=10` reached.\n",
      "üèÉ View run  at: https://datalab.corp.novocorp.net/mlflow/#/experiments/378/runs/f0f329cd25c8427cad6fef0455fed399\n",
      "üß™ View experiment at: https://datalab.corp.novocorp.net/mlflow/#/experiments/378\n",
      "\u001b[31m2025/02/21 19:20:03 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\u001b[0m\n",
      "[2025-02-21 19:20:08,025][src.model.abstract_components][INFO] - MODEL STOPPED BY EARLY STOPPER AT EPOCH 0\n",
      "[2025-02-21 19:20:08,025][src.model.abstract_components][INFO] - BEST MODEL VALIDATION LOSS IS 0.6970973014831543\n",
      "[2025-02-21 19:20:08,025][src.model.abstract_components][INFO] - BEST MODEL SAVED AT /novo/projects/departments/cdd/public/users/ehec/sbxw_files_2/378/f0f329cd25c8427cad6fef0455fed399/checkpoints/epoch=0-step=2.ckpt\n",
      "[2025-02-21 19:20:08,025][src.model.abstract_components][INFO] - FINAL MODEL SAVED AT None\n",
      "[2025-02-21 19:20:08,718][src.model.predictors][INFO] - Moving embeddings to device: cuda\n",
      "[2025-02-21 19:20:08,822][src.model.predictors][INFO] - Optimal cutoff is: 0.27 with MCC: 0.027977387564560148\n",
      "[2025-02-21 19:20:08,831][src.model.predictors][INFO] - Moving embeddings to device: cuda\n",
      "[2025-02-21 19:20:08,838][src.model.predictors][INFO] - Moving embeddings to device: cuda\n",
      "[2025-02-21 19:20:08,840][src.model.composite_model][INFO] - This is the updated predictor name: lightattention_kernel_size_3_dropout_0.25_conv_dropout_0.25_learning_rate_0.0005_batch_size_1000_max_epochs_10_patience_200_post_attention_mlp_conv1d_output_dim_-1_optimal_cutoff_0.27\n",
      "[2025-02-21 19:20:08,840][src.model.composite_model][INFO] - Composite model name: esm2t68MUR50D_LightAttention_sbxwfibrillationpeptidewaltzdb-train-valserrano-test\n",
      "[2025-02-21 19:20:08,840][src.model.composite_model][INFO] - Best model is: kernel_size_3_dropout_0.25_conv_dropout_0.25_learning_rate_0.0005_batch_size_1000_max_epochs_10_patience_200_post_attention_mlp_conv1d_output_dim_-1_optimal_cutoff_0.27\n",
      "[2025-02-21 19:20:08,840][src.model.composite_model][INFO] - Moving to test mode\n",
      "[2025-02-21 19:20:08,841][src.model.composite_model][INFO] - Composite model name: esm2t68MUR50D_LightAttention_sbxwfibrillationpeptidewaltzdb-train-valserrano-test\n",
      "[2025-02-21 19:20:08,841][src.model.composite_model][INFO] - Saving model: esm2t68MUR50D_LightAttention_sbxwfibrillationpeptidewaltzdb-train-valserrano-test\n",
      "<RunInfo: artifact_uri='s3://nnedl-core-prd-eu-central-1-curated/mlops/378/f0f329cd25c8427cad6fef0455fed399/artifacts', end_time=None, experiment_id='378', lifecycle_stage='active', run_id='f0f329cd25c8427cad6fef0455fed399', run_name='', run_uuid='f0f329cd25c8427cad6fef0455fed399', start_time=1740165540767, status='RUNNING', user_id='sbxw'>\n",
      "[2025-02-21 19:20:11,738][src.model.abstract_components][INFO] - Total memory: 23.58378496GB\n",
      "Memory already allocated: 0.04823808GB\n",
      "[2025-02-21 19:20:11,824][src.model.embedders][INFO] - Final results len: 248\n",
      "[2025-02-21 19:20:11,824][src.model.composite_model][INFO] - Residue embeddings\n",
      "[2025-02-21 19:20:11,828][src.model.predictors][INFO] - Moving embeddings to device: cuda\n",
      "sequences: (1122,)\n",
      "sequence_embeddings: 1122\n",
      "predictions: (1122,)\n",
      "data_split: train\n",
      "labels: (1122,)\n",
      "predictions_probability: (1122,)\n",
      "residue_level_prediction: False\n",
      "sequences: (277,)\n",
      "sequence_embeddings: 277\n",
      "predictions: (277,)\n",
      "data_split: val\n",
      "labels: (277,)\n",
      "predictions_probability: (277,)\n",
      "residue_level_prediction: False\n",
      "sequences: (248,)\n",
      "sequence_embeddings: 248\n",
      "predictions: (248,)\n",
      "data_split: test\n",
      "labels: (248,)\n",
      "predictions_probability: (248,)\n",
      "residue_level_prediction: False\n",
      "[2025-02-21 19:20:13,210][src.model.composite_model][INFO] - Composite model name: esm2t68MUR50D_LightAttention_sbxwfibrillationpeptidewaltzdb-train-valserrano-test\n",
      "[2025-02-21 19:20:13,210][src.model.composite_model][INFO] - Composite model name: esm2t68MUR50D_LightAttention_sbxwfibrillationpeptidewaltzdb-train-valserrano-test\n",
      "[2025-02-21 19:20:13,938][src.model.composite_model][INFO] - Composite model name: esm2t68MUR50D_LightAttention_sbxwfibrillationpeptidewaltzdb-train-valserrano-test\n",
      "[2025-02-21 19:20:13,949][__main__][INFO] - Done!\n",
      "run_id: f0f329cd25c8427cad6fef0455fed399\n",
      "artifacts: ['model/MLmodel', 'model/checkpoints', 'model/conda.yaml', 'model/data', 'model/python_env.yaml', 'model/requirements.txt']\n",
      "params: {'general.run_mode': 'train', 'general.abs_repo_path': 'None', 'general.composite_model_name': 'esm2t68MUR50D_LightAttention_sbxwfibrillationpeptidewaltzdb-train-valserrano-test', 'general.composite_model_path': 'None', 'general.precomputed_embeddings_path': 'None', 'general.random_state': '42', 'dataset.data_name': 'sbxw_fibrillation_peptide_waltzdb-train-val_serrano-test', 'dataset.add_data_columns': 'False', 'dataset.data_columns_dimred': 'False', 'dataset.data_columns_standard': 'False', 'dataset.data_scaler': 'RobustScaler', 'dataset.rbf_encoder': 'RadialBasisFunctionGaussian', 'dataset.rbf_n_kernels': '10', 'dataset.task': 'classification_binary', 'dataset.use_predefined_split': 'True', 'dataset.use_sample_weights': 'False', 'dataset.residue_prediction_labels': 'None', 'dataset.data_split.train': '0.8', 'dataset.data_split.val': '0.0', 'dataset.data_split.test': '0.2', 'embedder.class_name': 'ESM', 'embedder.model_name': 'esm2_t6_8M_UR50D', 'embedder.model_path': 'None', 'embedder.standardize': 'False', 'embedder.scalar_type': 'StandardScaler', 'embedder.hparams': 'None', 'embedder.n_copies': '1', 'embedder.chain_break': 'poly-gly-linker', 'embedder.buffer_scale_factor': '2.0', 'embedder.max_batch_size': '400', 'embedder.simple_batching': 'False', 'embedder.strict': 'True', 'embedder.verbose': 'False', 'embedder.mean_pool': 'False', 'dimred.class_name': 'NoReduction', 'dimred.transform_name': 'None', 'dimred.fraction_variance_explained': 'None', 'predictor.class_name': 'LightAttention', 'predictor.model_name': 'None', 'predictor.model_type': 'classification_binary', 'predictor.mem_per_job': 'None', 'predictor.residue_prediction_mode': 'False', 'predictor.hparams.kernel_size': '3', 'predictor.hparams.dropout': '0.25', 'predictor.hparams.conv_dropout': '0.25', 'predictor.hparams.learning_rate': '0.0005', 'predictor.hparams.batch_size': '1000', 'predictor.hparams.max_epochs': '10', 'predictor.hparams.patience': '200', 'predictor.hparams.post_attention': 'mlp', 'predictor.hparams.conv1d_output_dim': '-1', 'predictor.hparams.optimal_cutoff': '0.5', 'persistence.type': 'lovelace', 'persistence.data_root_folder': '/novo/projects/departments/cdd/molecular_ai/mlbp/data', 'epochs': '10', 'optimizer_name': 'SGD', 'lr': '0.0005', 'momentum': '0', 'dampening': '0', 'weight_decay': '0', 'nesterov': 'False', 'maximize': 'False', 'foreach': 'None', 'differentiable': 'False', 'fused': 'None', 'persistence.artifacts_root_folder': '/novo/projects/departments/cdd/molecular_ai/mlbp/artifacts', 'persistence.training_data': 'static_input_data', 'persistence.pretrained_weights': 'static_pretrained_weights', 'mlflow.tracking_uri': 'https://datalab.corp.novocorp.net/mlflow/', 'mlflow.experiment_name': 'ML-BP-Domino', 'plots.generate_plots': 'False', 'embeddings_dim': '320', 'output_dim': '1', 'kernel_size': '3', 'dropout': '0.25', 'conv_dropout': '0.25', 'learning_rate': '0.0005', 'post_attention': 'mlp', 'conv1d_output_dim': '-1', 'residue_prediction_mode': 'False', 'model_type': 'classification_binary'}\n",
      "metrics: {'epoch': 9.0, 'test.accuracy': 0.29838709677419356, 'test.precision': 0.3008130081300813, 'test.recall': 0.9736842105263158, 'test.specificity': 0.0, 'test.f_score': 0.45962732919254656, 'test.matthews_corr_coef': -0.13564533785127794, 'test.optimal_mcc': 0.73, 'test.optimal_mcc_cutoff': 0.73, 'test.balanced_accuracy': 0.4868421052631579, 'test.roc_auc_score': 0.46878824969400246, 'train.accuracy': 0.3663101604278075, 'train.precision': 0.36256781193490056, 'train.recall': 0.9852579852579852, 'train.specificity': 0.013986013986013986, 'train.f_score': 0.5300727032385988, 'train.matthews_corr_coef': -0.0030657370363354336, 'train.optimal_mcc': 0.31, 'train.optimal_mcc_cutoff': 0.31, 'train.balanced_accuracy': 0.4996219996219996, 'train.roc_auc_score': 0.4309685400594491, 'val.accuracy': 0.3574007220216607, 'val.precision': 0.358695652173913, 'val.recall': 0.99, 'train.loss_step': 0.7257487773895264, 'val.specificity': 0.0, 'val.f_score': 0.526595744680851, 'val_loss': 0.7308806777000427, 'val.matthews_corr_coef': -0.08008148024519071, 'val.optimal_mcc': 0.71, 'val.loss': 0.7308806777000427, 'train.loss': 0.728560209274292, 'val.optimal_mcc_cutoff': 0.71, 'val.balanced_accuracy': 0.495, 'train.loss_epoch': 0.728560209274292, 'val.roc_auc_score': 0.43553672316384184}\n",
      "tags: {'Mode': 'training'}\n",
      "results stored in /novo/projects/departments/cdd/molecular_ai/mlbp/artifacts/2025-02-21-1918_/esm2t68MUR50D_LightAttention_sbxwfibrillationpeptidewaltzdb-train-valserrano-test_final_stats.csv\n",
      "s3://nnedl-core-prd-eu-central-1-curated/mlops/378/f0f329cd25c8427cad6fef0455fed399/artifacts\n",
      "\u001b[34mSystem information\u001b[0m: Linux #70~20.04.1-Ubuntu SMP Fri Jun 14 15:42:13 UTC 2024\n",
      "\u001b[34mPython version\u001b[0m: 3.10.14\n",
      "\u001b[34mMLflow version\u001b[0m: 2.20.2\n",
      "\u001b[34mMLflow module location\u001b[0m: /nfs_home/users/sbxw/mambaforge/envs/mlbp/lib/python3.10/site-packages/mlflow/__init__.py\n",
      "\u001b[34mTracking URI\u001b[0m: https://datalab.corp.novocorp.net/mlflow/\n",
      "\u001b[34mRegistry URI\u001b[0m: https://datalab.corp.novocorp.net/mlflow/\n",
      "\u001b[34mActive experiment ID\u001b[0m: 378\n",
      "\u001b[34mActive run ID\u001b[0m: f0f329cd25c8427cad6fef0455fed399\n",
      "\u001b[34mActive run artifact URI\u001b[0m: s3://nnedl-core-prd-eu-central-1-curated/mlops/378/f0f329cd25c8427cad6fef0455fed399/artifacts\n",
      "\u001b[34mMLflow environment variables\u001b[0m: \n",
      "  MLFLOW_EXPERIMENT_ID: 378\n",
      "  MLFLOW_TRACKING_URI: https://datalab.corp.novocorp.net/mlflow/\n",
      "\u001b[34mMLflow dependencies\u001b[0m: \n",
      "  Flask: 2.2.5\n",
      "  Jinja2: 3.1.4\n",
      "  aiohttp: 3.9.5\n",
      "  alembic: 1.13.1\n",
      "  boto3: 1.36.23\n",
      "  botocore: 1.36.23\n",
      "  docker: 7.0.0\n",
      "  graphene: 3.3\n",
      "  gunicorn: 22.0.0\n",
      "  markdown: 3.6\n",
      "  matplotlib: 3.9.0\n",
      "  mlflow-skinny: 2.20.2\n",
      "  numpy: 1.26.4\n",
      "  pandas: 2.2.2\n",
      "  pyarrow: 15.0.2\n",
      "  scikit-learn: 1.4.2\n",
      "  scipy: 1.13.0\n",
      "  sqlalchemy: 2.0.30\n",
      "  virtualenv: 20.26.2\n",
      "None\n",
      "üèÉ View run  at: https://datalab.corp.novocorp.net/mlflow/#/experiments/378/runs/f0f329cd25c8427cad6fef0455fed399\n",
      "üß™ View experiment at: https://datalab.corp.novocorp.net/mlflow/#/experiments/378\n"
     ]
    }
   ],
   "source": [
    "%env AWS_ACCESS_KEY_ID=ASIATIJCHR3KA5YYSX4C\n",
    "%env AWS_SECRET_ACCESS_KEY=aPDRW7A6aUdgjnE2CdQeYG2IpZseMrimkIxc0H//\n",
    "%env AWS_SESSION_TOKEN=FwoGZXIvYXdzEMX//////////wEaDONh6B2GwAQwnkGFRSL0AwI0ymgCmmLalzZXga+CfvhC0RiboEHABvkZiIl6GOVwtQtrORvwMGFLYd5RwDFo+fKXDl5P3zXzI0hnN2nHWf9e+jNJ1wZVVr7JEmw1XZwZn7zyOMG0skT8+BYhtkkZPYUhZB+DPOrrszHfomSSbBuox+/5P/7M492NM2zMnLRPomrOHsCMpc5rTlpv2Qp/zMgP0wKud0NJLjgq46dZkJ7rr7STpYwqc3x+gQ0peDIDGWqtdgeX75v74lpSCBgLU1YwmhUFBBenqDWxFPnYZ+81Q8DAuwtGFABQAUHScu04lM352nNNDTM21nGW50KMXqubIFyBvNcwP7hK61HcxvDZtdXkOc0o/Rg/oVkfa3INcmwV3P8g8qsjmrWhWyfCi3zeXJmH4QJl4rksNLCPMNugzkljoFOxhXFW4dzcfjk/pIZ2RohVcbwsiVHpwR9SXVM+0YzFE2MYSSUomqt5ahlxuUyK2IAJRvggiGOlSBN0T3ADN45y0U+JIFpl92MoIGkaW6Tr0RNT8eIOEGPzBB4g9FILg+CfYT1tMPaVJmlKGkRY+/vJkaE3h4DelnO49JhB1wRJgdtwZlBuFgqRRAPatgbZwhG79EwkmwTTXd5i5AxMeqQymz8jVurFoMBfALEuASskEoLoZIIc65PA+n0xz422KLCh470GMpQBMYrXpVze1m5G2VeOYzklnn6hsbiLu63zI7T4XX5GLExc4eoffUYBO4hlZAvEKYKJoR1Rx+iNlFz2RoQNQAHbfydjTrp7srnbSTGcwtJP3pyxxuqwXIHpWw0wHWx0mAuxWrujzsSyReGInQd+bDpRYsHUTZBd7aHDPrUK7ctcczNzIiVwgFD8g1hroB4ZCAucGRTjjw==\n",
    "\n",
    "repo_dir = '/novo/projects/departments/cdd/molecular_ai/sbxw/repos/ML-BP-Domino'\n",
    "conda_env_name = 'mlbp'\n",
    "\n",
    "# Create command (single set of params)\n",
    "cmd = [\n",
    "    f\"/nfs_home/users/sbxw/mambaforge/condabin/conda run --no-capture-output -n {conda_env_name} python\",\n",
    "    f\"{repo_dir}/src/cli/training.py\",\n",
    "    \"mlflow=datalab\", \"persistence=lovelace\",\n",
    "    \"dataset.use_predefined_split=true\",\n",
    "    \"dataset.data_name=sbxw_fibrillation_peptide_waltzdb-train-val_serrano-test\", \"dataset.task=classification_binary\", \n",
    "    \"embedder=esm2_t6_8M\",\"embedder.mean_pool=false\",\n",
    "    \"dimred=noreduction\",\n",
    "    \"predictor=lightattention\",\n",
    "    \"predictor.hparams.kernel_size=3\", \"predictor.hparams.max_epochs=10\", \"predictor.hparams.patience=200\",\n",
    "    \"predictor.hparams.batch_size=1000\", \"predictor.hparams.learning_rate=0.0005\",\n",
    "    \"mlflow.experiment_name=ML-BP-Domino\",\n",
    "    \"plots.generate_plots=false\",\n",
    "]\n",
    "\n",
    "command_str = \" \".join(cmd)\n",
    "print(command_str)\n",
    "!PYTHONPATH=repo_dir; $command_str"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e87b9db2-6d48-413b-bc74-acbe9d5b32b8",
   "metadata": {},
   "source": [
    "Empty run name...."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e7ea2ac1-fac7-45ba-a2c1-400cc8b53562",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: AWS_ACCESS_KEY_ID=ASIATIJCHR3KA5YYSX4C\n",
      "env: AWS_SECRET_ACCESS_KEY=aPDRW7A6aUdgjnE2CdQeYG2IpZseMrimkIxc0H//\n",
      "env: AWS_SESSION_TOKEN=FwoGZXIvYXdzEMX//////////wEaDONh6B2GwAQwnkGFRSL0AwI0ymgCmmLalzZXga+CfvhC0RiboEHABvkZiIl6GOVwtQtrORvwMGFLYd5RwDFo+fKXDl5P3zXzI0hnN2nHWf9e+jNJ1wZVVr7JEmw1XZwZn7zyOMG0skT8+BYhtkkZPYUhZB+DPOrrszHfomSSbBuox+/5P/7M492NM2zMnLRPomrOHsCMpc5rTlpv2Qp/zMgP0wKud0NJLjgq46dZkJ7rr7STpYwqc3x+gQ0peDIDGWqtdgeX75v74lpSCBgLU1YwmhUFBBenqDWxFPnYZ+81Q8DAuwtGFABQAUHScu04lM352nNNDTM21nGW50KMXqubIFyBvNcwP7hK61HcxvDZtdXkOc0o/Rg/oVkfa3INcmwV3P8g8qsjmrWhWyfCi3zeXJmH4QJl4rksNLCPMNugzkljoFOxhXFW4dzcfjk/pIZ2RohVcbwsiVHpwR9SXVM+0YzFE2MYSSUomqt5ahlxuUyK2IAJRvggiGOlSBN0T3ADN45y0U+JIFpl92MoIGkaW6Tr0RNT8eIOEGPzBB4g9FILg+CfYT1tMPaVJmlKGkRY+/vJkaE3h4DelnO49JhB1wRJgdtwZlBuFgqRRAPatgbZwhG79EwkmwTTXd5i5AxMeqQymz8jVurFoMBfALEuASskEoLoZIIc65PA+n0xz422KLCh470GMpQBMYrXpVze1m5G2VeOYzklnn6hsbiLu63zI7T4XX5GLExc4eoffUYBO4hlZAvEKYKJoR1Rx+iNlFz2RoQNQAHbfydjTrp7srnbSTGcwtJP3pyxxuqwXIHpWw0wHWx0mAuxWrujzsSyReGInQd+bDpRYsHUTZBd7aHDPrUK7ctcczNzIiVwgFD8g1hroB4ZCAucGRTjjw==\n",
      "/nfs_home/users/sbxw/mambaforge/condabin/conda run --no-capture-output -n mlbp python /novo/projects/departments/cdd/molecular_ai/sbxw/repos/ML-BP-Domino/src/cli/training.py mlflow=datalab persistence=lovelace dataset.use_predefined_split=true dataset.data_name=sbxw_fibrillation_peptide_waltzdb-train-val_serrano-test dataset.task=classification_binary embedder=esm2_t6_8M embedder.mean_pool=false dimred=noreduction predictor=lightattention predictor.hparams.kernel_size=3 predictor.hparams.max_epochs=10 predictor.hparams.patience=200 predictor.hparams.batch_size=1000 predictor.hparams.learning_rate=0.0005 mlflow.experiment_name=ML-BP-Domino plots.generate_plots=false\n",
      "[2025-02-21 20:16:14,801][__main__][INFO] - Workflow configuration:\n",
      "\n",
      "general:\n",
      "  run_mode: train\n",
      "  abs_repo_path: null\n",
      "  composite_model_name: null\n",
      "  composite_model_path: null\n",
      "  precomputed_embeddings_path: null\n",
      "  random_state: 42\n",
      "dataset:\n",
      "  data_name: sbxw_fibrillation_peptide_waltzdb-train-val_serrano-test\n",
      "  add_data_columns: false\n",
      "  data_columns_dimred: false\n",
      "  data_columns_standard: false\n",
      "  data_scaler: RobustScaler\n",
      "  rbf_encoder: RadialBasisFunctionGaussian\n",
      "  rbf_n_kernels: 10\n",
      "  task: classification_binary\n",
      "  use_predefined_split: true\n",
      "  use_sample_weights: false\n",
      "  residue_prediction_labels: null\n",
      "  data_split:\n",
      "    train: 0.8\n",
      "    val: 0.0\n",
      "    test: 0.2\n",
      "embedder:\n",
      "  class_name: ESM\n",
      "  model_name: esm2_t6_8M_UR50D\n",
      "  model_path: null\n",
      "  standardize: false\n",
      "  scalar_type: StandardScaler\n",
      "  hparams: null\n",
      "  n_copies: 1\n",
      "  chain_break: poly-gly-linker\n",
      "  buffer_scale_factor: 2.0\n",
      "  max_batch_size: 400\n",
      "  simple_batching: false\n",
      "  strict: true\n",
      "  verbose: false\n",
      "  mean_pool: false\n",
      "dimred:\n",
      "  class_name: NoReduction\n",
      "  transform_name: null\n",
      "  fraction_variance_explained: null\n",
      "predictor:\n",
      "  class_name: LightAttention\n",
      "  model_name: null\n",
      "  model_type: classification_binary\n",
      "  mem_per_job: null\n",
      "  residue_prediction_mode: false\n",
      "  hparams:\n",
      "    kernel_size: 3\n",
      "    dropout: 0.25\n",
      "    conv_dropout: 0.25\n",
      "    learning_rate: 0.0005\n",
      "    batch_size: 1000\n",
      "    max_epochs: 10\n",
      "    patience: 200\n",
      "    post_attention: mlp\n",
      "    conv1d_output_dim: -1\n",
      "    optimal_cutoff: 0.5\n",
      "persistence:\n",
      "  type: lovelace\n",
      "  data_root_folder: /novo/projects/departments/cdd/molecular_ai/mlbp/data\n",
      "  artifacts_root_folder: /novo/projects/departments/cdd/molecular_ai/mlbp/artifacts\n",
      "  training_data: static_input_data\n",
      "  pretrained_weights: static_pretrained_weights\n",
      "mlflow:\n",
      "  tracking_uri: https://datalab.corp.novocorp.net/mlflow/\n",
      "  experiment_name: ML-BP-Domino\n",
      "plots:\n",
      "  generate_plots: false\n",
      "\n",
      "2025-02-21 20:16:36.514605: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2025-02-21 20:16:36.518222: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2025-02-21 20:16:36.861216: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2025-02-21 20:16:37.499374: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2025-02-21 20:16:48.900394: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "[2025-02-21 20:17:09,820][src.model.composite_model][INFO] - ANuPP: <class 'src.model.embedders.ANuPP'>\n",
      "[2025-02-21 20:17:09,820][src.model.composite_model][INFO] - Amorprot: <class 'src.model.embedders.Amorprot'>\n",
      "[2025-02-21 20:17:09,820][src.model.composite_model][INFO] - Ankh: <class 'src.model.embedders.Ankh'>\n",
      "[2025-02-21 20:17:09,820][src.model.composite_model][INFO] - Biophys: <class 'src.model.embedders.Biophys'>\n",
      "[2025-02-21 20:17:09,820][src.model.composite_model][INFO] - ESM: <class 'src.model.embedders.ESM'>\n",
      "[2025-02-21 20:17:09,820][src.model.composite_model][INFO] - Kmer: <class 'src.model.embedders.Kmer'>\n",
      "[2025-02-21 20:17:09,820][src.model.composite_model][INFO] - OneHot: <class 'src.model.embedders.OneHot'>\n",
      "[2025-02-21 20:17:09,821][src.model.composite_model][INFO] - PrecomputedDescriptors: <class 'src.model.embedders.PrecomputedDescriptors'>\n",
      "[2025-02-21 20:17:09,821][src.model.composite_model][INFO] - ProtT5: <class 'src.model.embedders.ProtT5'>\n",
      "[2025-02-21 20:17:09,824][src.model.composite_model][INFO] - NoReduction: <class 'src.model.dimred.NoReduction'>\n",
      "[2025-02-21 20:17:09,824][src.model.composite_model][INFO] - PCADimReduction: <class 'src.model.dimred.PCADimReduction'>\n",
      "[2025-02-21 20:17:10,598][src.model.composite_model][INFO] - KNearestNeighbors: <class 'src.model.predictors.KNearestNeighbors'>\n",
      "[2025-02-21 20:17:10,598][src.model.composite_model][INFO] - LSTM: <class 'src.model.predictors.LSTM'>\n",
      "[2025-02-21 20:17:10,598][src.model.composite_model][INFO] - LightAttention: <class 'src.model.predictors.LightAttention'>\n",
      "[2025-02-21 20:17:10,598][src.model.composite_model][INFO] - LogisticRegression: <class 'src.model.predictors.LogisticRegression'>\n",
      "[2025-02-21 20:17:10,598][src.model.composite_model][INFO] - MLP: <class 'src.model.predictors.MLP'>\n",
      "[2025-02-21 20:17:10,598][src.model.composite_model][INFO] - RandomForest: <class 'src.model.predictors.RandomForest'>\n",
      "[2025-02-21 20:17:10,598][src.model.composite_model][INFO] - RidgeRegression: <class 'src.model.predictors.RidgeRegression'>\n",
      "[2025-02-21 20:17:10,598][src.model.composite_model][INFO] - XGBoost: <class 'src.model.predictors.XGBoost'>\n",
      "[2025-02-21 20:17:10,599][src.model.dimred][INFO] - Load class (NoReduction): NoReduction\n",
      "[2025-02-21 20:17:10,599][src.model.abstract_components][INFO] - Load class (DimRed Model): NoReduction\n",
      "[2025-02-21 20:17:10,599][src.model.predictors][INFO] - Load class (LightAttention): LightAttention\n",
      "[2025-02-21 20:17:10,599][src.model.abstract_components][INFO] - Load class (TorchPredictorModel): LightAttention\n",
      "[2025-02-21 20:17:10,599][src.model.abstract_components][INFO] - Load class (Predictor Model): LightAttention\n",
      "[2025-02-21 20:17:10,599][src.model.composite_model][INFO] - Composite model name: esm2t68MUR50D_LightAttention_sbxwfibrillationpeptidewaltzdb-train-valserrano-test\n",
      "[2025-02-21 20:17:10,600][src.model.composite_model][INFO] - Initialized model: esm2t68MUR50D_LightAttention_sbxwfibrillationpeptidewaltzdb-train-valserrano-test in run_mode = train\n",
      "[2025-02-21 20:17:10,621][src.helpers.dataset][INFO] - Loading file: /novo/projects/departments/cdd/molecular_ai/mlbp/data/static_input_data/sbxw_fibrillation_peptide_waltzdb-train-val_serrano-test.csv\n",
      "[2025-02-21 20:17:10,621][src.helpers.dataset][INFO] - No additional data columns found while parsing.\n",
      "[2025-02-21 20:17:10,628][src.helpers.dataset][INFO] - Select data according to predetermined splits in the dataframe, train (N = 1122), validation (N = 277), test (N = 248)\n",
      "[2025-02-21 20:17:10,628][src.helpers.dataset][INFO] - Loaded columns: {}\n",
      "[2025-02-21 20:17:10,629][src.helpers.mlflow_helpers][INFO] - Setting up MLflow...\n",
      "[2025-02-21 20:17:10,629][src.helpers.mlflow_helpers][INFO] - Experiment name: ML-BP-Domino\n",
      "[2025-02-21 20:17:10,629][src.helpers.mlflow_helpers][INFO] - Setting MLflow tracking URI to https://datalab.corp.novocorp.net/mlflow/\n",
      "[2025-02-21 20:17:12,078][src.helpers.mlflow_helpers][INFO] - Setting MLflow experiment to ML-BP-Domino\n",
      "[2025-02-21 20:17:13,019][__main__][INFO] - <RunInfo: artifact_uri='s3://nnedl-core-prd-eu-central-1-curated/mlops/378/1ad2f595567a4b63ae87db66892229ec/artifacts', end_time=None, experiment_id='378', lifecycle_stage='active', run_id='1ad2f595567a4b63ae87db66892229ec', run_name='', run_uuid='1ad2f595567a4b63ae87db66892229ec', start_time=1740169032778, status='RUNNING', user_id='sbxw'>\n",
      "[2025-02-21 20:17:13,644][__main__][INFO] - Compute embeddings on-the-fly and train model\n",
      "[2025-02-21 20:17:13,645][src.model.abstract_components][INFO] - Load class (LLMEmbedderModel): ESM\n",
      "[2025-02-21 20:17:13,645][src.model.abstract_components][INFO] - Load class (Embedder Model): ESM\n",
      "[2025-02-21 20:17:13,646][src.model.embedders][INFO] - Using existing cache directory: /novo/projects/departments/cdd/molecular_ai/mlbp/data/static_pretrained_weights\n",
      "Using cache found in /novo/projects/departments/cdd/molecular_ai/mlbp/data/static_pretrained_weights/facebookresearch_esm_main\n",
      "[2025-02-21 20:17:14,317][src.model.embedders][INFO] - moving model to cuda\n",
      "[2025-02-21 20:17:14,824][src.model.abstract_components][INFO] - Total memory: 23.58378496GB\n",
      "Memory already allocated: 0.030069248GB\n",
      "[2025-02-21 20:17:16,224][src.model.embedders][INFO] - Final results len: 1122\n",
      "[2025-02-21 20:17:16,224][src.model.composite_model][INFO] - Residue embeddings\n",
      "[2025-02-21 20:17:16,224][src.model.abstract_components][INFO] - Total memory: 23.58378496GB\n",
      "Memory already allocated: 0.038758912GB\n",
      "[2025-02-21 20:17:16,262][src.model.embedders][INFO] - Final results len: 277\n",
      "/nfs_home/users/sbxw/mambaforge/envs/mlbp/lib/python3.10/site-packages/lightning/fabric/plugins/environments/slurm.py:204: The `srun` command is available on your system but is not used. HINT: If your intention is to run Lightning on SLURM, prepend your python command with `srun` like so: srun python /novo/projects/departments/cdd/molecular_ai/sbxw/rep ...\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/nfs_home/users/sbxw/mambaforge/envs/mlbp/lib/python3.10/site-packages/lightning/fabric/plugins/environments/slurm.py:204: The `srun` command is available on your system but is not used. HINT: If your intention is to run Lightning on SLURM, prepend your python command with `srun` like so: srun python /novo/projects/departments/cdd/molecular_ai/sbxw/rep ...\n",
      "[2025-02-21 20:17:19,455][pytorch_lightning.utilities.rank_zero][INFO] - You are using a CUDA device ('NVIDIA L4') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name                  | Type       | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | feature_convolution   | Conv1d     | 307 K  | train\n",
      "1 | attention_convolution | Conv1d     | 307 K  | train\n",
      "2 | softmax               | Softmax    | 0      | train\n",
      "3 | dropout               | Dropout    | 0      | train\n",
      "4 | sigmoid               | Sigmoid    | 0      | train\n",
      "5 | mlp                   | Sequential | 20.6 K | train\n",
      "6 | loss_fxn              | BCELoss    | 0      | train\n",
      "-------------------------------------------------------------\n",
      "635 K     Trainable params\n",
      "0         Non-trainable params\n",
      "635 K     Total params\n",
      "2.543     Total estimated model params size (MB)\n",
      "12        Modules in train mode\n",
      "0         Modules in eval mode\n",
      "/nfs_home/users/sbxw/mambaforge/envs/mlbp/lib/python3.10/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:424: The 'val_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=7` in the `DataLoader` to improve performance.\n",
      "/nfs_home/users/sbxw/mambaforge/envs/mlbp/lib/python3.10/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:424: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=7` in the `DataLoader` to improve performance.\n",
      "[2025-02-21 20:17:26,696][botocore.credentials][INFO] - Found credentials in environment variables.\n",
      "[2025-02-21 20:18:06,266][pytorch_lightning.utilities.rank_zero][INFO] - `Trainer.fit` stopped: `max_epochs=10` reached.\n",
      "üèÉ View run  at: https://datalab.corp.novocorp.net/mlflow/#/experiments/378/runs/1ad2f595567a4b63ae87db66892229ec\n",
      "üß™ View experiment at: https://datalab.corp.novocorp.net/mlflow/#/experiments/378\n",
      "\u001b[31m2025/02/21 20:18:57 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\u001b[0m\n",
      "[2025-02-21 20:19:04,876][src.model.abstract_components][INFO] - MODEL STOPPED BY EARLY STOPPER AT EPOCH 0\n",
      "[2025-02-21 20:19:04,877][src.model.abstract_components][INFO] - BEST MODEL VALIDATION LOSS IS 0.6848748922348022\n",
      "[2025-02-21 20:19:04,877][src.model.abstract_components][INFO] - BEST MODEL SAVED AT /novo/projects/departments/cdd/public/users/ehec/sbxw_files_2/378/1ad2f595567a4b63ae87db66892229ec/checkpoints/epoch=9-step=20.ckpt\n",
      "[2025-02-21 20:19:04,877][src.model.abstract_components][INFO] - FINAL MODEL SAVED AT None\n",
      "[2025-02-21 20:19:05,583][src.model.predictors][INFO] - Moving embeddings to device: cuda\n",
      "[2025-02-21 20:19:05,721][src.model.predictors][INFO] - Optimal cutoff is: 0.6 with MCC: 0.18379826910128555\n",
      "[2025-02-21 20:19:05,731][src.model.predictors][INFO] - Moving embeddings to device: cuda\n",
      "[2025-02-21 20:19:05,739][src.model.predictors][INFO] - Moving embeddings to device: cuda\n",
      "[2025-02-21 20:19:05,741][src.model.composite_model][INFO] - This is the updated predictor name: lightattention_kernel_size_3_dropout_0.25_conv_dropout_0.25_learning_rate_0.0005_batch_size_1000_max_epochs_10_patience_200_post_attention_mlp_conv1d_output_dim_-1_optimal_cutoff_0.6\n",
      "[2025-02-21 20:19:05,741][src.model.composite_model][INFO] - Composite model name: esm2t68MUR50D_LightAttention_sbxwfibrillationpeptidewaltzdb-train-valserrano-test\n",
      "[2025-02-21 20:19:05,741][src.model.composite_model][INFO] - Best model is: kernel_size_3_dropout_0.25_conv_dropout_0.25_learning_rate_0.0005_batch_size_1000_max_epochs_10_patience_200_post_attention_mlp_conv1d_output_dim_-1_optimal_cutoff_0.6\n",
      "[2025-02-21 20:19:05,741][src.model.composite_model][INFO] - Moving to test mode\n",
      "[2025-02-21 20:19:05,742][src.model.composite_model][INFO] - Composite model name: esm2t68MUR50D_LightAttention_sbxwfibrillationpeptidewaltzdb-train-valserrano-test\n",
      "[2025-02-21 20:19:05,742][src.model.composite_model][INFO] - Saving model: esm2t68MUR50D_LightAttention_sbxwfibrillationpeptidewaltzdb-train-valserrano-test\n",
      "<RunInfo: artifact_uri='s3://nnedl-core-prd-eu-central-1-curated/mlops/378/1ad2f595567a4b63ae87db66892229ec/artifacts', end_time=None, experiment_id='378', lifecycle_stage='active', run_id='1ad2f595567a4b63ae87db66892229ec', run_name='', run_uuid='1ad2f595567a4b63ae87db66892229ec', start_time=1740169032778, status='RUNNING', user_id='sbxw'>\n",
      "[2025-02-21 20:19:10,686][src.model.abstract_components][INFO] - Total memory: 23.58378496GB\n",
      "Memory already allocated: 0.04823808GB\n",
      "[2025-02-21 20:19:10,773][src.model.embedders][INFO] - Final results len: 248\n",
      "[2025-02-21 20:19:10,773][src.model.composite_model][INFO] - Residue embeddings\n",
      "[2025-02-21 20:19:10,776][src.model.predictors][INFO] - Moving embeddings to device: cuda\n",
      "sequences: (1122,)\n",
      "sequence_embeddings: 1122\n",
      "predictions: (1122,)\n",
      "data_split: train\n",
      "labels: (1122,)\n",
      "predictions_probability: (1122,)\n",
      "residue_level_prediction: False\n",
      "sequences: (277,)\n",
      "sequence_embeddings: 277\n",
      "predictions: (277,)\n",
      "data_split: val\n",
      "labels: (277,)\n",
      "predictions_probability: (277,)\n",
      "residue_level_prediction: False\n",
      "sequences: (248,)\n",
      "sequence_embeddings: 248\n",
      "predictions: (248,)\n",
      "data_split: test\n",
      "labels: (248,)\n",
      "predictions_probability: (248,)\n",
      "residue_level_prediction: False\n",
      "[2025-02-21 20:19:12,116][src.model.composite_model][INFO] - Composite model name: esm2t68MUR50D_LightAttention_sbxwfibrillationpeptidewaltzdb-train-valserrano-test\n",
      "[2025-02-21 20:19:12,116][src.model.composite_model][INFO] - Composite model name: esm2t68MUR50D_LightAttention_sbxwfibrillationpeptidewaltzdb-train-valserrano-test\n",
      "[2025-02-21 20:19:12,850][src.model.composite_model][INFO] - Composite model name: esm2t68MUR50D_LightAttention_sbxwfibrillationpeptidewaltzdb-train-valserrano-test\n",
      "[2025-02-21 20:19:12,860][__main__][INFO] - Done!\n",
      "run_id: 1ad2f595567a4b63ae87db66892229ec\n",
      "artifacts: ['model/MLmodel', 'model/checkpoints', 'model/conda.yaml', 'model/data', 'model/python_env.yaml', 'model/requirements.txt']\n",
      "params: {'epochs': '10', 'optimizer_name': 'SGD', 'lr': '0.0005', 'momentum': '0', 'dampening': '0', 'weight_decay': '0', 'nesterov': 'False', 'maximize': 'False', 'foreach': 'None', 'differentiable': 'False', 'fused': 'None', 'general.run_mode': 'train', 'general.abs_repo_path': 'None', 'general.composite_model_name': 'esm2t68MUR50D_LightAttention_sbxwfibrillationpeptidewaltzdb-train-valserrano-test', 'general.composite_model_path': 'None', 'general.precomputed_embeddings_path': 'None', 'general.random_state': '42', 'dataset.data_name': 'sbxw_fibrillation_peptide_waltzdb-train-val_serrano-test', 'dataset.add_data_columns': 'False', 'dataset.data_columns_dimred': 'False', 'dataset.data_columns_standard': 'False', 'dataset.data_scaler': 'RobustScaler', 'dataset.rbf_encoder': 'RadialBasisFunctionGaussian', 'dataset.rbf_n_kernels': '10', 'dataset.task': 'classification_binary', 'dataset.use_predefined_split': 'True', 'dataset.use_sample_weights': 'False', 'dataset.residue_prediction_labels': 'None', 'dataset.data_split.train': '0.8', 'dataset.data_split.val': '0.0', 'dataset.data_split.test': '0.2', 'embedder.class_name': 'ESM', 'embedder.model_name': 'esm2_t6_8M_UR50D', 'embedder.model_path': 'None', 'embedder.standardize': 'False', 'embedder.scalar_type': 'StandardScaler', 'embedder.hparams': 'None', 'embedder.n_copies': '1', 'embedder.chain_break': 'poly-gly-linker', 'embedder.buffer_scale_factor': '2.0', 'embedder.max_batch_size': '400', 'embedder.simple_batching': 'False', 'embedder.strict': 'True', 'embedder.verbose': 'False', 'embedder.mean_pool': 'False', 'dimred.class_name': 'NoReduction', 'dimred.transform_name': 'None', 'dimred.fraction_variance_explained': 'None', 'predictor.class_name': 'LightAttention', 'predictor.model_name': 'None', 'predictor.model_type': 'classification_binary', 'predictor.mem_per_job': 'None', 'predictor.residue_prediction_mode': 'False', 'predictor.hparams.kernel_size': '3', 'predictor.hparams.dropout': '0.25', 'predictor.hparams.conv_dropout': '0.25', 'predictor.hparams.learning_rate': '0.0005', 'predictor.hparams.batch_size': '1000', 'predictor.hparams.max_epochs': '10', 'predictor.hparams.patience': '200', 'predictor.hparams.post_attention': 'mlp', 'predictor.hparams.conv1d_output_dim': '-1', 'predictor.hparams.optimal_cutoff': '0.5', 'persistence.type': 'lovelace', 'persistence.data_root_folder': '/novo/projects/departments/cdd/molecular_ai/mlbp/data', 'persistence.artifacts_root_folder': '/novo/projects/departments/cdd/molecular_ai/mlbp/artifacts', 'persistence.training_data': 'static_input_data', 'persistence.pretrained_weights': 'static_pretrained_weights', 'mlflow.tracking_uri': 'https://datalab.corp.novocorp.net/mlflow/', 'mlflow.experiment_name': 'ML-BP-Domino', 'plots.generate_plots': 'False', 'embeddings_dim': '320', 'output_dim': '1', 'kernel_size': '3', 'dropout': '0.25', 'conv_dropout': '0.25', 'learning_rate': '0.0005', 'post_attention': 'mlp', 'conv1d_output_dim': '-1', 'residue_prediction_mode': 'False', 'model_type': 'classification_binary'}\n",
      "metrics: {'val.loss': 0.6848748922348022, 'val_loss': 0.6848748922348022, 'val.accuracy': 0.6425992779783394, 'val.precision': 0.5142857142857142, 'val.recall': 0.18, 'val.specificity': 0.903954802259887, 'val.f_score': 0.26666666666666666, 'val.matthews_corr_coef': 0.12136416467524103, 'val.optimal_mcc': 0.44, 'val.optimal_mcc_cutoff': 0.44, 'val.balanced_accuracy': 0.5419774011299435, 'val.roc_auc_score': 0.6020338983050847, 'train.loss_step': 0.6776665449142456, 'train.loss': 0.6864377856254578, 'train.loss_epoch': 0.6864377856254578, 'epoch': 9.0, 'train.accuracy': 0.6229946524064172, 'train.precision': 0.43846153846153846, 'train.recall': 0.14004914004914004, 'train.specificity': 0.8979020979020979, 'train.f_score': 0.2122905027932961, 'train.matthews_corr_coef': 0.057009687474896396, 'train.optimal_mcc': 0.51, 'train.optimal_mcc_cutoff': 0.51, 'train.balanced_accuracy': 0.518975618975619, 'train.roc_auc_score': 0.5506915688733871, 'test.accuracy': 0.6612903225806451, 'test.precision': 0.375, 'test.recall': 0.15789473684210525, 'test.specificity': 0.8837209302325582, 'test.f_score': 0.2222222222222222, 'test.matthews_corr_coef': 0.05723029906331337, 'test.optimal_mcc': 0.5700000000000001, 'test.optimal_mcc_cutoff': 0.5700000000000001, 'test.balanced_accuracy': 0.5208078335373317, 'test.roc_auc_score': 0.5174418604651163}\n",
      "tags: {'Mode': 'training'}\n",
      "results stored in /novo/projects/departments/cdd/molecular_ai/mlbp/artifacts/2025-02-21-2016_1ad2f595567a4b63ae87db66892229ec/esm2t68MUR50D_LightAttention_sbxwfibrillationpeptidewaltzdb-train-valserrano-test_final_stats.csv\n",
      "s3://nnedl-core-prd-eu-central-1-curated/mlops/378/1ad2f595567a4b63ae87db66892229ec/artifacts\n",
      "\u001b[34mSystem information\u001b[0m: Linux #70~20.04.1-Ubuntu SMP Fri Jun 14 15:42:13 UTC 2024\n",
      "\u001b[34mPython version\u001b[0m: 3.10.14\n",
      "\u001b[34mMLflow version\u001b[0m: 2.20.2\n",
      "\u001b[34mMLflow module location\u001b[0m: /nfs_home/users/sbxw/mambaforge/envs/mlbp/lib/python3.10/site-packages/mlflow/__init__.py\n",
      "\u001b[34mTracking URI\u001b[0m: https://datalab.corp.novocorp.net/mlflow/\n",
      "\u001b[34mRegistry URI\u001b[0m: https://datalab.corp.novocorp.net/mlflow/\n",
      "\u001b[34mActive experiment ID\u001b[0m: 378\n",
      "\u001b[34mActive run ID\u001b[0m: 1ad2f595567a4b63ae87db66892229ec\n",
      "\u001b[34mActive run artifact URI\u001b[0m: s3://nnedl-core-prd-eu-central-1-curated/mlops/378/1ad2f595567a4b63ae87db66892229ec/artifacts\n",
      "\u001b[34mMLflow environment variables\u001b[0m: \n",
      "  MLFLOW_EXPERIMENT_ID: 378\n",
      "  MLFLOW_TRACKING_URI: https://datalab.corp.novocorp.net/mlflow/\n",
      "\u001b[34mMLflow dependencies\u001b[0m: \n",
      "  Flask: 2.2.5\n",
      "  Jinja2: 3.1.4\n",
      "  aiohttp: 3.9.5\n",
      "  alembic: 1.13.1\n",
      "  boto3: 1.36.23\n",
      "  botocore: 1.36.23\n",
      "  docker: 7.0.0\n",
      "  graphene: 3.3\n",
      "  gunicorn: 22.0.0\n",
      "  markdown: 3.6\n",
      "  matplotlib: 3.9.0\n",
      "  mlflow-skinny: 2.20.2\n",
      "  numpy: 1.26.4\n",
      "  pandas: 2.2.2\n",
      "  pyarrow: 15.0.2\n",
      "  scikit-learn: 1.4.2\n",
      "  scipy: 1.13.0\n",
      "  sqlalchemy: 2.0.30\n",
      "  virtualenv: 20.26.2\n",
      "None\n",
      "üèÉ View run  at: https://datalab.corp.novocorp.net/mlflow/#/experiments/378/runs/1ad2f595567a4b63ae87db66892229ec\n",
      "üß™ View experiment at: https://datalab.corp.novocorp.net/mlflow/#/experiments/378\n"
     ]
    }
   ],
   "source": [
    "%env AWS_ACCESS_KEY_ID=ASIATIJCHR3KA5YYSX4C\n",
    "%env AWS_SECRET_ACCESS_KEY=aPDRW7A6aUdgjnE2CdQeYG2IpZseMrimkIxc0H//\n",
    "%env AWS_SESSION_TOKEN=FwoGZXIvYXdzEMX//////////wEaDONh6B2GwAQwnkGFRSL0AwI0ymgCmmLalzZXga+CfvhC0RiboEHABvkZiIl6GOVwtQtrORvwMGFLYd5RwDFo+fKXDl5P3zXzI0hnN2nHWf9e+jNJ1wZVVr7JEmw1XZwZn7zyOMG0skT8+BYhtkkZPYUhZB+DPOrrszHfomSSbBuox+/5P/7M492NM2zMnLRPomrOHsCMpc5rTlpv2Qp/zMgP0wKud0NJLjgq46dZkJ7rr7STpYwqc3x+gQ0peDIDGWqtdgeX75v74lpSCBgLU1YwmhUFBBenqDWxFPnYZ+81Q8DAuwtGFABQAUHScu04lM352nNNDTM21nGW50KMXqubIFyBvNcwP7hK61HcxvDZtdXkOc0o/Rg/oVkfa3INcmwV3P8g8qsjmrWhWyfCi3zeXJmH4QJl4rksNLCPMNugzkljoFOxhXFW4dzcfjk/pIZ2RohVcbwsiVHpwR9SXVM+0YzFE2MYSSUomqt5ahlxuUyK2IAJRvggiGOlSBN0T3ADN45y0U+JIFpl92MoIGkaW6Tr0RNT8eIOEGPzBB4g9FILg+CfYT1tMPaVJmlKGkRY+/vJkaE3h4DelnO49JhB1wRJgdtwZlBuFgqRRAPatgbZwhG79EwkmwTTXd5i5AxMeqQymz8jVurFoMBfALEuASskEoLoZIIc65PA+n0xz422KLCh470GMpQBMYrXpVze1m5G2VeOYzklnn6hsbiLu63zI7T4XX5GLExc4eoffUYBO4hlZAvEKYKJoR1Rx+iNlFz2RoQNQAHbfydjTrp7srnbSTGcwtJP3pyxxuqwXIHpWw0wHWx0mAuxWrujzsSyReGInQd+bDpRYsHUTZBd7aHDPrUK7ctcczNzIiVwgFD8g1hroB4ZCAucGRTjjw==\n",
    "\n",
    "repo_dir = '/novo/projects/departments/cdd/molecular_ai/sbxw/repos/ML-BP-Domino'\n",
    "conda_env_name = 'mlbp'\n",
    "\n",
    "# Create command (single set of params)\n",
    "cmd = [\n",
    "    f\"/nfs_home/users/sbxw/mambaforge/condabin/conda run --no-capture-output -n {conda_env_name} python\",\n",
    "    f\"{repo_dir}/src/cli/training.py\",\n",
    "    \"mlflow=datalab\", \"persistence=lovelace\",\n",
    "    \"dataset.use_predefined_split=true\",\n",
    "    \"dataset.data_name=sbxw_fibrillation_peptide_waltzdb-train-val_serrano-test\", \"dataset.task=classification_binary\", \n",
    "    \"embedder=esm2_t6_8M\",\"embedder.mean_pool=false\",\n",
    "    \"dimred=noreduction\",\n",
    "    \"predictor=lightattention\",\n",
    "    \"predictor.hparams.kernel_size=3\", \"predictor.hparams.max_epochs=10\", \"predictor.hparams.patience=200\",\n",
    "    \"predictor.hparams.batch_size=1000\", \"predictor.hparams.learning_rate=0.0005\",\n",
    "    \"mlflow.experiment_name=ML-BP-Domino\",\n",
    "    \"plots.generate_plots=false\",\n",
    "]\n",
    "\n",
    "command_str = \" \".join(cmd)\n",
    "print(command_str)\n",
    "!PYTHONPATH=repo_dir; $command_str"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5646494a-58bd-46e7-b267-1298a36c02cc",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Run job with pytorch main merge branch (3 tests)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "20f69d8f-4079-428b-abba-d798596c83a8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: AWS_ACCESS_KEY_ID=ASIATIJCHR3KA5YYSX4C\n",
      "env: AWS_SECRET_ACCESS_KEY=aPDRW7A6aUdgjnE2CdQeYG2IpZseMrimkIxc0H//\n",
      "env: AWS_SESSION_TOKEN=FwoGZXIvYXdzEMX//////////wEaDONh6B2GwAQwnkGFRSL0AwI0ymgCmmLalzZXga+CfvhC0RiboEHABvkZiIl6GOVwtQtrORvwMGFLYd5RwDFo+fKXDl5P3zXzI0hnN2nHWf9e+jNJ1wZVVr7JEmw1XZwZn7zyOMG0skT8+BYhtkkZPYUhZB+DPOrrszHfomSSbBuox+/5P/7M492NM2zMnLRPomrOHsCMpc5rTlpv2Qp/zMgP0wKud0NJLjgq46dZkJ7rr7STpYwqc3x+gQ0peDIDGWqtdgeX75v74lpSCBgLU1YwmhUFBBenqDWxFPnYZ+81Q8DAuwtGFABQAUHScu04lM352nNNDTM21nGW50KMXqubIFyBvNcwP7hK61HcxvDZtdXkOc0o/Rg/oVkfa3INcmwV3P8g8qsjmrWhWyfCi3zeXJmH4QJl4rksNLCPMNugzkljoFOxhXFW4dzcfjk/pIZ2RohVcbwsiVHpwR9SXVM+0YzFE2MYSSUomqt5ahlxuUyK2IAJRvggiGOlSBN0T3ADN45y0U+JIFpl92MoIGkaW6Tr0RNT8eIOEGPzBB4g9FILg+CfYT1tMPaVJmlKGkRY+/vJkaE3h4DelnO49JhB1wRJgdtwZlBuFgqRRAPatgbZwhG79EwkmwTTXd5i5AxMeqQymz8jVurFoMBfALEuASskEoLoZIIc65PA+n0xz422KLCh470GMpQBMYrXpVze1m5G2VeOYzklnn6hsbiLu63zI7T4XX5GLExc4eoffUYBO4hlZAvEKYKJoR1Rx+iNlFz2RoQNQAHbfydjTrp7srnbSTGcwtJP3pyxxuqwXIHpWw0wHWx0mAuxWrujzsSyReGInQd+bDpRYsHUTZBd7aHDPrUK7ctcczNzIiVwgFD8g1hroB4ZCAucGRTjjw==\n",
      "/nfs_home/users/sbxw/mambaforge/condabin/conda run --no-capture-output -n mlbp python /novo/projects/departments/cdd/molecular_ai/sbxw/repos/ML-BP-Domino/src/cli/training.py mlflow=datalab persistence=lovelace dataset.use_predefined_split=true dataset.data_name=sbxw_fibrillation_peptide_waltzdb-train-val_serrano-test dataset.task=classification_binary embedder=esm2_t6_8M embedder.mean_pool=false dimred=noreduction predictor=lightattention predictor.hparams.kernel_size=3 predictor.hparams.max_epochs=10 predictor.hparams.patience=200 predictor.hparams.batch_size=1000 predictor.hparams.learning_rate=0.0005 mlflow.experiment_name=ML-BP-Domino plots.generate_plots=false\n",
      "2025-02-21 20:25:44.630460: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2025-02-21 20:25:44.630508: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2025-02-21 20:25:44.632046: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2025-02-21 20:25:44.639521: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2025-02-21 20:25:48.314288: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "[2025-02-21 20:26:00,275][__main__][INFO] - Workflow configuration:\n",
      "\n",
      "general:\n",
      "  run_mode: train\n",
      "  abs_repo_path: null\n",
      "  composite_model_name: null\n",
      "  composite_model_path: null\n",
      "  precomputed_embeddings_path: null\n",
      "  random_state: 42\n",
      "dataset:\n",
      "  data_name: sbxw_fibrillation_peptide_waltzdb-train-val_serrano-test\n",
      "  add_data_columns: false\n",
      "  data_columns_dimred: false\n",
      "  data_columns_standard: false\n",
      "  group_column: null\n",
      "  data_scaler: RobustScaler\n",
      "  target_scaling: null\n",
      "  rbf_encoder: RadialBasisFunctionGaussian\n",
      "  rbf_n_kernels: 10\n",
      "  task: classification_binary\n",
      "  use_predefined_split: true\n",
      "  use_sample_weights: false\n",
      "  residue_prediction_labels: null\n",
      "  data_split_column: data_split\n",
      "  data_split:\n",
      "    train: 0.8\n",
      "    val: 0.0\n",
      "    test: 0.2\n",
      "embedder:\n",
      "  class_name: ESM\n",
      "  model_name: esm2_t6_8M_UR50D\n",
      "  model_path: null\n",
      "  standardize: false\n",
      "  scalar_type: StandardScaler\n",
      "  hparams: null\n",
      "  n_copies: 1\n",
      "  chain_break: poly-gly-linker\n",
      "  buffer_scale_factor: 2.0\n",
      "  max_batch_size: 400\n",
      "  simple_batching: false\n",
      "  strict: true\n",
      "  verbose: false\n",
      "  mean_pool: false\n",
      "  output_hidden_states: false\n",
      "dimred:\n",
      "  class_name: NoReduction\n",
      "  transform_name: null\n",
      "  fraction_variance_explained: null\n",
      "predictor:\n",
      "  class_name: LightAttention\n",
      "  model_name: null\n",
      "  model_type: classification_binary\n",
      "  mem_per_job: null\n",
      "  residue_prediction_mode: false\n",
      "  hparams:\n",
      "    kernel_size: 3\n",
      "    dropout: 0.25\n",
      "    conv_dropout: 0.25\n",
      "    learning_rate: 0.0005\n",
      "    batch_size: 1000\n",
      "    max_epochs: 10\n",
      "    patience: 200\n",
      "    post_attention: mlp\n",
      "    conv1d_output_dim: -1\n",
      "    optimal_cutoff: 0.5\n",
      "persistence:\n",
      "  type: lovelace\n",
      "  data_root_folder: /novo/projects/departments/cdd/molecular_ai/mlbp/data\n",
      "  artifacts_root_folder: /novo/projects/departments/cdd/molecular_ai/mlbp/artifacts\n",
      "  training_data: static_input_data\n",
      "  pretrained_weights: static_pretrained_weights\n",
      "mlflow:\n",
      "  tracking_uri: https://datalab.corp.novocorp.net/mlflow/\n",
      "  experiment_name: ML-BP-Domino\n",
      "plots:\n",
      "  generate_plots: false\n",
      "\n",
      "[2025-02-21 20:26:00,276][src.model.dimred][INFO] - Load class (NoReduction): NoReduction\n",
      "[2025-02-21 20:26:00,276][src.model.abstract_components][INFO] - Load class (DimRed Model): NoReduction\n",
      "[2025-02-21 20:26:00,277][src.model.predictors][INFO] - Load class (LightAttention): LightAttention\n",
      "[2025-02-21 20:26:00,277][src.model.abstract_components][INFO] - Load class (TorchPredictorModel): LightAttention\n",
      "[2025-02-21 20:26:00,277][src.model.abstract_components][INFO] - Load class (Predictor Model): LightAttention\n",
      "[2025-02-21 20:26:00,277][src.model.composite_model][INFO] - Composite model name: esm2t68MUR50D_LightAttention_sbxwfibrillationpeptidewaltzdb-train-valserrano-test\n",
      "[2025-02-21 20:26:00,277][src.model.composite_model][INFO] - Initialized model: esm2t68MUR50D_LightAttention_sbxwfibrillationpeptidewaltzdb-train-valserrano-test in run_mode = train\n",
      "[2025-02-21 20:26:00,282][src.helpers.dataset][INFO] - Loading file: /novo/projects/departments/cdd/molecular_ai/mlbp/data/static_input_data/sbxw_fibrillation_peptide_waltzdb-train-val_serrano-test.csv\n",
      "[2025-02-21 20:26:00,282][src.helpers.dataset][INFO] - Using group_column \"None\".\n",
      "[2025-02-21 20:26:00,283][src.helpers.dataset][INFO] - No additional data columns found while parsing.\n",
      "[2025-02-21 20:26:00,284][src.helpers.dataset][INFO] - Select data according to predetermined splits in the dataframe, train (N = 1122), validation (N = 277), test (N = 248)\n",
      "[2025-02-21 20:26:00,284][src.helpers.dataset][INFO] - Loaded columns: {}\n",
      "[2025-02-21 20:26:00,285][src.helpers.mlflow_helpers][INFO] - Setting up MLflow...\n",
      "[2025-02-21 20:26:00,285][src.helpers.mlflow_helpers][INFO] - Experiment name: ML-BP-Domino\n",
      "[2025-02-21 20:26:00,285][src.helpers.mlflow_helpers][INFO] - Setting MLflow tracking URI to https://datalab.corp.novocorp.net/mlflow/\n",
      "[2025-02-21 20:26:01,645][src.helpers.mlflow_helpers][INFO] - Setting MLflow experiment to ML-BP-Domino\n",
      "[2025-02-21 20:26:02,849][__main__][INFO] - Compute embeddings on-the-fly and train model\n",
      "[2025-02-21 20:26:02,849][src.model.abstract_components][INFO] - Load class (LLMEmbedderModel): ESM\n",
      "[2025-02-21 20:26:02,849][src.model.abstract_components][INFO] - Load class (Embedder Model): ESM\n",
      "[2025-02-21 20:26:02,850][src.model.embedders][INFO] - Loading model: esm2_t6_8M_UR50D, will extract embeddings from 6-th layer\n",
      "Some weights of EsmModel were not initialized from the model checkpoint at facebook/esm2_t6_8M_UR50D and are newly initialized: ['esm.pooler.dense.bias', 'esm.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "[2025-02-21 20:26:03,969][src.model.embedders][INFO] - Moving model to cuda\n",
      "[2025-02-21 20:26:04,239][src.model.abstract_components][INFO] - Total memory: 23.58378496GB\n",
      "Memory already allocated: 0.031387648GB\n",
      "[2025-02-21 20:26:04,740][src.model.embedders][INFO] - Per-residue embeddings count: 1122\n",
      "[2025-02-21 20:26:04,740][src.model.composite_model][INFO] - Residue embeddings\n",
      "[2025-02-21 20:26:04,741][src.model.abstract_components][INFO] - Total memory: 23.58378496GB\n",
      "Memory already allocated: 0.043664896GB\n",
      "[2025-02-21 20:26:04,764][src.model.embedders][INFO] - Per-residue embeddings count: 277\n",
      "[2025-02-21 20:26:04,764][src.model.scalers][INFO] - Fitted scaler: PassThroughScaler\n",
      "[2025-02-21 20:26:04,769][src.model.scalers][INFO] - Before standardization - min: 0.0, max: 1.0\n",
      "[2025-02-21 20:26:04,769][src.model.scalers][INFO] - After standardization - min: 0.0, max: 1.0\n",
      "[2025-02-21 20:26:04,769][src.model.scalers][INFO] - Before standardization - min: 0.0, max: 1.0\n",
      "[2025-02-21 20:26:04,769][src.model.scalers][INFO] - After standardization - min: 0.0, max: 1.0\n",
      "[2025-02-21 20:26:04,769][src.model.scalers][INFO] - Before standardization - min: 0.0, max: 1.0\n",
      "[2025-02-21 20:26:04,769][src.model.scalers][INFO] - After standardization - min: 0.0, max: 1.0\n",
      "/nfs_home/users/sbxw/mambaforge/envs/mlbp/lib/python3.10/site-packages/lightning/fabric/plugins/environments/slurm.py:204: The `srun` command is available on your system but is not used. HINT: If your intention is to run Lightning on SLURM, prepend your python command with `srun` like so: srun python /novo/projects/departments/cdd/molecular_ai/sbxw/rep ...\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/nfs_home/users/sbxw/mambaforge/envs/mlbp/lib/python3.10/site-packages/lightning/fabric/plugins/environments/slurm.py:204: The `srun` command is available on your system but is not used. HINT: If your intention is to run Lightning on SLURM, prepend your python command with `srun` like so: srun python /novo/projects/departments/cdd/molecular_ai/sbxw/rep ...\n",
      "[2025-02-21 20:26:06,335][pytorch_lightning.utilities.rank_zero][INFO] - You are using a CUDA device ('NVIDIA L4') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name                  | Type       | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | feature_convolution   | Conv1d     | 307 K  | train\n",
      "1 | attention_convolution | Conv1d     | 307 K  | train\n",
      "2 | softmax               | Softmax    | 0      | train\n",
      "3 | dropout               | Dropout    | 0      | train\n",
      "4 | sigmoid               | Sigmoid    | 0      | train\n",
      "5 | mlp                   | Sequential | 20.6 K | train\n",
      "6 | loss_fxn              | BCELoss    | 0      | train\n",
      "-------------------------------------------------------------\n",
      "635 K     Trainable params\n",
      "0         Non-trainable params\n",
      "635 K     Total params\n",
      "2.543     Total estimated model params size (MB)\n",
      "12        Modules in train mode\n",
      "0         Modules in eval mode\n",
      "/nfs_home/users/sbxw/mambaforge/envs/mlbp/lib/python3.10/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:424: The 'val_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=7` in the `DataLoader` to improve performance.\n",
      "/nfs_home/users/sbxw/mambaforge/envs/mlbp/lib/python3.10/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:424: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=7` in the `DataLoader` to improve performance.\n",
      "[2025-02-21 20:26:10,051][botocore.credentials][INFO] - Found credentials in environment variables.\n",
      "[2025-02-21 20:26:35,778][pytorch_lightning.utilities.rank_zero][INFO] - `Trainer.fit` stopped: `max_epochs=10` reached.\n",
      "üèÉ View run  at: https://datalab.corp.novocorp.net/mlflow/#/experiments/378/runs/99c476f32f3347a693bc88622e97a7a0\n",
      "üß™ View experiment at: https://datalab.corp.novocorp.net/mlflow/#/experiments/378\n",
      "\u001b[31m2025/02/21 20:27:04 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\u001b[0m\n",
      "[2025-02-21 20:27:09,838][src.model.abstract_components][INFO] - MODEL STOPPED BY EARLY STOPPER AT EPOCH 0\n",
      "[2025-02-21 20:27:09,838][src.model.abstract_components][INFO] - BEST MODEL VALIDATION LOSS IS 0.6722960472106934\n",
      "[2025-02-21 20:27:09,838][src.model.abstract_components][INFO] - BEST MODEL SAVED AT /novo/projects/departments/cdd/public/users/ehec/sbxw_files_2/378/99c476f32f3347a693bc88622e97a7a0/checkpoints/epoch=9-step=20.ckpt\n",
      "[2025-02-21 20:27:09,839][src.model.abstract_components][INFO] - FINAL MODEL SAVED AT None\n",
      "[2025-02-21 20:27:10,127][src.model.predictors][INFO] - Moving embeddings to device: cuda\n",
      "[2025-02-21 20:27:10,234][src.model.predictors][INFO] - Optimal cutoff is: 0.45 with MCC: 0.24175942417297044\n",
      "[2025-02-21 20:27:10,245][src.model.predictors][INFO] - Moving embeddings to device: cuda\n",
      "[2025-02-21 20:27:10,253][src.model.predictors][INFO] - Moving embeddings to device: cuda\n",
      "[2025-02-21 20:27:10,254][src.model.scalers][INFO] - Before standardization - min: False, max: True\n",
      "[2025-02-21 20:27:10,254][src.model.scalers][INFO] - After standardization - min: False, max: True\n",
      "[2025-02-21 20:27:10,254][src.model.scalers][INFO] - Before standardization - min: False, max: True\n",
      "[2025-02-21 20:27:10,254][src.model.scalers][INFO] - After standardization - min: False, max: True\n",
      "[2025-02-21 20:27:10,255][src.model.composite_model][INFO] - This is the updated predictor name: lightattention_kernel_size_3_dropout_0.25_conv_dropout_0.25_learning_rate_0.0005_batch_size_1000_max_epochs_10_patience_200_post_attention_mlp_conv1d_output_dim_-1_optimal_cutoff_0.45\n",
      "[2025-02-21 20:27:10,255][src.model.composite_model][INFO] - Composite model name: esm2t68MUR50D_LightAttention_sbxwfibrillationpeptidewaltzdb-train-valserrano-test\n",
      "[2025-02-21 20:27:10,255][src.model.composite_model][INFO] - Best model is: kernel_size_3_dropout_0.25_conv_dropout_0.25_learning_rate_0.0005_batch_size_1000_max_epochs_10_patience_200_post_attention_mlp_conv1d_output_dim_-1_optimal_cutoff_0.45\n",
      "[2025-02-21 20:27:10,255][src.model.composite_model][INFO] - Moving to test mode\n",
      "[2025-02-21 20:27:10,256][src.model.composite_model][INFO] - Composite model name: esm2t68MUR50D_LightAttention_sbxwfibrillationpeptidewaltzdb-train-valserrano-test\n",
      "[2025-02-21 20:27:10,256][src.model.composite_model][INFO] - Saving model: esm2t68MUR50D_LightAttention_sbxwfibrillationpeptidewaltzdb-train-valserrano-test\n",
      "<RunInfo: artifact_uri='s3://nnedl-core-prd-eu-central-1-curated/mlops/378/99c476f32f3347a693bc88622e97a7a0/artifacts', end_time=None, experiment_id='378', lifecycle_stage='active', run_id='99c476f32f3347a693bc88622e97a7a0', run_name='', run_uuid='99c476f32f3347a693bc88622e97a7a0', start_time=1740169561915, status='RUNNING', user_id='sbxw'>\n",
      "[2025-02-21 20:27:14,599][src.model.abstract_components][INFO] - Total memory: 23.58378496GB\n",
      "Memory already allocated: 0.04955648GB\n",
      "[2025-02-21 20:27:14,670][src.model.embedders][INFO] - Per-residue embeddings count: 248\n",
      "[2025-02-21 20:27:14,670][src.model.composite_model][INFO] - Residue embeddings\n",
      "[2025-02-21 20:27:14,673][src.model.predictors][INFO] - Moving embeddings to device: cuda\n",
      "[2025-02-21 20:27:14,677][src.model.scalers][INFO] - Before standardization - min: False, max: True\n",
      "[2025-02-21 20:27:14,678][src.model.scalers][INFO] - After standardization - min: False, max: True\n",
      "sequences: (1122,)\n",
      "sequence_embeddings: 1122\n",
      "predictions: (1122,)\n",
      "predictions_scaled: (1122,)\n",
      "data_split: train\n",
      "labels: (1122,)\n",
      "predictions_probability: (1122,)\n",
      "residue_level_prediction: False\n",
      "sequences: (277,)\n",
      "sequence_embeddings: 277\n",
      "predictions: (277,)\n",
      "predictions_scaled: (277,)\n",
      "data_split: val\n",
      "labels: (277,)\n",
      "predictions_probability: (277,)\n",
      "residue_level_prediction: False\n",
      "sequences: (248,)\n",
      "sequence_embeddings: 248\n",
      "predictions: (248,)\n",
      "predictions_scaled: (248,)\n",
      "data_split: test\n",
      "labels: (248,)\n",
      "predictions_probability: (248,)\n",
      "residue_level_prediction: False\n",
      "[2025-02-21 20:27:16,024][src.model.composite_model][INFO] - Composite model name: esm2t68MUR50D_LightAttention_sbxwfibrillationpeptidewaltzdb-train-valserrano-test\n",
      "[2025-02-21 20:27:16,864][__main__][INFO] - Done!\n",
      "run_id: 99c476f32f3347a693bc88622e97a7a0\n",
      "artifacts: ['model/MLmodel', 'model/checkpoints', 'model/conda.yaml', 'model/data', 'model/python_env.yaml', 'model/requirements.txt']\n",
      "params: {'epochs': '10', 'optimizer_name': 'SGD', 'lr': '0.0005', 'momentum': '0', 'dampening': '0', 'weight_decay': '0', 'nesterov': 'False', 'maximize': 'False', 'foreach': 'None', 'differentiable': 'False', 'fused': 'None', 'embeddings_dim': '320', 'output_dim': '1', 'kernel_size': '3', 'dropout': '0.25', 'conv_dropout': '0.25', 'learning_rate': '0.0005', 'post_attention': 'mlp', 'conv1d_output_dim': '-1', 'residue_prediction_mode': 'False', 'general.run_mode': 'train', 'general.abs_repo_path': 'None', 'general.composite_model_name': 'esm2t68MUR50D_LightAttention_sbxwfibrillationpeptidewaltzdb-train-valserrano-test', 'general.composite_model_path': 'None', 'general.precomputed_embeddings_path': 'None', 'general.random_state': '42', 'dataset.data_name': 'sbxw_fibrillation_peptide_waltzdb-train-val_serrano-test', 'dataset.add_data_columns': 'False', 'dataset.data_columns_dimred': 'False', 'dataset.data_columns_standard': 'False', 'dataset.group_column': 'None', 'dataset.data_scaler': 'RobustScaler', 'dataset.target_scaling': 'None', 'dataset.rbf_encoder': 'RadialBasisFunctionGaussian', 'dataset.rbf_n_kernels': '10', 'dataset.task': 'classification_binary', 'dataset.use_predefined_split': 'True', 'dataset.use_sample_weights': 'False', 'dataset.residue_prediction_labels': 'None', 'dataset.data_split_column': 'data_split', 'dataset.data_split.train': '0.8', 'dataset.data_split.val': '0.0', 'dataset.data_split.test': '0.2', 'embedder.class_name': 'ESM', 'embedder.model_name': 'esm2_t6_8M_UR50D', 'embedder.model_path': 'None', 'embedder.standardize': 'False', 'embedder.scalar_type': 'StandardScaler', 'embedder.hparams': 'None', 'embedder.n_copies': '1', 'embedder.chain_break': 'poly-gly-linker', 'embedder.buffer_scale_factor': '2.0', 'embedder.max_batch_size': '400', 'embedder.simple_batching': 'False', 'embedder.strict': 'True', 'embedder.verbose': 'False', 'embedder.mean_pool': 'False', 'embedder.output_hidden_states': 'False', 'dimred.class_name': 'NoReduction', 'dimred.transform_name': 'None', 'dimred.fraction_variance_explained': 'None', 'predictor.class_name': 'LightAttention', 'predictor.model_name': 'None', 'predictor.model_type': 'classification_binary', 'predictor.mem_per_job': 'None', 'predictor.residue_prediction_mode': 'False', 'predictor.hparams.kernel_size': '3', 'predictor.hparams.dropout': '0.25', 'predictor.hparams.conv_dropout': '0.25', 'predictor.hparams.learning_rate': '0.0005', 'predictor.hparams.batch_size': '1000', 'predictor.hparams.max_epochs': '10', 'predictor.hparams.patience': '200', 'predictor.hparams.post_attention': 'mlp', 'predictor.hparams.conv1d_output_dim': '-1', 'predictor.hparams.optimal_cutoff': '0.5', 'persistence.type': 'lovelace', 'persistence.data_root_folder': '/novo/projects/departments/cdd/molecular_ai/mlbp/data', 'persistence.artifacts_root_folder': '/novo/projects/departments/cdd/molecular_ai/mlbp/artifacts', 'persistence.training_data': 'static_input_data', 'persistence.pretrained_weights': 'static_pretrained_weights', 'mlflow.tracking_uri': 'https://datalab.corp.novocorp.net/mlflow/', 'mlflow.experiment_name': 'ML-BP-Domino', 'plots.generate_plots': 'False', 'model_type': 'classification_binary'}\n",
      "metrics: {'val_loss': 0.6722960472106934, 'train.accuracy': 0.5169340463458111, 'train.precision': 0.4028776978417266, 'train.recall': 0.687960687960688, 'train.specificity': 0.4195804195804196, 'train.f_score': 0.5081669691470054, 'train.matthews_corr_coef': 0.10649234502599098, 'train.optimal_mcc': 0.1588864982783678, 'train.optimal_mcc_cutoff': 0.49, 'train.balanced_accuracy': 0.5537705537705537, 'train.roc_auc_score': 0.5930001202728477, 'val.accuracy': 0.47653429602888087, 'val.precision': 0.3699421965317919, 'val.recall': 0.64, 'val.specificity': 0.384180790960452, 'val.f_score': 0.46886446886446886, 'val.matthews_corr_coef': 0.023983768006364117, 'val.optimal_mcc': 0.13125485028599299, 'val.optimal_mcc_cutoff': 0.3, 'val.balanced_accuracy': 0.5120903954802261, 'val.roc_auc_score': 0.5215254237288136, 'train.loss_step': 0.6521094441413879, 'epoch': 9.0, 'test.accuracy': 0.5282258064516129, 'test.precision': 0.36774193548387096, 'test.recall': 0.75, 'test.specificity': 0.43023255813953487, 'test.f_score': 0.4935064935064935, 'test.matthews_corr_coef': 0.17163147829313036, 'test.optimal_mcc': 0.19106586058692035, 'test.optimal_mcc_cutoff': 0.48, 'test.balanced_accuracy': 0.5901162790697674, 'test.roc_auc_score': 0.6090881272949815, 'val.loss': 0.6722960472106934, 'train.loss': 0.6749476194381714, 'train.loss_epoch': 0.6749476194381714}\n",
      "tags: {'Mode': 'training'}\n",
      "results stored in /novo/projects/departments/cdd/molecular_ai/mlbp/artifacts/2025-02-21-2026_/esm2t68MUR50D_LightAttention_sbxwfibrillationpeptidewaltzdb-train-valserrano-test_stats.csv\n",
      "s3://nnedl-core-prd-eu-central-1-curated/mlops/378/99c476f32f3347a693bc88622e97a7a0/artifacts\n",
      "\u001b[34mSystem information\u001b[0m: Linux #70~20.04.1-Ubuntu SMP Fri Jun 14 15:42:13 UTC 2024\n",
      "\u001b[34mPython version\u001b[0m: 3.10.14\n",
      "\u001b[34mMLflow version\u001b[0m: 2.20.2\n",
      "\u001b[34mMLflow module location\u001b[0m: /nfs_home/users/sbxw/mambaforge/envs/mlbp/lib/python3.10/site-packages/mlflow/__init__.py\n",
      "\u001b[34mTracking URI\u001b[0m: https://datalab.corp.novocorp.net/mlflow/\n",
      "\u001b[34mRegistry URI\u001b[0m: https://datalab.corp.novocorp.net/mlflow/\n",
      "\u001b[34mActive experiment ID\u001b[0m: 378\n",
      "\u001b[34mActive run ID\u001b[0m: 99c476f32f3347a693bc88622e97a7a0\n",
      "\u001b[34mActive run artifact URI\u001b[0m: s3://nnedl-core-prd-eu-central-1-curated/mlops/378/99c476f32f3347a693bc88622e97a7a0/artifacts\n",
      "\u001b[34mMLflow environment variables\u001b[0m: \n",
      "  MLFLOW_EXPERIMENT_ID: 378\n",
      "  MLFLOW_TRACKING_URI: https://datalab.corp.novocorp.net/mlflow/\n",
      "\u001b[34mMLflow dependencies\u001b[0m: \n",
      "  Flask: 2.2.5\n",
      "  Jinja2: 3.1.4\n",
      "  aiohttp: 3.9.5\n",
      "  alembic: 1.13.1\n",
      "  boto3: 1.36.23\n",
      "  botocore: 1.36.23\n",
      "  docker: 7.0.0\n",
      "  graphene: 3.3\n",
      "  gunicorn: 22.0.0\n",
      "  markdown: 3.6\n",
      "  matplotlib: 3.9.0\n",
      "  mlflow-skinny: 2.20.2\n",
      "  numpy: 1.26.4\n",
      "  pandas: 2.2.2\n",
      "  pyarrow: 15.0.2\n",
      "  scikit-learn: 1.4.2\n",
      "  scipy: 1.13.0\n",
      "  sqlalchemy: 2.0.30\n",
      "  virtualenv: 20.26.2\n",
      "None\n",
      "üèÉ View run  at: https://datalab.corp.novocorp.net/mlflow/#/experiments/378/runs/99c476f32f3347a693bc88622e97a7a0\n",
      "üß™ View experiment at: https://datalab.corp.novocorp.net/mlflow/#/experiments/378\n"
     ]
    }
   ],
   "source": [
    "%env AWS_ACCESS_KEY_ID=ASIATIJCHR3KA5YYSX4C\n",
    "%env AWS_SECRET_ACCESS_KEY=aPDRW7A6aUdgjnE2CdQeYG2IpZseMrimkIxc0H//\n",
    "%env AWS_SESSION_TOKEN=FwoGZXIvYXdzEMX//////////wEaDONh6B2GwAQwnkGFRSL0AwI0ymgCmmLalzZXga+CfvhC0RiboEHABvkZiIl6GOVwtQtrORvwMGFLYd5RwDFo+fKXDl5P3zXzI0hnN2nHWf9e+jNJ1wZVVr7JEmw1XZwZn7zyOMG0skT8+BYhtkkZPYUhZB+DPOrrszHfomSSbBuox+/5P/7M492NM2zMnLRPomrOHsCMpc5rTlpv2Qp/zMgP0wKud0NJLjgq46dZkJ7rr7STpYwqc3x+gQ0peDIDGWqtdgeX75v74lpSCBgLU1YwmhUFBBenqDWxFPnYZ+81Q8DAuwtGFABQAUHScu04lM352nNNDTM21nGW50KMXqubIFyBvNcwP7hK61HcxvDZtdXkOc0o/Rg/oVkfa3INcmwV3P8g8qsjmrWhWyfCi3zeXJmH4QJl4rksNLCPMNugzkljoFOxhXFW4dzcfjk/pIZ2RohVcbwsiVHpwR9SXVM+0YzFE2MYSSUomqt5ahlxuUyK2IAJRvggiGOlSBN0T3ADN45y0U+JIFpl92MoIGkaW6Tr0RNT8eIOEGPzBB4g9FILg+CfYT1tMPaVJmlKGkRY+/vJkaE3h4DelnO49JhB1wRJgdtwZlBuFgqRRAPatgbZwhG79EwkmwTTXd5i5AxMeqQymz8jVurFoMBfALEuASskEoLoZIIc65PA+n0xz422KLCh470GMpQBMYrXpVze1m5G2VeOYzklnn6hsbiLu63zI7T4XX5GLExc4eoffUYBO4hlZAvEKYKJoR1Rx+iNlFz2RoQNQAHbfydjTrp7srnbSTGcwtJP3pyxxuqwXIHpWw0wHWx0mAuxWrujzsSyReGInQd+bDpRYsHUTZBd7aHDPrUK7ctcczNzIiVwgFD8g1hroB4ZCAucGRTjjw==\n",
    "\n",
    "repo_dir = '/novo/projects/departments/cdd/molecular_ai/sbxw/repos/ML-BP-Domino'\n",
    "conda_env_name = 'mlbp'\n",
    "\n",
    "# Create command (single set of params)\n",
    "cmd = [\n",
    "    f\"/nfs_home/users/sbxw/mambaforge/condabin/conda run --no-capture-output -n {conda_env_name} python\",\n",
    "    f\"{repo_dir}/src/cli/training.py\",\n",
    "    \"mlflow=datalab\", \"persistence=lovelace\",\n",
    "    \"dataset.use_predefined_split=true\",\n",
    "    \"dataset.data_name=sbxw_fibrillation_peptide_waltzdb-train-val_serrano-test\", \"dataset.task=classification_binary\", \n",
    "    \"embedder=esm2_t6_8M\",\"embedder.mean_pool=false\",\n",
    "    \"dimred=noreduction\",\n",
    "    \"predictor=lightattention\",\n",
    "    \"predictor.hparams.kernel_size=3\", \"predictor.hparams.max_epochs=10\", \"predictor.hparams.patience=200\",\n",
    "    \"predictor.hparams.batch_size=1000\", \"predictor.hparams.learning_rate=0.0005\",\n",
    "    \"mlflow.experiment_name=ML-BP-Domino\",\n",
    "    \"plots.generate_plots=false\",\n",
    "]\n",
    "\n",
    "command_str = \" \".join(cmd)\n",
    "print(command_str)\n",
    "!PYTHONPATH=repo_dir; $command_str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "71e34511-5732-4ab3-b614-93dee2891218",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: AWS_ACCESS_KEY_ID=ASIATIJCHR3KA5YYSX4C\n",
      "env: AWS_SECRET_ACCESS_KEY=aPDRW7A6aUdgjnE2CdQeYG2IpZseMrimkIxc0H//\n",
      "env: AWS_SESSION_TOKEN=FwoGZXIvYXdzEMX//////////wEaDONh6B2GwAQwnkGFRSL0AwI0ymgCmmLalzZXga+CfvhC0RiboEHABvkZiIl6GOVwtQtrORvwMGFLYd5RwDFo+fKXDl5P3zXzI0hnN2nHWf9e+jNJ1wZVVr7JEmw1XZwZn7zyOMG0skT8+BYhtkkZPYUhZB+DPOrrszHfomSSbBuox+/5P/7M492NM2zMnLRPomrOHsCMpc5rTlpv2Qp/zMgP0wKud0NJLjgq46dZkJ7rr7STpYwqc3x+gQ0peDIDGWqtdgeX75v74lpSCBgLU1YwmhUFBBenqDWxFPnYZ+81Q8DAuwtGFABQAUHScu04lM352nNNDTM21nGW50KMXqubIFyBvNcwP7hK61HcxvDZtdXkOc0o/Rg/oVkfa3INcmwV3P8g8qsjmrWhWyfCi3zeXJmH4QJl4rksNLCPMNugzkljoFOxhXFW4dzcfjk/pIZ2RohVcbwsiVHpwR9SXVM+0YzFE2MYSSUomqt5ahlxuUyK2IAJRvggiGOlSBN0T3ADN45y0U+JIFpl92MoIGkaW6Tr0RNT8eIOEGPzBB4g9FILg+CfYT1tMPaVJmlKGkRY+/vJkaE3h4DelnO49JhB1wRJgdtwZlBuFgqRRAPatgbZwhG79EwkmwTTXd5i5AxMeqQymz8jVurFoMBfALEuASskEoLoZIIc65PA+n0xz422KLCh470GMpQBMYrXpVze1m5G2VeOYzklnn6hsbiLu63zI7T4XX5GLExc4eoffUYBO4hlZAvEKYKJoR1Rx+iNlFz2RoQNQAHbfydjTrp7srnbSTGcwtJP3pyxxuqwXIHpWw0wHWx0mAuxWrujzsSyReGInQd+bDpRYsHUTZBd7aHDPrUK7ctcczNzIiVwgFD8g1hroB4ZCAucGRTjjw==\n",
      "/nfs_home/users/sbxw/mambaforge/condabin/conda run --no-capture-output -n mlbp python /novo/projects/departments/cdd/molecular_ai/sbxw/repos/ML-BP-Domino/src/cli/training.py mlflow=datalab persistence=lovelace dataset.use_predefined_split=true dataset.data_name=sbxw_fibrillation_peptide_waltzdb-train-val_amypro27-test_randpadded10x dataset.task=classification_binary dataset.residue_prediction_labels=res_value_bool embedder=esm2_t6_8M embedder.mean_pool=false dimred=noreduction predictor=lightattention predictor.residue_prediction_mode=true predictor.hparams.kernel_size=3 predictor.hparams.max_epochs=10 predictor.hparams.patience=200 predictor.hparams.batch_size=1000 predictor.hparams.learning_rate=0.0005 mlflow.experiment_name=ML-BP-Domino plots.generate_plots=false\n",
      "2025-02-21 20:35:02.787558: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2025-02-21 20:35:02.787603: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2025-02-21 20:35:02.789126: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2025-02-21 20:35:02.796578: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2025-02-21 20:35:06.498751: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "[2025-02-21 20:35:18,359][__main__][INFO] - Workflow configuration:\n",
      "\n",
      "general:\n",
      "  run_mode: train\n",
      "  abs_repo_path: null\n",
      "  composite_model_name: null\n",
      "  composite_model_path: null\n",
      "  precomputed_embeddings_path: null\n",
      "  random_state: 42\n",
      "dataset:\n",
      "  data_name: sbxw_fibrillation_peptide_waltzdb-train-val_amypro27-test_randpadded10x\n",
      "  add_data_columns: false\n",
      "  data_columns_dimred: false\n",
      "  data_columns_standard: false\n",
      "  group_column: null\n",
      "  data_scaler: RobustScaler\n",
      "  target_scaling: null\n",
      "  rbf_encoder: RadialBasisFunctionGaussian\n",
      "  rbf_n_kernels: 10\n",
      "  task: classification_binary\n",
      "  use_predefined_split: true\n",
      "  use_sample_weights: false\n",
      "  residue_prediction_labels: res_value_bool\n",
      "  data_split_column: data_split\n",
      "  data_split:\n",
      "    train: 0.8\n",
      "    val: 0.0\n",
      "    test: 0.2\n",
      "embedder:\n",
      "  class_name: ESM\n",
      "  model_name: esm2_t6_8M_UR50D\n",
      "  model_path: null\n",
      "  standardize: false\n",
      "  scalar_type: StandardScaler\n",
      "  hparams: null\n",
      "  n_copies: 1\n",
      "  chain_break: poly-gly-linker\n",
      "  buffer_scale_factor: 2.0\n",
      "  max_batch_size: 400\n",
      "  simple_batching: false\n",
      "  strict: true\n",
      "  verbose: false\n",
      "  mean_pool: false\n",
      "  output_hidden_states: false\n",
      "dimred:\n",
      "  class_name: NoReduction\n",
      "  transform_name: null\n",
      "  fraction_variance_explained: null\n",
      "predictor:\n",
      "  class_name: LightAttention\n",
      "  model_name: null\n",
      "  model_type: classification_binary\n",
      "  mem_per_job: null\n",
      "  residue_prediction_mode: true\n",
      "  hparams:\n",
      "    kernel_size: 3\n",
      "    dropout: 0.25\n",
      "    conv_dropout: 0.25\n",
      "    learning_rate: 0.0005\n",
      "    batch_size: 1000\n",
      "    max_epochs: 10\n",
      "    patience: 200\n",
      "    post_attention: mlp\n",
      "    conv1d_output_dim: -1\n",
      "    optimal_cutoff: 0.5\n",
      "persistence:\n",
      "  type: lovelace\n",
      "  data_root_folder: /novo/projects/departments/cdd/molecular_ai/mlbp/data\n",
      "  artifacts_root_folder: /novo/projects/departments/cdd/molecular_ai/mlbp/artifacts\n",
      "  training_data: static_input_data\n",
      "  pretrained_weights: static_pretrained_weights\n",
      "mlflow:\n",
      "  tracking_uri: https://datalab.corp.novocorp.net/mlflow/\n",
      "  experiment_name: ML-BP-Domino\n",
      "plots:\n",
      "  generate_plots: false\n",
      "\n",
      "[2025-02-21 20:35:18,361][src.model.dimred][INFO] - Load class (NoReduction): NoReduction\n",
      "[2025-02-21 20:35:18,361][src.model.abstract_components][INFO] - Load class (DimRed Model): NoReduction\n",
      "[2025-02-21 20:35:18,361][src.model.predictors][INFO] - Load class (LightAttention): LightAttention\n",
      "[2025-02-21 20:35:18,361][src.model.abstract_components][INFO] - Load class (TorchPredictorModel): LightAttention\n",
      "[2025-02-21 20:35:18,361][src.model.abstract_components][INFO] - Load class (Predictor Model): LightAttention\n",
      "[2025-02-21 20:35:18,362][src.model.composite_model][INFO] - Composite model name: esm2t68MUR50D_LightAttention_sbxwfibrillationpeptidewaltzdb-train-valamypro27-testrandpadded10x\n",
      "[2025-02-21 20:35:18,362][src.model.composite_model][INFO] - Initialized model: esm2t68MUR50D_LightAttention_sbxwfibrillationpeptidewaltzdb-train-valamypro27-testrandpadded10x in run_mode = train\n",
      "[2025-02-21 20:35:18,381][src.helpers.dataset][INFO] - Loading file: /novo/projects/departments/cdd/molecular_ai/mlbp/data/static_input_data/sbxw_fibrillation_peptide_waltzdb-train-val_amypro27-test_randpadded10x.csv\n",
      "[2025-02-21 20:35:18,382][src.helpers.dataset][INFO] - Using group_column \"None\".\n",
      "[2025-02-21 20:35:18,382][src.helpers.dataset][INFO] - No additional data columns found while parsing.\n",
      "[2025-02-21 20:35:18,389][src.helpers.dataset][INFO] - Select data according to predetermined splits in the dataframe, train (N = 11220), validation (N = 2770), test (N = 27)\n",
      "[2025-02-21 20:35:18,389][src.helpers.dataset][INFO] - Loaded columns: {}\n",
      "[2025-02-21 20:35:18,392][src.helpers.mlflow_helpers][INFO] - Setting up MLflow...\n",
      "[2025-02-21 20:35:18,392][src.helpers.mlflow_helpers][INFO] - Experiment name: ML-BP-Domino\n",
      "[2025-02-21 20:35:18,392][src.helpers.mlflow_helpers][INFO] - Setting MLflow tracking URI to https://datalab.corp.novocorp.net/mlflow/\n",
      "[2025-02-21 20:35:19,769][src.helpers.mlflow_helpers][INFO] - Setting MLflow experiment to ML-BP-Domino\n",
      "[2025-02-21 20:35:21,025][__main__][INFO] - Compute embeddings on-the-fly and train model\n",
      "[2025-02-21 20:35:21,027][src.model.abstract_components][INFO] - Load class (LLMEmbedderModel): ESM\n",
      "[2025-02-21 20:35:21,027][src.model.abstract_components][INFO] - Load class (Embedder Model): ESM\n",
      "[2025-02-21 20:35:21,028][src.model.embedders][INFO] - Loading model: esm2_t6_8M_UR50D, will extract embeddings from 6-th layer\n",
      "Some weights of EsmModel were not initialized from the model checkpoint at facebook/esm2_t6_8M_UR50D and are newly initialized: ['esm.pooler.dense.bias', 'esm.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "[2025-02-21 20:35:21,862][src.model.embedders][INFO] - Moving model to cuda\n",
      "[2025-02-21 20:35:22,385][src.model.abstract_components][INFO] - Total memory: 23.58378496GB\n",
      "Memory already allocated: 0.031387648GB\n",
      "[2025-02-21 20:35:24,711][src.model.embedders][INFO] - Per-residue embeddings count: 11220\n",
      "[2025-02-21 20:35:24,711][src.model.composite_model][INFO] - Residue embeddings\n",
      "[2025-02-21 20:35:24,713][src.model.abstract_components][INFO] - Total memory: 23.58378496GB\n",
      "Memory already allocated: 0.039919616GB\n",
      "[2025-02-21 20:35:25,202][src.model.embedders][INFO] - Per-residue embeddings count: 2770\n",
      "[2025-02-21 20:35:25,202][src.model.scalers][INFO] - Fitted scaler: PassThroughScaler\n",
      "[2025-02-21 20:35:25,203][src.model.scalers][INFO] - Before standardization - min: 00000000, max: 01111110000000000\n",
      "[2025-02-21 20:35:25,203][src.model.scalers][INFO] - After standardization - min: 00000000, max: 01111110000000000\n",
      "[2025-02-21 20:35:25,203][src.model.scalers][INFO] - Before standardization - min: 00000000, max: 01111110000000000\n",
      "[2025-02-21 20:35:25,204][src.model.scalers][INFO] - After standardization - min: 00000000, max: 01111110000000000\n",
      "[2025-02-21 20:35:25,204][src.model.scalers][INFO] - Before standardization - min: 000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000001111111111111111110000000000000000000000000000000000000011111111111111111100000000000000000000001111111111111111111111111111111100000000000000000000000000000000000000000, max: 111111111111111111111111111110000000000000000000000000000000000000000000000000000000000000000000000011111111111111111100000000000000000000000000000000000\n",
      "[2025-02-21 20:35:25,204][src.model.scalers][INFO] - After standardization - min: 000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000001111111111111111110000000000000000000000000000000000000011111111111111111100000000000000000000001111111111111111111111111111111100000000000000000000000000000000000000000, max: 111111111111111111111111111110000000000000000000000000000000000000000000000000000000000000000000000011111111111111111100000000000000000000000000000000000\n",
      "/nfs_home/users/sbxw/mambaforge/envs/mlbp/lib/python3.10/site-packages/lightning/fabric/plugins/environments/slurm.py:204: The `srun` command is available on your system but is not used. HINT: If your intention is to run Lightning on SLURM, prepend your python command with `srun` like so: srun python /novo/projects/departments/cdd/molecular_ai/sbxw/rep ...\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/nfs_home/users/sbxw/mambaforge/envs/mlbp/lib/python3.10/site-packages/lightning/fabric/plugins/environments/slurm.py:204: The `srun` command is available on your system but is not used. HINT: If your intention is to run Lightning on SLURM, prepend your python command with `srun` like so: srun python /novo/projects/departments/cdd/molecular_ai/sbxw/rep ...\n",
      "[2025-02-21 20:35:26,938][pytorch_lightning.utilities.rank_zero][INFO] - You are using a CUDA device ('NVIDIA L4') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name                  | Type       | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | feature_convolution   | Conv1d     | 307 K  | train\n",
      "1 | attention_convolution | Conv1d     | 307 K  | train\n",
      "2 | softmax               | Softmax    | 0      | train\n",
      "3 | dropout               | Dropout    | 0      | train\n",
      "4 | sigmoid               | Sigmoid    | 0      | train\n",
      "5 | mlp                   | Sequential | 10.4 K | train\n",
      "6 | loss_fxn              | BCELoss    | 0      | train\n",
      "-------------------------------------------------------------\n",
      "625 K     Trainable params\n",
      "0         Non-trainable params\n",
      "625 K     Total params\n",
      "2.502     Total estimated model params size (MB)\n",
      "12        Modules in train mode\n",
      "0         Modules in eval mode\n",
      "/nfs_home/users/sbxw/mambaforge/envs/mlbp/lib/python3.10/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:424: The 'val_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=7` in the `DataLoader` to improve performance.\n",
      "/nfs_home/users/sbxw/mambaforge/envs/mlbp/lib/python3.10/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:424: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=7` in the `DataLoader` to improve performance.\n",
      "[2025-02-21 20:35:34,230][botocore.credentials][INFO] - Found credentials in environment variables.\n",
      "[2025-02-21 20:36:44,405][pytorch_lightning.utilities.rank_zero][INFO] - `Trainer.fit` stopped: `max_epochs=10` reached.\n",
      "üèÉ View run  at: https://datalab.corp.novocorp.net/mlflow/#/experiments/378/runs/f46088299bb24cd4b9702026bc3bc197\n",
      "üß™ View experiment at: https://datalab.corp.novocorp.net/mlflow/#/experiments/378\n",
      "\u001b[31m2025/02/21 20:37:13 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\u001b[0m\n",
      "[2025-02-21 20:37:22,357][src.model.abstract_components][INFO] - MODEL STOPPED BY EARLY STOPPER AT EPOCH 0\n",
      "[2025-02-21 20:37:22,357][src.model.abstract_components][INFO] - BEST MODEL VALIDATION LOSS IS 0.5608060359954834\n",
      "[2025-02-21 20:37:22,357][src.model.abstract_components][INFO] - BEST MODEL SAVED AT /novo/projects/departments/cdd/public/users/ehec/sbxw_files_2/378/f46088299bb24cd4b9702026bc3bc197/checkpoints/epoch=9-step=120.ckpt\n",
      "[2025-02-21 20:37:22,357][src.model.abstract_components][INFO] - FINAL MODEL SAVED AT None\n",
      "[2025-02-21 20:37:22,678][src.model.predictors][INFO] - Moving embeddings to device: cuda\n",
      "[2025-02-21 20:37:23,619][src.model.predictors][INFO] - Optimal cutoff is: 0.71 with MCC: 0.0031666614567243405\n",
      "[2025-02-21 20:37:23,750][src.model.predictors][INFO] - Moving embeddings to device: cuda\n",
      "[2025-02-21 20:37:23,894][src.model.predictors][INFO] - Moving embeddings to device: cuda\n",
      "[2025-02-21 20:37:23,923][src.model.scalers][INFO] - Before standardization - min: False, max: True\n",
      "[2025-02-21 20:37:23,924][src.model.scalers][INFO] - After standardization - min: False, max: True\n",
      "[2025-02-21 20:37:23,924][src.model.scalers][INFO] - Before standardization - min: False, max: True\n",
      "[2025-02-21 20:37:23,924][src.model.scalers][INFO] - After standardization - min: False, max: True\n",
      "[2025-02-21 20:37:23,925][src.model.composite_model][INFO] - This is the updated predictor name: lightattention_kernel_size_3_dropout_0.25_conv_dropout_0.25_learning_rate_0.0005_batch_size_1000_max_epochs_10_patience_200_post_attention_mlp_conv1d_output_dim_-1_optimal_cutoff_0.71\n",
      "[2025-02-21 20:37:23,925][src.model.composite_model][INFO] - Composite model name: esm2t68MUR50D_LightAttention_sbxwfibrillationpeptidewaltzdb-train-valamypro27-testrandpadded10x\n",
      "[2025-02-21 20:37:23,925][src.model.composite_model][INFO] - Best model is: kernel_size_3_dropout_0.25_conv_dropout_0.25_learning_rate_0.0005_batch_size_1000_max_epochs_10_patience_200_post_attention_mlp_conv1d_output_dim_-1_optimal_cutoff_0.71\n",
      "[2025-02-21 20:37:23,925][src.model.composite_model][INFO] - Moving to test mode\n",
      "[2025-02-21 20:37:23,925][src.model.composite_model][INFO] - Composite model name: esm2t68MUR50D_LightAttention_sbxwfibrillationpeptidewaltzdb-train-valamypro27-testrandpadded10x\n",
      "[2025-02-21 20:37:23,926][src.model.composite_model][INFO] - Saving model: esm2t68MUR50D_LightAttention_sbxwfibrillationpeptidewaltzdb-train-valamypro27-testrandpadded10x\n",
      "<RunInfo: artifact_uri='s3://nnedl-core-prd-eu-central-1-curated/mlops/378/f46088299bb24cd4b9702026bc3bc197/artifacts', end_time=None, experiment_id='378', lifecycle_stage='active', run_id='f46088299bb24cd4b9702026bc3bc197', run_name='', run_uuid='f46088299bb24cd4b9702026bc3bc197', start_time=1740170120035, status='RUNNING', user_id='sbxw'>\n",
      "[2025-02-21 20:37:46,484][src.model.abstract_components][INFO] - Total memory: 23.58378496GB\n",
      "Memory already allocated: 0.396289536GB\n",
      "[2025-02-21 20:37:46,717][src.model.embedders][INFO] - Per-residue embeddings count: 27\n",
      "[2025-02-21 20:37:46,717][src.model.composite_model][INFO] - Residue embeddings\n",
      "[2025-02-21 20:37:46,724][src.model.predictors][INFO] - Moving embeddings to device: cuda\n",
      "/nfs_home/users/sbxw/mambaforge/envs/mlbp/lib/python3.10/site-packages/torch/nn/modules/conv.py:306: UserWarning: Plan failed with a cudnnException: CUDNN_BACKEND_EXECUTION_PLAN_DESCRIPTOR: cudnnFinalize Descriptor Failed cudnn_status: CUDNN_STATUS_NOT_SUPPORTED (Triggered internally at ../aten/src/ATen/native/cudnn/Conv_v8.cpp:919.)\n",
      "  return F.conv1d(input, weight, bias, self.stride,\n",
      "[2025-02-21 20:37:46,735][src.model.scalers][INFO] - Before standardization - min: False, max: True\n",
      "[2025-02-21 20:37:46,735][src.model.scalers][INFO] - After standardization - min: False, max: True\n",
      "sequences: (11220,)\n",
      "sequence_embeddings: 11220\n",
      "predictions: (11220, 26)\n",
      "predictions_scaled: (11220, 26)\n",
      "data_split: train\n",
      "labels: (11220,)\n",
      "predictions_probability: (11220, 26)\n",
      "residue_level_prediction: True\n",
      "sequences: (2770,)\n",
      "sequence_embeddings: 2770\n",
      "predictions: (2770, 26)\n",
      "predictions_scaled: (2770, 26)\n",
      "data_split: val\n",
      "labels: (2770,)\n",
      "predictions_probability: (2770, 26)\n",
      "residue_level_prediction: True\n",
      "sequences: (27,)\n",
      "sequence_embeddings: 27\n",
      "predictions: (27, 660)\n",
      "predictions_scaled: (27, 660)\n",
      "data_split: test\n",
      "labels: (27,)\n",
      "predictions_probability: (27, 660)\n",
      "residue_level_prediction: True\n",
      "[2025-02-21 20:37:52,875][src.model.composite_model][INFO] - Composite model name: esm2t68MUR50D_LightAttention_sbxwfibrillationpeptidewaltzdb-train-valamypro27-testrandpadded10x\n",
      "[2025-02-21 20:38:00,728][__main__][INFO] - Done!\n",
      "run_id: f46088299bb24cd4b9702026bc3bc197\n",
      "artifacts: ['model/MLmodel', 'model/checkpoints', 'model/conda.yaml', 'model/data', 'model/python_env.yaml', 'model/requirements.txt']\n",
      "params: {'general.run_mode': 'train', 'general.abs_repo_path': 'None', 'general.composite_model_name': 'esm2t68MUR50D_LightAttention_sbxwfibrillationpeptidewaltzdb-train-valamypro27-testrandpadded10x', 'general.composite_model_path': 'None', 'general.precomputed_embeddings_path': 'None', 'general.random_state': '42', 'dataset.data_name': 'sbxw_fibrillation_peptide_waltzdb-train-val_amypro27-test_randpadded10x', 'dataset.add_data_columns': 'False', 'dataset.data_columns_dimred': 'False', 'dataset.data_columns_standard': 'False', 'dataset.group_column': 'None', 'dataset.data_scaler': 'RobustScaler', 'dataset.target_scaling': 'None', 'dataset.rbf_encoder': 'RadialBasisFunctionGaussian', 'dataset.rbf_n_kernels': '10', 'dataset.task': 'classification_binary', 'dataset.use_predefined_split': 'True', 'dataset.use_sample_weights': 'False', 'dataset.residue_prediction_labels': 'res_value_bool', 'dataset.data_split_column': 'data_split', 'dataset.data_split.train': '0.8', 'dataset.data_split.val': '0.0', 'dataset.data_split.test': '0.2', 'embedder.class_name': 'ESM', 'embedder.model_name': 'esm2_t6_8M_UR50D', 'embedder.model_path': 'None', 'embedder.standardize': 'False', 'embedder.scalar_type': 'StandardScaler', 'embedder.hparams': 'None', 'embedder.n_copies': '1', 'embedder.chain_break': 'poly-gly-linker', 'embedder.buffer_scale_factor': '2.0', 'embedder.max_batch_size': '400', 'embedder.simple_batching': 'False', 'embedder.strict': 'True', 'embedder.verbose': 'False', 'embedder.mean_pool': 'False', 'embedder.output_hidden_states': 'False', 'dimred.class_name': 'NoReduction', 'dimred.transform_name': 'None', 'dimred.fraction_variance_explained': 'None', 'predictor.class_name': 'LightAttention', 'embeddings_dim': '320', 'output_dim': '1', 'kernel_size': '3', 'dropout': '0.25', 'conv_dropout': '0.25', 'learning_rate': '0.0005', 'post_attention': 'mlp', 'conv1d_output_dim': '-1', 'residue_prediction_mode': 'True', 'epochs': '10', 'optimizer_name': 'SGD', 'lr': '0.0005', 'momentum': '0', 'dampening': '0', 'weight_decay': '0', 'nesterov': 'False', 'maximize': 'False', 'foreach': 'None', 'differentiable': 'False', 'fused': 'None', 'predictor.model_name': 'None', 'predictor.model_type': 'classification_binary', 'predictor.mem_per_job': 'None', 'predictor.residue_prediction_mode': 'True', 'predictor.hparams.kernel_size': '3', 'predictor.hparams.dropout': '0.25', 'predictor.hparams.conv_dropout': '0.25', 'predictor.hparams.learning_rate': '0.0005', 'predictor.hparams.batch_size': '1000', 'predictor.hparams.max_epochs': '10', 'predictor.hparams.patience': '200', 'predictor.hparams.post_attention': 'mlp', 'predictor.hparams.conv1d_output_dim': '-1', 'predictor.hparams.optimal_cutoff': '0.5', 'persistence.type': 'lovelace', 'persistence.data_root_folder': '/novo/projects/departments/cdd/molecular_ai/mlbp/data', 'persistence.artifacts_root_folder': '/novo/projects/departments/cdd/molecular_ai/mlbp/artifacts', 'persistence.training_data': 'static_input_data', 'persistence.pretrained_weights': 'static_pretrained_weights', 'mlflow.tracking_uri': 'https://datalab.corp.novocorp.net/mlflow/', 'mlflow.experiment_name': 'ML-BP-Domino', 'plots.generate_plots': 'False', 'model_type': 'classification_binary'}\n",
      "metrics: {'train.loss_step': 0.5879999399185181, 'train.loss': 0.585083544254303, 'train.loss_epoch': 0.585083544254303, 'epoch': 9.0, 'val.accuracy': 0.8722522216080616, 'val.precision': 0.0, 'val.recall': 0.0, 'val.specificity': 0.9997806910668161, 'val.f_score': 0.0, 'val.matthews_corr_coef': -0.0052895766433425405, 'val.optimal_mcc': 0.0024933447895292577, 'val.optimal_mcc_cutoff': 0.15, 'val.balanced_accuracy': 0.49989034553340805, 'val.roc_auc_score': 0.4836582009357181, 'val_loss': 0.5659210085868835, 'test.accuracy': 0.7967516354613129, 'test.precision': 0.0, 'test.recall': 0.0, 'test.specificity': 0.998868778280543, 'test.f_score': 0.0, 'val.loss': 0.5608060359954834, 'test.matthews_corr_coef': -0.015136213637392894, 'test.optimal_mcc': 0.0, 'test.optimal_mcc_cutoff': 0.0, 'test.balanced_accuracy': 0.4994343891402715, 'test.roc_auc_score': 0.45882296190922983, 'train.accuracy': 0.8711354597413543, 'train.precision': 0.022222222222222223, 'train.recall': 4.095004095004095e-05, 'train.specificity': 0.9997340023577064, 'train.f_score': 8.174943797261394e-05, 'train.matthews_corr_coef': -0.00489431303653257, 'train.optimal_mcc': 0.0008818574449684712, 'train.optimal_mcc_cutoff': 0.12, 'train.balanced_accuracy': 0.4998874761993282, 'train.roc_auc_score': 0.48533738721780917}\n",
      "tags: {'Mode': 'training'}\n",
      "results stored in /novo/projects/departments/cdd/molecular_ai/mlbp/artifacts/2025-02-21-2035_/esm2t68MUR50D_LightAttention_sbxwfibrillationpeptidewaltzdb-train-valamypro27-testrandpadded10x_stats.csv\n",
      "s3://nnedl-core-prd-eu-central-1-curated/mlops/378/f46088299bb24cd4b9702026bc3bc197/artifacts\n",
      "\u001b[34mSystem information\u001b[0m: Linux #70~20.04.1-Ubuntu SMP Fri Jun 14 15:42:13 UTC 2024\n",
      "\u001b[34mPython version\u001b[0m: 3.10.14\n",
      "\u001b[34mMLflow version\u001b[0m: 2.20.2\n",
      "\u001b[34mMLflow module location\u001b[0m: /nfs_home/users/sbxw/mambaforge/envs/mlbp/lib/python3.10/site-packages/mlflow/__init__.py\n",
      "\u001b[34mTracking URI\u001b[0m: https://datalab.corp.novocorp.net/mlflow/\n",
      "\u001b[34mRegistry URI\u001b[0m: https://datalab.corp.novocorp.net/mlflow/\n",
      "\u001b[34mActive experiment ID\u001b[0m: 378\n",
      "\u001b[34mActive run ID\u001b[0m: f46088299bb24cd4b9702026bc3bc197\n",
      "\u001b[34mActive run artifact URI\u001b[0m: s3://nnedl-core-prd-eu-central-1-curated/mlops/378/f46088299bb24cd4b9702026bc3bc197/artifacts\n",
      "\u001b[34mMLflow environment variables\u001b[0m: \n",
      "  MLFLOW_EXPERIMENT_ID: 378\n",
      "  MLFLOW_TRACKING_URI: https://datalab.corp.novocorp.net/mlflow/\n",
      "\u001b[34mMLflow dependencies\u001b[0m: \n",
      "  Flask: 2.2.5\n",
      "  Jinja2: 3.1.4\n",
      "  aiohttp: 3.9.5\n",
      "  alembic: 1.13.1\n",
      "  boto3: 1.36.23\n",
      "  botocore: 1.36.23\n",
      "  docker: 7.0.0\n",
      "  graphene: 3.3\n",
      "  gunicorn: 22.0.0\n",
      "  markdown: 3.6\n",
      "  matplotlib: 3.9.0\n",
      "  mlflow-skinny: 2.20.2\n",
      "  numpy: 1.26.4\n",
      "  pandas: 2.2.2\n",
      "  pyarrow: 15.0.2\n",
      "  scikit-learn: 1.4.2\n",
      "  scipy: 1.13.0\n",
      "  sqlalchemy: 2.0.30\n",
      "  virtualenv: 20.26.2\n",
      "None\n",
      "üèÉ View run  at: https://datalab.corp.novocorp.net/mlflow/#/experiments/378/runs/f46088299bb24cd4b9702026bc3bc197\n",
      "üß™ View experiment at: https://datalab.corp.novocorp.net/mlflow/#/experiments/378\n"
     ]
    }
   ],
   "source": [
    "%env AWS_ACCESS_KEY_ID=ASIATIJCHR3KA5YYSX4C\n",
    "%env AWS_SECRET_ACCESS_KEY=aPDRW7A6aUdgjnE2CdQeYG2IpZseMrimkIxc0H//\n",
    "%env AWS_SESSION_TOKEN=FwoGZXIvYXdzEMX//////////wEaDONh6B2GwAQwnkGFRSL0AwI0ymgCmmLalzZXga+CfvhC0RiboEHABvkZiIl6GOVwtQtrORvwMGFLYd5RwDFo+fKXDl5P3zXzI0hnN2nHWf9e+jNJ1wZVVr7JEmw1XZwZn7zyOMG0skT8+BYhtkkZPYUhZB+DPOrrszHfomSSbBuox+/5P/7M492NM2zMnLRPomrOHsCMpc5rTlpv2Qp/zMgP0wKud0NJLjgq46dZkJ7rr7STpYwqc3x+gQ0peDIDGWqtdgeX75v74lpSCBgLU1YwmhUFBBenqDWxFPnYZ+81Q8DAuwtGFABQAUHScu04lM352nNNDTM21nGW50KMXqubIFyBvNcwP7hK61HcxvDZtdXkOc0o/Rg/oVkfa3INcmwV3P8g8qsjmrWhWyfCi3zeXJmH4QJl4rksNLCPMNugzkljoFOxhXFW4dzcfjk/pIZ2RohVcbwsiVHpwR9SXVM+0YzFE2MYSSUomqt5ahlxuUyK2IAJRvggiGOlSBN0T3ADN45y0U+JIFpl92MoIGkaW6Tr0RNT8eIOEGPzBB4g9FILg+CfYT1tMPaVJmlKGkRY+/vJkaE3h4DelnO49JhB1wRJgdtwZlBuFgqRRAPatgbZwhG79EwkmwTTXd5i5AxMeqQymz8jVurFoMBfALEuASskEoLoZIIc65PA+n0xz422KLCh470GMpQBMYrXpVze1m5G2VeOYzklnn6hsbiLu63zI7T4XX5GLExc4eoffUYBO4hlZAvEKYKJoR1Rx+iNlFz2RoQNQAHbfydjTrp7srnbSTGcwtJP3pyxxuqwXIHpWw0wHWx0mAuxWrujzsSyReGInQd+bDpRYsHUTZBd7aHDPrUK7ctcczNzIiVwgFD8g1hroB4ZCAucGRTjjw==\n",
    "\n",
    "repo_dir = '/novo/projects/departments/cdd/molecular_ai/sbxw/repos/ML-BP-Domino'\n",
    "conda_env_name = 'mlbp'\n",
    "\n",
    "# Create command (single set of params)\n",
    "cmd = [\n",
    "    f\"/nfs_home/users/sbxw/mambaforge/condabin/conda run --no-capture-output -n {conda_env_name} python\",\n",
    "    f\"{repo_dir}/src/cli/training.py\",\n",
    "    \"mlflow=datalab\", \"persistence=lovelace\",\n",
    "    \"dataset.use_predefined_split=true\",\n",
    "    \"dataset.data_name=sbxw_fibrillation_peptide_waltzdb-train-val_amypro27-test_randpadded10x\", \"dataset.task=classification_binary\", \n",
    "    \"dataset.residue_prediction_labels=res_value_bool\",\n",
    "    \"embedder=esm2_t6_8M\",\"embedder.mean_pool=false\",\n",
    "    \"dimred=noreduction\",\n",
    "    \"predictor=lightattention\", \"predictor.residue_prediction_mode=true\",\n",
    "    \"predictor.hparams.kernel_size=3\", \"predictor.hparams.max_epochs=10\", \"predictor.hparams.patience=200\",\n",
    "    \"predictor.hparams.batch_size=1000\", \"predictor.hparams.learning_rate=0.0005\",\n",
    "    \"mlflow.experiment_name=ML-BP-Domino\",\n",
    "    \"plots.generate_plots=false\",\n",
    "]\n",
    "command_str = \" \".join(cmd)\n",
    "print(command_str)\n",
    "!PYTHONPATH=repo_dir; $command_str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e0ada933-b80b-4db9-9c3d-5cecbd809870",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/nfs_home/users/sbxw/mambaforge/condabin/conda run --no-capture-output -n mlbp python /novo/projects/departments/cdd/molecular_ai/sbxw/repos/ML-BP-Domino/src/cli/training.py mlflow=datalab persistence=lovelace dataset.use_predefined_split=true dataset.data_name=sbxw_fibrillation_peptide_waltz_aggreprot_split0 dataset.task=classification_binary embedder=anupp embedder.mean_pool=false dimred=noreduction predictor=lstm predictor.hparams.max_epochs=10 predictor.hparams.patience=1000 predictor.hparams.batch_size=1000 predictor.hparams.learning_rate=0.001 mlflow.experiment_name=ML-BP-Domino plots.generate_plots=false\n",
      "2025-02-21 20:38:45.776462: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2025-02-21 20:38:45.776506: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2025-02-21 20:38:45.778018: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2025-02-21 20:38:45.785473: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2025-02-21 20:38:49.436784: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "[2025-02-21 20:39:01,324][__main__][INFO] - Workflow configuration:\n",
      "\n",
      "general:\n",
      "  run_mode: train\n",
      "  abs_repo_path: null\n",
      "  composite_model_name: null\n",
      "  composite_model_path: null\n",
      "  precomputed_embeddings_path: null\n",
      "  random_state: 42\n",
      "dataset:\n",
      "  data_name: sbxw_fibrillation_peptide_waltz_aggreprot_split0\n",
      "  add_data_columns: false\n",
      "  data_columns_dimred: false\n",
      "  data_columns_standard: false\n",
      "  group_column: null\n",
      "  data_scaler: RobustScaler\n",
      "  target_scaling: null\n",
      "  rbf_encoder: RadialBasisFunctionGaussian\n",
      "  rbf_n_kernels: 10\n",
      "  task: classification_binary\n",
      "  use_predefined_split: true\n",
      "  use_sample_weights: false\n",
      "  residue_prediction_labels: null\n",
      "  data_split_column: data_split\n",
      "  data_split:\n",
      "    train: 0.8\n",
      "    val: 0.0\n",
      "    test: 0.2\n",
      "embedder:\n",
      "  class_name: ANuPP\n",
      "  model_name: anupp\n",
      "  standardize: false\n",
      "  scalar_type: null\n",
      "  model_path: null\n",
      "  hparams: null\n",
      "  batch_size_scaling_factor: null\n",
      "  mean_pool: false\n",
      "dimred:\n",
      "  class_name: NoReduction\n",
      "  transform_name: null\n",
      "  fraction_variance_explained: null\n",
      "predictor:\n",
      "  class_name: LSTM\n",
      "  model_name: null\n",
      "  model_type: classification_binary\n",
      "  mem_per_job: null\n",
      "  residue_prediction_mode: false\n",
      "  hparams:\n",
      "    dropout: 0.25\n",
      "    learning_rate: 0.001\n",
      "    batch_size: 1000\n",
      "    max_epochs: 10\n",
      "    patience: 1000\n",
      "    optimal_cutoff: 0.5\n",
      "persistence:\n",
      "  type: lovelace\n",
      "  data_root_folder: /novo/projects/departments/cdd/molecular_ai/mlbp/data\n",
      "  artifacts_root_folder: /novo/projects/departments/cdd/molecular_ai/mlbp/artifacts\n",
      "  training_data: static_input_data\n",
      "  pretrained_weights: static_pretrained_weights\n",
      "mlflow:\n",
      "  tracking_uri: https://datalab.corp.novocorp.net/mlflow/\n",
      "  experiment_name: ML-BP-Domino\n",
      "plots:\n",
      "  generate_plots: false\n",
      "\n",
      "[2025-02-21 20:39:01,326][src.model.dimred][INFO] - Load class (NoReduction): NoReduction\n",
      "[2025-02-21 20:39:01,326][src.model.abstract_components][INFO] - Load class (DimRed Model): NoReduction\n",
      "[2025-02-21 20:39:01,326][src.model.predictors][INFO] - Load class (LSTM): LSTM\n",
      "[2025-02-21 20:39:01,326][src.model.abstract_components][INFO] - Load class (TorchPredictorModel): LSTM\n",
      "[2025-02-21 20:39:01,326][src.model.abstract_components][INFO] - Load class (Predictor Model): LSTM\n",
      "[2025-02-21 20:39:01,326][src.model.composite_model][INFO] - Composite model name: anupp_LSTM_sbxwfibrillationpeptidewaltzaggreprotsplit0\n",
      "[2025-02-21 20:39:01,327][src.model.composite_model][INFO] - Initialized model: anupp_LSTM_sbxwfibrillationpeptidewaltzaggreprotsplit0 in run_mode = train\n",
      "[2025-02-21 20:39:01,335][src.helpers.dataset][INFO] - Loading file: /novo/projects/departments/cdd/molecular_ai/mlbp/data/static_input_data/sbxw_fibrillation_peptide_waltz_aggreprot_split0.csv\n",
      "[2025-02-21 20:39:01,336][src.helpers.dataset][INFO] - Using group_column \"None\".\n",
      "[2025-02-21 20:39:01,336][src.helpers.dataset][INFO] - No additional data columns found while parsing.\n",
      "[2025-02-21 20:39:01,337][src.helpers.dataset][INFO] - Select data according to predetermined splits in the dataframe, train (N = 1007), validation (N = 252), test (N = 140)\n",
      "[2025-02-21 20:39:01,338][src.helpers.dataset][INFO] - Loaded columns: {}\n",
      "[2025-02-21 20:39:01,338][src.helpers.mlflow_helpers][INFO] - Setting up MLflow...\n",
      "[2025-02-21 20:39:01,339][src.helpers.mlflow_helpers][INFO] - Experiment name: ML-BP-Domino\n",
      "[2025-02-21 20:39:01,339][src.helpers.mlflow_helpers][INFO] - Setting MLflow tracking URI to https://datalab.corp.novocorp.net/mlflow/\n",
      "[2025-02-21 20:39:02,330][src.helpers.mlflow_helpers][INFO] - Setting MLflow experiment to ML-BP-Domino\n",
      "[2025-02-21 20:39:03,424][__main__][INFO] - Compute embeddings on-the-fly and train model\n",
      "[2025-02-21 20:39:03,425][src.model.abstract_components][INFO] - Load class (AAFeaturizer): ANuPP\n",
      "[2025-02-21 20:39:03,425][src.model.abstract_components][INFO] - Load class (Embedder Model): ANuPP\n",
      "[2025-02-21 20:39:03,457][src.model.abstract_components][INFO] - Final results len: 1007\n",
      "[2025-02-21 20:39:03,458][src.model.composite_model][INFO] - Residue embeddings\n",
      "[2025-02-21 20:39:03,466][src.model.abstract_components][INFO] - Final results len: 252\n",
      "[2025-02-21 20:39:03,466][src.model.scalers][INFO] - Fitted scaler: PassThroughScaler\n",
      "[2025-02-21 20:39:03,466][src.model.scalers][INFO] - Before standardization - min: False, max: True\n",
      "[2025-02-21 20:39:03,466][src.model.scalers][INFO] - After standardization - min: False, max: True\n",
      "[2025-02-21 20:39:03,466][src.model.scalers][INFO] - Before standardization - min: False, max: True\n",
      "[2025-02-21 20:39:03,466][src.model.scalers][INFO] - After standardization - min: False, max: True\n",
      "[2025-02-21 20:39:03,466][src.model.scalers][INFO] - Before standardization - min: False, max: True\n",
      "[2025-02-21 20:39:03,466][src.model.scalers][INFO] - After standardization - min: False, max: True\n",
      "/nfs_home/users/sbxw/mambaforge/envs/mlbp/lib/python3.10/site-packages/lightning/fabric/plugins/environments/slurm.py:204: The `srun` command is available on your system but is not used. HINT: If your intention is to run Lightning on SLURM, prepend your python command with `srun` like so: srun python /novo/projects/departments/cdd/molecular_ai/sbxw/rep ...\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/nfs_home/users/sbxw/mambaforge/envs/mlbp/lib/python3.10/site-packages/lightning/fabric/plugins/environments/slurm.py:204: The `srun` command is available on your system but is not used. HINT: If your intention is to run Lightning on SLURM, prepend your python command with `srun` like so: srun python /novo/projects/departments/cdd/molecular_ai/sbxw/rep ...\n",
      "[2025-02-21 20:39:05,190][pytorch_lightning.utilities.rank_zero][INFO] - You are using a CUDA device ('NVIDIA L4') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name     | Type       | Params | Mode \n",
      "------------------------------------------------\n",
      "0 | sigmoid  | Sigmoid    | 0      | train\n",
      "1 | softmax  | Softmax    | 0      | train\n",
      "2 | layers   | Sequential | 38.0 K | train\n",
      "3 | linear1  | Linear     | 14.2 K | train\n",
      "4 | LSTM1    | LSTM       | 230 K  | train\n",
      "5 | LSTM2    | LSTM       | 173 K  | train\n",
      "6 | loss_fxn | BCELoss    | 0      | train\n",
      "------------------------------------------------\n",
      "456 K     Trainable params\n",
      "0         Non-trainable params\n",
      "456 K     Total params\n",
      "1.825     Total estimated model params size (MB)\n",
      "14        Modules in train mode\n",
      "0         Modules in eval mode\n",
      "/nfs_home/users/sbxw/mambaforge/envs/mlbp/lib/python3.10/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:424: The 'val_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=7` in the `DataLoader` to improve performance.\n",
      "/nfs_home/users/sbxw/mambaforge/envs/mlbp/lib/python3.10/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:424: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=7` in the `DataLoader` to improve performance.\n",
      "[2025-02-21 20:39:09,938][botocore.credentials][INFO] - Found credentials in environment variables.\n",
      "[2025-02-21 20:39:46,467][pytorch_lightning.utilities.rank_zero][INFO] - `Trainer.fit` stopped: `max_epochs=10` reached.\n",
      "üèÉ View run  at: https://datalab.corp.novocorp.net/mlflow/#/experiments/378/runs/578217577a7343c19c2b533a0b4f2400\n",
      "üß™ View experiment at: https://datalab.corp.novocorp.net/mlflow/#/experiments/378\n",
      "\u001b[31m2025/02/21 20:40:13 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\u001b[0m\n",
      "[2025-02-21 20:40:17,340][src.model.abstract_components][INFO] - MODEL STOPPED BY EARLY STOPPER AT EPOCH 0\n",
      "[2025-02-21 20:40:17,340][src.model.abstract_components][INFO] - BEST MODEL VALIDATION LOSS IS 0.6836018562316895\n",
      "[2025-02-21 20:40:17,340][src.model.abstract_components][INFO] - BEST MODEL SAVED AT /novo/projects/departments/cdd/public/users/ehec/sbxw_files_2/378/578217577a7343c19c2b533a0b4f2400/checkpoints/epoch=9-step=20.ckpt\n",
      "[2025-02-21 20:40:17,340][src.model.abstract_components][INFO] - FINAL MODEL SAVED AT None\n",
      "[2025-02-21 20:40:17,615][src.model.predictors][INFO] - Moving embeddings to device: cuda\n",
      "[2025-02-21 20:40:17,711][src.model.predictors][INFO] - Optimal cutoff is: 0.47000000000000003 with MCC: 0.08067301388296585\n",
      "[2025-02-21 20:40:17,712][src.model.predictors][INFO] - Moving embeddings to device: cuda\n",
      "[2025-02-21 20:40:17,714][src.model.predictors][INFO] - Moving embeddings to device: cuda\n",
      "[2025-02-21 20:40:17,715][src.model.scalers][INFO] - Before standardization - min: False, max: True\n",
      "[2025-02-21 20:40:17,715][src.model.scalers][INFO] - After standardization - min: False, max: True\n",
      "[2025-02-21 20:40:17,715][src.model.scalers][INFO] - Before standardization - min: False, max: True\n",
      "[2025-02-21 20:40:17,715][src.model.scalers][INFO] - After standardization - min: False, max: True\n",
      "[2025-02-21 20:40:17,715][src.model.composite_model][INFO] - This is the updated predictor name: lstm_dropout_0.25_learning_rate_0.001_batch_size_1000_max_epochs_10_patience_1000_optimal_cutoff_0.47000000000000003\n",
      "[2025-02-21 20:40:17,716][src.model.composite_model][INFO] - Composite model name: anupp_LSTM_sbxwfibrillationpeptidewaltzaggreprotsplit0\n",
      "[2025-02-21 20:40:17,716][src.model.composite_model][INFO] - Best model is: dropout_0.25_learning_rate_0.001_batch_size_1000_max_epochs_10_patience_1000_optimal_cutoff_0.47000000000000003\n",
      "[2025-02-21 20:40:17,716][src.model.composite_model][INFO] - Moving to test mode\n",
      "[2025-02-21 20:40:17,716][src.model.composite_model][INFO] - Composite model name: anupp_LSTM_sbxwfibrillationpeptidewaltzaggreprotsplit0\n",
      "[2025-02-21 20:40:17,716][src.model.composite_model][INFO] - Saving model: anupp_LSTM_sbxwfibrillationpeptidewaltzaggreprotsplit0\n",
      "<RunInfo: artifact_uri='s3://nnedl-core-prd-eu-central-1-curated/mlops/378/578217577a7343c19c2b533a0b4f2400/artifacts', end_time=None, experiment_id='378', lifecycle_stage='active', run_id='578217577a7343c19c2b533a0b4f2400', run_name='', run_uuid='578217577a7343c19c2b533a0b4f2400', start_time=1740170342598, status='RUNNING', user_id='sbxw'>\n",
      "[2025-02-21 20:40:19,279][src.model.abstract_components][INFO] - Final results len: 140\n",
      "[2025-02-21 20:40:19,279][src.model.composite_model][INFO] - Residue embeddings\n",
      "[2025-02-21 20:40:19,279][src.model.predictors][INFO] - Moving embeddings to device: cuda\n",
      "[2025-02-21 20:40:19,280][src.model.scalers][INFO] - Before standardization - min: False, max: True\n",
      "[2025-02-21 20:40:19,280][src.model.scalers][INFO] - After standardization - min: False, max: True\n",
      "sequences: (1007,)\n",
      "sequence_embeddings: 1007\n",
      "predictions: (1007,)\n",
      "predictions_scaled: (1007,)\n",
      "data_split: train\n",
      "labels: (1007,)\n",
      "predictions_probability: (1007,)\n",
      "residue_level_prediction: False\n",
      "sequences: (252,)\n",
      "sequence_embeddings: 252\n",
      "predictions: (252,)\n",
      "predictions_scaled: (252,)\n",
      "data_split: val\n",
      "labels: (252,)\n",
      "predictions_probability: (252,)\n",
      "residue_level_prediction: False\n",
      "sequences: (140,)\n",
      "sequence_embeddings: 140\n",
      "predictions: (140,)\n",
      "predictions_scaled: (140,)\n",
      "data_split: test\n",
      "labels: (140,)\n",
      "predictions_probability: (140,)\n",
      "residue_level_prediction: False\n",
      "[2025-02-21 20:40:20,616][src.model.composite_model][INFO] - Composite model name: anupp_LSTM_sbxwfibrillationpeptidewaltzaggreprotsplit0\n",
      "[2025-02-21 20:40:21,346][__main__][INFO] - Done!\n",
      "run_id: 578217577a7343c19c2b533a0b4f2400\n",
      "artifacts: ['model/MLmodel', 'model/checkpoints', 'model/conda.yaml', 'model/data', 'model/python_env.yaml', 'model/requirements.txt']\n",
      "params: {'general.run_mode': 'train', 'general.abs_repo_path': 'None', 'general.composite_model_name': 'anupp_LSTM_sbxwfibrillationpeptidewaltzaggreprotsplit0', 'general.composite_model_path': 'None', 'general.precomputed_embeddings_path': 'None', 'general.random_state': '42', 'dataset.data_name': 'sbxw_fibrillation_peptide_waltz_aggreprot_split0', 'dataset.add_data_columns': 'False', 'dataset.data_columns_dimred': 'False', 'dataset.data_columns_standard': 'False', 'dataset.group_column': 'None', 'dataset.data_scaler': 'RobustScaler', 'dataset.target_scaling': 'None', 'model_type': 'classification_binary', 'epochs': '10', 'optimizer_name': 'SGD', 'lr': '0.001', 'momentum': '0', 'dampening': '0', 'weight_decay': '0', 'nesterov': 'False', 'maximize': 'False', 'foreach': 'None', 'differentiable': 'False', 'fused': 'None', 'embeddings_dim': '36', 'output_dim': '1', 'dropout': '0.25', 'learning_rate': '0.001', 'dataset.rbf_encoder': 'RadialBasisFunctionGaussian', 'dataset.rbf_n_kernels': '10', 'dataset.task': 'classification_binary', 'dataset.use_predefined_split': 'True', 'dataset.use_sample_weights': 'False', 'dataset.residue_prediction_labels': 'None', 'dataset.data_split_column': 'data_split', 'dataset.data_split.train': '0.8', 'dataset.data_split.val': '0.0', 'dataset.data_split.test': '0.2', 'embedder.class_name': 'ANuPP', 'embedder.model_name': 'anupp', 'embedder.standardize': 'False', 'embedder.scalar_type': 'None', 'embedder.model_path': 'None', 'embedder.hparams': 'None', 'embedder.batch_size_scaling_factor': 'None', 'embedder.mean_pool': 'False', 'dimred.class_name': 'NoReduction', 'dimred.transform_name': 'None', 'dimred.fraction_variance_explained': 'None', 'predictor.class_name': 'LSTM', 'predictor.model_name': 'None', 'predictor.model_type': 'classification_binary', 'predictor.mem_per_job': 'None', 'predictor.residue_prediction_mode': 'False', 'predictor.hparams.dropout': '0.25', 'predictor.hparams.learning_rate': '0.001', 'predictor.hparams.batch_size': '1000', 'predictor.hparams.max_epochs': '10', 'predictor.hparams.patience': '1000', 'predictor.hparams.optimal_cutoff': '0.5', 'persistence.type': 'lovelace', 'persistence.data_root_folder': '/novo/projects/departments/cdd/molecular_ai/mlbp/data', 'persistence.artifacts_root_folder': '/novo/projects/departments/cdd/molecular_ai/mlbp/artifacts', 'persistence.training_data': 'static_input_data', 'persistence.pretrained_weights': 'static_pretrained_weights', 'mlflow.tracking_uri': 'https://datalab.corp.novocorp.net/mlflow/', 'mlflow.experiment_name': 'ML-BP-Domino', 'plots.generate_plots': 'False'}\n",
      "metrics: {'train.loss': 0.681490957736969, 'train.loss_epoch': 0.681490957736969, 'train.loss_step': 0.6672521829605103, 'val.loss': 0.6836018562316895, 'train.accuracy': 0.37835153922542203, 'train.precision': 0.35691318327974275, 'train.recall': 0.9275766016713092, 'train.specificity': 0.07407407407407407, 'train.f_score': 0.5154798761609907, 'train.matthews_corr_coef': 0.0030299803735492985, 'train.optimal_mcc': 0.04235856981715592, 'train.optimal_mcc_cutoff': 0.5, 'train.balanced_accuracy': 0.5008253378726917, 'train.roc_auc_score': 0.4870073764572372, 'val.loss_epoch': 0.6836018562316895, 'test.accuracy': 0.4357142857142857, 'test.precision': 0.392, 'test.recall': 0.9423076923076923, 'test.specificity': 0.13636363636363635, 'test.f_score': 0.5536723163841808, 'test.matthews_corr_coef': 0.1229019735598054, 'test.optimal_mcc': 0.13436724205839481, 'test.optimal_mcc_cutoff': 0.49, 'test.balanced_accuracy': 0.5393356643356644, 'test.roc_auc_score': 0.5572552447552448, 'val.loss_step': 0.6836018562316895, 'epoch': 9.0, 'val.accuracy': 0.4126984126984127, 'val.precision': 0.3898305084745763, 'val.recall': 0.9583333333333334, 'val.specificity': 0.07692307692307693, 'val.f_score': 0.5542168674698795, 'val.matthews_corr_coef': 0.07021340166337273, 'val.optimal_mcc': 0.11481740813509748, 'val.optimal_mcc_cutoff': 0.48, 'val.balanced_accuracy': 0.5176282051282052, 'val.roc_auc_score': 0.5611645299145298}\n",
      "tags: {'Mode': 'training'}\n",
      "results stored in /novo/projects/departments/cdd/molecular_ai/mlbp/artifacts/2025-02-21-2039_/anupp_LSTM_sbxwfibrillationpeptidewaltzaggreprotsplit0_stats.csv\n",
      "s3://nnedl-core-prd-eu-central-1-curated/mlops/378/578217577a7343c19c2b533a0b4f2400/artifacts\n",
      "\u001b[34mSystem information\u001b[0m: Linux #70~20.04.1-Ubuntu SMP Fri Jun 14 15:42:13 UTC 2024\n",
      "\u001b[34mPython version\u001b[0m: 3.10.14\n",
      "\u001b[34mMLflow version\u001b[0m: 2.20.2\n",
      "\u001b[34mMLflow module location\u001b[0m: /nfs_home/users/sbxw/mambaforge/envs/mlbp/lib/python3.10/site-packages/mlflow/__init__.py\n",
      "\u001b[34mTracking URI\u001b[0m: https://datalab.corp.novocorp.net/mlflow/\n",
      "\u001b[34mRegistry URI\u001b[0m: https://datalab.corp.novocorp.net/mlflow/\n",
      "\u001b[34mActive experiment ID\u001b[0m: 378\n",
      "\u001b[34mActive run ID\u001b[0m: 578217577a7343c19c2b533a0b4f2400\n",
      "\u001b[34mActive run artifact URI\u001b[0m: s3://nnedl-core-prd-eu-central-1-curated/mlops/378/578217577a7343c19c2b533a0b4f2400/artifacts\n",
      "\u001b[34mMLflow environment variables\u001b[0m: \n",
      "  MLFLOW_EXPERIMENT_ID: 378\n",
      "  MLFLOW_TRACKING_URI: https://datalab.corp.novocorp.net/mlflow/\n",
      "\u001b[34mMLflow dependencies\u001b[0m: \n",
      "  Flask: 2.2.5\n",
      "  Jinja2: 3.1.4\n",
      "  aiohttp: 3.9.5\n",
      "  alembic: 1.13.1\n",
      "  boto3: 1.36.23\n",
      "  botocore: 1.36.23\n",
      "  docker: 7.0.0\n",
      "  graphene: 3.3\n",
      "  gunicorn: 22.0.0\n",
      "  markdown: 3.6\n",
      "  matplotlib: 3.9.0\n",
      "  mlflow-skinny: 2.20.2\n",
      "  numpy: 1.26.4\n",
      "  pandas: 2.2.2\n",
      "  pyarrow: 15.0.2\n",
      "  scikit-learn: 1.4.2\n",
      "  scipy: 1.13.0\n",
      "  sqlalchemy: 2.0.30\n",
      "  virtualenv: 20.26.2\n",
      "None\n",
      "üèÉ View run  at: https://datalab.corp.novocorp.net/mlflow/#/experiments/378/runs/578217577a7343c19c2b533a0b4f2400\n",
      "üß™ View experiment at: https://datalab.corp.novocorp.net/mlflow/#/experiments/378\n"
     ]
    }
   ],
   "source": [
    "repo_dir = '/novo/projects/departments/cdd/molecular_ai/sbxw/repos/ML-BP-Domino'\n",
    "conda_env_name = 'mlbp'\n",
    "\n",
    "# Create command (single set of params)\n",
    "cmd = [\n",
    "    f\"/nfs_home/users/sbxw/mambaforge/condabin/conda run --no-capture-output -n {conda_env_name} python\",\n",
    "    f\"{repo_dir}/src/cli/training.py\",\n",
    "    \"mlflow=datalab\", \"persistence=lovelace\",\n",
    "    \"dataset.use_predefined_split=true\",\n",
    "    \"dataset.data_name=sbxw_fibrillation_peptide_waltz_aggreprot_split0\", \"dataset.task=classification_binary\", \n",
    "    \"embedder=anupp\",\"embedder.mean_pool=false\",\n",
    "    \"dimred=noreduction\",\n",
    "    \"predictor=lstm\", \n",
    "    \"predictor.hparams.max_epochs=10\",\"predictor.hparams.patience=1000\",\n",
    "    \"predictor.hparams.batch_size=1000\", \"predictor.hparams.learning_rate=0.001\",\n",
    "    \"mlflow.experiment_name=ML-BP-Domino\",\n",
    "    \"plots.generate_plots=false\",\n",
    "]\n",
    "\n",
    "command_str = \" \".join(cmd)\n",
    "print(command_str)\n",
    "!PYTHONPATH=repo_dir; $command_str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a9947430-c4fe-4f90-9df5-22220b17445f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.20.2\n"
     ]
    }
   ],
   "source": [
    "print(mlflow.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "def4a5ad-3352-4dc7-8bde-517eeeb11b66",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "JSONDecodeError",
     "evalue": "Expecting value: line 4 column 1 (char 3)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mJSONDecodeError\u001b[0m                           Traceback (most recent call last)",
      "File \u001b[0;32m/nfs_home/users/sbxw/mambaforge/envs/mlbp/lib/python3.10/site-packages/requests/models.py:974\u001b[0m, in \u001b[0;36mResponse.json\u001b[0;34m(self, **kwargs)\u001b[0m\n\u001b[1;32m    973\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 974\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mcomplexjson\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mloads\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtext\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    975\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m JSONDecodeError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    976\u001b[0m     \u001b[38;5;66;03m# Catch JSON-related errors and raise as requests.JSONDecodeError\u001b[39;00m\n\u001b[1;32m    977\u001b[0m     \u001b[38;5;66;03m# This aliases json.JSONDecodeError and simplejson.JSONDecodeError\u001b[39;00m\n",
      "File \u001b[0;32m/nfs_home/users/sbxw/mambaforge/envs/mlbp/lib/python3.10/json/__init__.py:346\u001b[0m, in \u001b[0;36mloads\u001b[0;34m(s, cls, object_hook, parse_float, parse_int, parse_constant, object_pairs_hook, **kw)\u001b[0m\n\u001b[1;32m    343\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\u001b[38;5;28mcls\u001b[39m \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m object_hook \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m\n\u001b[1;32m    344\u001b[0m         parse_int \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m parse_float \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m\n\u001b[1;32m    345\u001b[0m         parse_constant \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m object_pairs_hook \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m kw):\n\u001b[0;32m--> 346\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_default_decoder\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[43ms\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    347\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mcls\u001b[39m \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m/nfs_home/users/sbxw/mambaforge/envs/mlbp/lib/python3.10/json/decoder.py:337\u001b[0m, in \u001b[0;36mJSONDecoder.decode\u001b[0;34m(self, s, _w)\u001b[0m\n\u001b[1;32m    333\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Return the Python representation of ``s`` (a ``str`` instance\u001b[39;00m\n\u001b[1;32m    334\u001b[0m \u001b[38;5;124;03mcontaining a JSON document).\u001b[39;00m\n\u001b[1;32m    335\u001b[0m \n\u001b[1;32m    336\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m--> 337\u001b[0m obj, end \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mraw_decode\u001b[49m\u001b[43m(\u001b[49m\u001b[43ms\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43midx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m_w\u001b[49m\u001b[43m(\u001b[49m\u001b[43ms\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mend\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    338\u001b[0m end \u001b[38;5;241m=\u001b[39m _w(s, end)\u001b[38;5;241m.\u001b[39mend()\n",
      "File \u001b[0;32m/nfs_home/users/sbxw/mambaforge/envs/mlbp/lib/python3.10/json/decoder.py:355\u001b[0m, in \u001b[0;36mJSONDecoder.raw_decode\u001b[0;34m(self, s, idx)\u001b[0m\n\u001b[1;32m    354\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[0;32m--> 355\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m JSONDecodeError(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExpecting value\u001b[39m\u001b[38;5;124m\"\u001b[39m, s, err\u001b[38;5;241m.\u001b[39mvalue) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    356\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m obj, end\n",
      "\u001b[0;31mJSONDecodeError\u001b[0m: Expecting value: line 4 column 1 (char 3)",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mJSONDecodeError\u001b[0m                           Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[19], line 5\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmlflow\u001b[39;00m\n\u001b[1;32m      4\u001b[0m response \u001b[38;5;241m=\u001b[39m requests\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhttps://datalab.corp.novocorp.net/mlflow:100.64.1.2:443/version\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m----> 5\u001b[0m server_version \u001b[38;5;241m=\u001b[39m \u001b[43mresponse\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mjson\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mversion\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m server_version \u001b[38;5;241m==\u001b[39m mlflow\u001b[38;5;241m.\u001b[39m__version__, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mClient and server versions do not match.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "File \u001b[0;32m/nfs_home/users/sbxw/mambaforge/envs/mlbp/lib/python3.10/site-packages/requests/models.py:978\u001b[0m, in \u001b[0;36mResponse.json\u001b[0;34m(self, **kwargs)\u001b[0m\n\u001b[1;32m    974\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m complexjson\u001b[38;5;241m.\u001b[39mloads(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtext, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    975\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m JSONDecodeError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    976\u001b[0m     \u001b[38;5;66;03m# Catch JSON-related errors and raise as requests.JSONDecodeError\u001b[39;00m\n\u001b[1;32m    977\u001b[0m     \u001b[38;5;66;03m# This aliases json.JSONDecodeError and simplejson.JSONDecodeError\u001b[39;00m\n\u001b[0;32m--> 978\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m RequestsJSONDecodeError(e\u001b[38;5;241m.\u001b[39mmsg, e\u001b[38;5;241m.\u001b[39mdoc, e\u001b[38;5;241m.\u001b[39mpos)\n",
      "\u001b[0;31mJSONDecodeError\u001b[0m: Expecting value: line 4 column 1 (char 3)"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import mlflow\n",
    "\n",
    "response = requests.get(\"https://datalab.corp.novocorp.net/mlflow:100.64.1.2:443/version\")\n",
    "server_version = response.json()['version']\n",
    "assert server_version == mlflow.__version__, \"Client and server versions do not match.\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6700587c-0f29-44a9-a230-fcaa6b9ba861",
   "metadata": {},
   "source": [
    "# Run test with pytorch reduction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "80f2b571-ff0d-4a25-9ea5-974fa352d8d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: AWS_ACCESS_KEY_ID=ASIATIJCHR3KA5YYSX4C\n",
      "env: AWS_SECRET_ACCESS_KEY=aPDRW7A6aUdgjnE2CdQeYG2IpZseMrimkIxc0H//\n",
      "env: AWS_SESSION_TOKEN=FwoGZXIvYXdzEMX//////////wEaDONh6B2GwAQwnkGFRSL0AwI0ymgCmmLalzZXga+CfvhC0RiboEHABvkZiIl6GOVwtQtrORvwMGFLYd5RwDFo+fKXDl5P3zXzI0hnN2nHWf9e+jNJ1wZVVr7JEmw1XZwZn7zyOMG0skT8+BYhtkkZPYUhZB+DPOrrszHfomSSbBuox+/5P/7M492NM2zMnLRPomrOHsCMpc5rTlpv2Qp/zMgP0wKud0NJLjgq46dZkJ7rr7STpYwqc3x+gQ0peDIDGWqtdgeX75v74lpSCBgLU1YwmhUFBBenqDWxFPnYZ+81Q8DAuwtGFABQAUHScu04lM352nNNDTM21nGW50KMXqubIFyBvNcwP7hK61HcxvDZtdXkOc0o/Rg/oVkfa3INcmwV3P8g8qsjmrWhWyfCi3zeXJmH4QJl4rksNLCPMNugzkljoFOxhXFW4dzcfjk/pIZ2RohVcbwsiVHpwR9SXVM+0YzFE2MYSSUomqt5ahlxuUyK2IAJRvggiGOlSBN0T3ADN45y0U+JIFpl92MoIGkaW6Tr0RNT8eIOEGPzBB4g9FILg+CfYT1tMPaVJmlKGkRY+/vJkaE3h4DelnO49JhB1wRJgdtwZlBuFgqRRAPatgbZwhG79EwkmwTTXd5i5AxMeqQymz8jVurFoMBfALEuASskEoLoZIIc65PA+n0xz422KLCh470GMpQBMYrXpVze1m5G2VeOYzklnn6hsbiLu63zI7T4XX5GLExc4eoffUYBO4hlZAvEKYKJoR1Rx+iNlFz2RoQNQAHbfydjTrp7srnbSTGcwtJP3pyxxuqwXIHpWw0wHWx0mAuxWrujzsSyReGInQd+bDpRYsHUTZBd7aHDPrUK7ctcczNzIiVwgFD8g1hroB4ZCAucGRTjjw==\n",
      "/nfs_home/users/sbxw/mambaforge/condabin/conda run --no-capture-output -n mlbp python /novo/projects/departments/cdd/molecular_ai/sbxw/repos/ML-BP-Domino/src/cli/training.py mlflow=datalab persistence=lovelace dataset.use_predefined_split=true dataset.data_name=sbxw_fibrillation_peptide_waltzdb-train-val_serrano-test_randpadded10x dataset.task=classification_binary embedder=esm2_t6_8M embedder.mean_pool=false dimred=noreduction predictor=lightattention predictor.hparams.kernel_size=1 predictor.hparams.max_epochs=10 predictor.hparams.patience=200 predictor.hparams.batch_size=1000 predictor.hparams.learning_rate=0.0005 predictor.hparams.reduction_mode=mean mlflow.experiment_name=ML-BP-Domino plots.generate_plots=false\n",
      "2025-02-22 00:57:40.137324: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2025-02-22 00:57:40.138327: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2025-02-22 00:57:40.282412: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2025-02-22 00:57:40.555454: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2025-02-22 00:57:45.343600: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "[2025-02-22 00:58:00,690][__main__][INFO] - Workflow configuration:\n",
      "\n",
      "general:\n",
      "  run_mode: train\n",
      "  abs_repo_path: null\n",
      "  composite_model_name: null\n",
      "  composite_model_path: null\n",
      "  precomputed_embeddings_path: null\n",
      "  random_state: 42\n",
      "dataset:\n",
      "  data_name: sbxw_fibrillation_peptide_waltzdb-train-val_serrano-test_randpadded10x\n",
      "  add_data_columns: false\n",
      "  data_columns_dimred: false\n",
      "  data_columns_standard: false\n",
      "  group_column: null\n",
      "  data_scaler: RobustScaler\n",
      "  target_scaling: null\n",
      "  rbf_encoder: RadialBasisFunctionGaussian\n",
      "  rbf_n_kernels: 10\n",
      "  task: classification_binary\n",
      "  use_predefined_split: true\n",
      "  use_sample_weights: false\n",
      "  residue_prediction_labels: null\n",
      "  data_split_column: data_split\n",
      "  data_split:\n",
      "    train: 0.8\n",
      "    val: 0.0\n",
      "    test: 0.2\n",
      "embedder:\n",
      "  class_name: ESM\n",
      "  model_name: esm2_t6_8M_UR50D\n",
      "  model_path: null\n",
      "  standardize: false\n",
      "  scalar_type: StandardScaler\n",
      "  hparams: null\n",
      "  n_copies: 1\n",
      "  chain_break: poly-gly-linker\n",
      "  buffer_scale_factor: 2.0\n",
      "  max_batch_size: 400\n",
      "  simple_batching: false\n",
      "  strict: true\n",
      "  verbose: false\n",
      "  mean_pool: false\n",
      "  output_hidden_states: false\n",
      "dimred:\n",
      "  class_name: NoReduction\n",
      "  transform_name: null\n",
      "  fraction_variance_explained: null\n",
      "predictor:\n",
      "  class_name: LightAttention\n",
      "  model_name: null\n",
      "  model_type: classification_binary\n",
      "  mem_per_job: null\n",
      "  residue_prediction_mode: false\n",
      "  hparams:\n",
      "    kernel_size: 1\n",
      "    dropout: 0.25\n",
      "    conv_dropout: 0.25\n",
      "    learning_rate: 0.0005\n",
      "    batch_size: 1000\n",
      "    max_epochs: 10\n",
      "    patience: 200\n",
      "    post_attention: mlp\n",
      "    conv1d_output_dim: -1\n",
      "    optimal_cutoff: 0.5\n",
      "    reduction_mode: mean\n",
      "persistence:\n",
      "  type: lovelace\n",
      "  data_root_folder: /novo/projects/departments/cdd/molecular_ai/mlbp/data\n",
      "  artifacts_root_folder: /novo/projects/departments/cdd/molecular_ai/mlbp/artifacts\n",
      "  training_data: static_input_data\n",
      "  pretrained_weights: static_pretrained_weights\n",
      "mlflow:\n",
      "  tracking_uri: https://datalab.corp.novocorp.net/mlflow/\n",
      "  experiment_name: ML-BP-Domino\n",
      "plots:\n",
      "  generate_plots: false\n",
      "\n",
      "[2025-02-22 00:58:00,692][src.model.dimred][INFO] - Load class (NoReduction): NoReduction\n",
      "[2025-02-22 00:58:00,693][src.model.abstract_components][INFO] - Load class (DimRed Model): NoReduction\n",
      "[2025-02-22 00:58:00,693][src.model.predictors][INFO] - Load class (LightAttention): LightAttention\n",
      "[2025-02-22 00:58:00,693][src.model.abstract_components][INFO] - Load class (TorchPredictorModel): LightAttention\n",
      "[2025-02-22 00:58:00,693][src.model.abstract_components][INFO] - Load class (Predictor Model): LightAttention\n",
      "[2025-02-22 00:58:00,693][src.model.composite_model][INFO] - Composite model name: esm2t68MUR50D_LightAttention_sbxwfibrillationpeptidewaltzdb-train-valserrano-testrandpadded10x\n",
      "[2025-02-22 00:58:00,694][src.model.composite_model][INFO] - Initialized model: esm2t68MUR50D_LightAttention_sbxwfibrillationpeptidewaltzdb-train-valserrano-testrandpadded10x in run_mode = train\n",
      "[2025-02-22 00:58:00,717][src.helpers.dataset][INFO] - Loading file: /novo/projects/departments/cdd/molecular_ai/mlbp/data/static_input_data/sbxw_fibrillation_peptide_waltzdb-train-val_serrano-test_randpadded10x.csv\n",
      "[2025-02-22 00:58:00,718][src.helpers.dataset][INFO] - Using group_column \"None\".\n",
      "[2025-02-22 00:58:00,718][src.helpers.dataset][INFO] - No additional data columns found while parsing.\n",
      "[2025-02-22 00:58:00,727][src.helpers.dataset][INFO] - Select data according to predetermined splits in the dataframe, train (N = 11220), validation (N = 2770), test (N = 248)\n",
      "[2025-02-22 00:58:00,727][src.helpers.dataset][INFO] - Loaded columns: {}\n",
      "[2025-02-22 00:58:00,729][src.helpers.mlflow_helpers][INFO] - Setting up MLflow...\n",
      "[2025-02-22 00:58:00,729][src.helpers.mlflow_helpers][INFO] - Experiment name: ML-BP-Domino\n",
      "[2025-02-22 00:58:00,730][src.helpers.mlflow_helpers][INFO] - Setting MLflow tracking URI to https://datalab.corp.novocorp.net/mlflow/\n",
      "[2025-02-22 00:58:01,857][src.helpers.mlflow_helpers][INFO] - Setting MLflow experiment to ML-BP-Domino\n",
      "[2025-02-22 00:58:02,543][__main__][INFO] - <RunInfo: artifact_uri='s3://nnedl-core-prd-eu-central-1-curated/mlops/378/59c1e0fac1b64093baae3404ce223057/artifacts', end_time=None, experiment_id='378', lifecycle_stage='active', run_id='59c1e0fac1b64093baae3404ce223057', run_name='', run_uuid='59c1e0fac1b64093baae3404ce223057', start_time=1740185882285, status='RUNNING', user_id='sbxw'>\n",
      "[2025-02-22 00:58:03,251][__main__][INFO] - Compute embeddings on-the-fly and train model\n",
      "[2025-02-22 00:58:03,254][src.model.abstract_components][INFO] - Load class (LLMEmbedderModel): ESM\n",
      "[2025-02-22 00:58:03,254][src.model.abstract_components][INFO] - Load class (Embedder Model): ESM\n",
      "[2025-02-22 00:58:03,254][src.model.embedders][INFO] - Loading model: esm2_t6_8M_UR50D, will extract embeddings from 6-th layer\n",
      "Some weights of EsmModel were not initialized from the model checkpoint at facebook/esm2_t6_8M_UR50D and are newly initialized: ['esm.pooler.dense.bias', 'esm.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "[2025-02-22 00:58:04,215][src.model.embedders][INFO] - Moving model to cuda\n",
      "[2025-02-22 00:58:04,827][src.model.abstract_components][INFO] - Total memory: 23.58378496GB\n",
      "Memory already allocated: 0.031387648GB\n",
      "[2025-02-22 00:58:07,534][src.model.embedders][INFO] - Per-residue embeddings count: 11220\n",
      "[2025-02-22 00:58:07,534][src.model.composite_model][INFO] - Residue embeddings\n",
      "[2025-02-22 00:58:07,535][src.model.abstract_components][INFO] - Total memory: 23.58378496GB\n",
      "Memory already allocated: 0.039919616GB\n",
      "[2025-02-22 00:58:08,029][src.model.embedders][INFO] - Per-residue embeddings count: 2770\n",
      "[2025-02-22 00:58:08,029][src.model.scalers][INFO] - Fitted scaler: PassThroughScaler\n",
      "[2025-02-22 00:58:08,033][src.model.scalers][INFO] - Before standardization - min: 0.0, max: 1.0\n",
      "[2025-02-22 00:58:08,033][src.model.scalers][INFO] - After standardization - min: 0.0, max: 1.0\n",
      "[2025-02-22 00:58:08,033][src.model.scalers][INFO] - Before standardization - min: 0.0, max: 1.0\n",
      "[2025-02-22 00:58:08,033][src.model.scalers][INFO] - After standardization - min: 0.0, max: 1.0\n",
      "[2025-02-22 00:58:08,033][src.model.scalers][INFO] - Before standardization - min: 0.0, max: 1.0\n",
      "[2025-02-22 00:58:08,033][src.model.scalers][INFO] - After standardization - min: 0.0, max: 1.0\n",
      "/nfs_home/users/sbxw/mambaforge/envs/mlbp/lib/python3.10/site-packages/lightning/fabric/plugins/environments/slurm.py:204: The `srun` command is available on your system but is not used. HINT: If your intention is to run Lightning on SLURM, prepend your python command with `srun` like so: srun python /novo/projects/departments/cdd/molecular_ai/sbxw/rep ...\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/nfs_home/users/sbxw/mambaforge/envs/mlbp/lib/python3.10/site-packages/lightning/fabric/plugins/environments/slurm.py:204: The `srun` command is available on your system but is not used. HINT: If your intention is to run Lightning on SLURM, prepend your python command with `srun` like so: srun python /novo/projects/departments/cdd/molecular_ai/sbxw/rep ...\n",
      "[2025-02-22 00:58:09,456][pytorch_lightning.utilities.rank_zero][INFO] - You are using a CUDA device ('NVIDIA L4') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name                  | Type       | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | feature_convolution   | Conv1d     | 102 K  | train\n",
      "1 | attention_convolution | Conv1d     | 102 K  | train\n",
      "2 | softmax               | Softmax    | 0      | train\n",
      "3 | dropout               | Dropout    | 0      | train\n",
      "4 | sigmoid               | Sigmoid    | 0      | train\n",
      "5 | mlp                   | Sequential | 10.4 K | train\n",
      "6 | loss_fxn              | BCELoss    | 0      | train\n",
      "-------------------------------------------------------------\n",
      "215 K     Trainable params\n",
      "0         Non-trainable params\n",
      "215 K     Total params\n",
      "0.863     Total estimated model params size (MB)\n",
      "12        Modules in train mode\n",
      "0         Modules in eval mode\n",
      "/nfs_home/users/sbxw/mambaforge/envs/mlbp/lib/python3.10/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:424: The 'val_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=7` in the `DataLoader` to improve performance.\n",
      "/nfs_home/users/sbxw/mambaforge/envs/mlbp/lib/python3.10/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:424: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=7` in the `DataLoader` to improve performance.\n",
      "[2025-02-22 00:58:18,327][botocore.credentials][INFO] - Found credentials in environment variables.\n",
      "[2025-02-22 00:59:09,810][pytorch_lightning.utilities.rank_zero][INFO] - `Trainer.fit` stopped: `max_epochs=10` reached.\n",
      "üèÉ View run  at: https://datalab.corp.novocorp.net/mlflow/#/experiments/378/runs/59c1e0fac1b64093baae3404ce223057\n",
      "üß™ View experiment at: https://datalab.corp.novocorp.net/mlflow/#/experiments/378\n",
      "\u001b[31m2025/02/22 00:59:35 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\u001b[0m\n",
      "[2025-02-22 00:59:44,590][src.model.abstract_components][INFO] - MODEL STOPPED BY EARLY STOPPER AT EPOCH 0\n",
      "[2025-02-22 00:59:44,590][src.model.abstract_components][INFO] - BEST MODEL VALIDATION LOSS IS 0.6990423202514648\n",
      "[2025-02-22 00:59:44,590][src.model.abstract_components][INFO] - BEST MODEL SAVED AT /novo/projects/departments/cdd/public/users/ehec/sbxw_files_2/378/59c1e0fac1b64093baae3404ce223057/checkpoints/epoch=1-step=24.ckpt\n",
      "[2025-02-22 00:59:44,590][src.model.abstract_components][INFO] - FINAL MODEL SAVED AT None\n",
      "[2025-02-22 00:59:44,909][src.model.predictors][INFO] - Moving embeddings to device: cuda\n",
      "[2025-02-22 00:59:45,098][src.model.predictors][INFO] - Optimal cutoff is: 0.0 with MCC: 0.0\n",
      "[2025-02-22 00:59:45,229][src.model.predictors][INFO] - Moving embeddings to device: cuda\n",
      "[2025-02-22 00:59:45,377][src.model.predictors][INFO] - Moving embeddings to device: cuda\n",
      "[2025-02-22 00:59:45,403][src.model.composite_model][INFO] - This is the updated predictor name: lightattention_kernel_size_1_dropout_0.25_conv_dropout_0.25_learning_rate_0.0005_batch_size_1000_max_epochs_10_patience_200_post_attention_mlp_conv1d_output_dim_-1_optimal_cutoff_0.0_reduction_mode_mean\n",
      "[2025-02-22 00:59:45,403][src.model.composite_model][INFO] - Composite model name: esm2t68MUR50D_LightAttention_sbxwfibrillationpeptidewaltzdb-train-valserrano-testrandpadded10x\n",
      "[2025-02-22 00:59:45,403][src.model.composite_model][INFO] - Best model is: kernel_size_1_dropout_0.25_conv_dropout_0.25_learning_rate_0.0005_batch_size_1000_max_epochs_10_patience_200_post_attention_mlp_conv1d_output_dim_-1_optimal_cutoff_0.0_reduction_mode_mean\n",
      "[2025-02-22 00:59:45,404][src.model.composite_model][INFO] - Moving to test mode\n",
      "[2025-02-22 00:59:45,404][src.model.composite_model][INFO] - Composite model name: esm2t68MUR50D_LightAttention_sbxwfibrillationpeptidewaltzdb-train-valserrano-testrandpadded10x\n",
      "[2025-02-22 00:59:45,404][src.model.composite_model][INFO] - Saving model: esm2t68MUR50D_LightAttention_sbxwfibrillationpeptidewaltzdb-train-valserrano-testrandpadded10x\n",
      "<RunInfo: artifact_uri='s3://nnedl-core-prd-eu-central-1-curated/mlops/378/59c1e0fac1b64093baae3404ce223057/artifacts', end_time=None, experiment_id='378', lifecycle_stage='active', run_id='59c1e0fac1b64093baae3404ce223057', run_name='', run_uuid='59c1e0fac1b64093baae3404ce223057', start_time=1740185882285, status='RUNNING', user_id='sbxw'>\n",
      "[2025-02-22 01:00:07,042][src.model.abstract_components][INFO] - Total memory: 23.58378496GB\n",
      "Memory already allocated: 0.394783232GB\n",
      "[2025-02-22 01:00:07,112][src.model.embedders][INFO] - Per-residue embeddings count: 248\n",
      "[2025-02-22 01:00:07,112][src.model.composite_model][INFO] - Residue embeddings\n",
      "[2025-02-22 01:00:07,115][src.model.predictors][INFO] - Moving embeddings to device: cuda\n",
      "sequences: (11220,)\n",
      "sequence_embeddings: 11220\n",
      "data_split: train\n",
      "labels: (11220,)\n",
      "predictions_probability: (11220,)\n",
      "residue_level_prediction: False\n",
      "sequences: (2770,)\n",
      "sequence_embeddings: 2770\n",
      "data_split: val\n",
      "labels: (2770,)\n",
      "predictions_probability: (2770,)\n",
      "residue_level_prediction: False\n",
      "sequences: (248,)\n",
      "sequence_embeddings: 248\n",
      "data_split: test\n",
      "labels: (248,)\n",
      "predictions_probability: (248,)\n",
      "residue_level_prediction: False\n",
      "üèÉ View run  at: https://datalab.corp.novocorp.net/mlflow/#/experiments/378/runs/59c1e0fac1b64093baae3404ce223057\n",
      "üß™ View experiment at: https://datalab.corp.novocorp.net/mlflow/#/experiments/378\n",
      "Error executing job with overrides: ['mlflow=datalab', 'persistence=lovelace', 'dataset.use_predefined_split=true', 'dataset.data_name=sbxw_fibrillation_peptide_waltzdb-train-val_serrano-test_randpadded10x', 'dataset.task=classification_binary', 'embedder=esm2_t6_8M', 'embedder.mean_pool=false', 'dimred=noreduction', 'predictor=lightattention', 'predictor.hparams.kernel_size=1', 'predictor.hparams.max_epochs=10', 'predictor.hparams.patience=200', 'predictor.hparams.batch_size=1000', 'predictor.hparams.learning_rate=0.0005', 'predictor.hparams.reduction_mode=mean', 'mlflow.experiment_name=ML-BP-Domino', 'plots.generate_plots=false']\n",
      "Traceback (most recent call last):\n",
      "  File \"/novo/projects/departments/cdd/molecular_ai/sbxw/repos/ML-BP-Domino/src/cli/training.py\", line 82, in my_app\n",
      "    stats_df = calculate_statistics_from_df(\n",
      "  File \"/novo/projects/departments/cdd/molecular_ai/sbxw/repos/ML-BP-Domino/src/helpers/stats_utilities.py\", line 276, in calculate_statistics_from_df\n",
      "    stat_dict = calculate_classification_statistics(\n",
      "  File \"/novo/projects/departments/cdd/molecular_ai/sbxw/repos/ML-BP-Domino/src/helpers/stats_utilities.py\", line 140, in calculate_classification_statistics\n",
      "    balanced_accuracy = float(balanced_accuracy_score(y, y_pred))\n",
      "  File \"/nfs_home/users/sbxw/mambaforge/envs/mlbp/lib/python3.10/site-packages/sklearn/utils/_param_validation.py\", line 213, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/nfs_home/users/sbxw/mambaforge/envs/mlbp/lib/python3.10/site-packages/sklearn/metrics/_classification.py\", line 2454, in balanced_accuracy_score\n",
      "    C = confusion_matrix(y_true, y_pred, sample_weight=sample_weight)\n",
      "  File \"/nfs_home/users/sbxw/mambaforge/envs/mlbp/lib/python3.10/site-packages/sklearn/utils/_param_validation.py\", line 186, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/nfs_home/users/sbxw/mambaforge/envs/mlbp/lib/python3.10/site-packages/sklearn/metrics/_classification.py\", line 319, in confusion_matrix\n",
      "    y_type, y_true, y_pred = _check_targets(y_true, y_pred)\n",
      "  File \"/nfs_home/users/sbxw/mambaforge/envs/mlbp/lib/python3.10/site-packages/sklearn/metrics/_classification.py\", line 94, in _check_targets\n",
      "    raise ValueError(\n",
      "ValueError: Classification metrics can't handle a mix of binary and unknown targets\n",
      "\n",
      "Set the environment variable HYDRA_FULL_ERROR=1 for a complete stack trace.\n",
      "ERROR conda.cli.main_run:execute(47): `conda run python /novo/projects/departments/cdd/molecular_ai/sbxw/repos/ML-BP-Domino/src/cli/training.py mlflow=datalab persistence=lovelace dataset.use_predefined_split=true dataset.data_name=sbxw_fibrillation_peptide_waltzdb-train-val_serrano-test_randpadded10x dataset.task=classification_binary embedder=esm2_t6_8M embedder.mean_pool=false dimred=noreduction predictor=lightattention predictor.hparams.kernel_size=1 predictor.hparams.max_epochs=10 predictor.hparams.patience=200 predictor.hparams.batch_size=1000 predictor.hparams.learning_rate=0.0005 predictor.hparams.reduction_mode=mean mlflow.experiment_name=ML-BP-Domino plots.generate_plots=false` failed. (See above for error)\n"
     ]
    }
   ],
   "source": [
    "%env AWS_ACCESS_KEY_ID=ASIATIJCHR3KA5YYSX4C\n",
    "%env AWS_SECRET_ACCESS_KEY=aPDRW7A6aUdgjnE2CdQeYG2IpZseMrimkIxc0H//\n",
    "%env AWS_SESSION_TOKEN=FwoGZXIvYXdzEMX//////////wEaDONh6B2GwAQwnkGFRSL0AwI0ymgCmmLalzZXga+CfvhC0RiboEHABvkZiIl6GOVwtQtrORvwMGFLYd5RwDFo+fKXDl5P3zXzI0hnN2nHWf9e+jNJ1wZVVr7JEmw1XZwZn7zyOMG0skT8+BYhtkkZPYUhZB+DPOrrszHfomSSbBuox+/5P/7M492NM2zMnLRPomrOHsCMpc5rTlpv2Qp/zMgP0wKud0NJLjgq46dZkJ7rr7STpYwqc3x+gQ0peDIDGWqtdgeX75v74lpSCBgLU1YwmhUFBBenqDWxFPnYZ+81Q8DAuwtGFABQAUHScu04lM352nNNDTM21nGW50KMXqubIFyBvNcwP7hK61HcxvDZtdXkOc0o/Rg/oVkfa3INcmwV3P8g8qsjmrWhWyfCi3zeXJmH4QJl4rksNLCPMNugzkljoFOxhXFW4dzcfjk/pIZ2RohVcbwsiVHpwR9SXVM+0YzFE2MYSSUomqt5ahlxuUyK2IAJRvggiGOlSBN0T3ADN45y0U+JIFpl92MoIGkaW6Tr0RNT8eIOEGPzBB4g9FILg+CfYT1tMPaVJmlKGkRY+/vJkaE3h4DelnO49JhB1wRJgdtwZlBuFgqRRAPatgbZwhG79EwkmwTTXd5i5AxMeqQymz8jVurFoMBfALEuASskEoLoZIIc65PA+n0xz422KLCh470GMpQBMYrXpVze1m5G2VeOYzklnn6hsbiLu63zI7T4XX5GLExc4eoffUYBO4hlZAvEKYKJoR1Rx+iNlFz2RoQNQAHbfydjTrp7srnbSTGcwtJP3pyxxuqwXIHpWw0wHWx0mAuxWrujzsSyReGInQd+bDpRYsHUTZBd7aHDPrUK7ctcczNzIiVwgFD8g1hroB4ZCAucGRTjjw==\n",
    "\n",
    "repo_dir = '/novo/projects/departments/cdd/molecular_ai/sbxw/repos/ML-BP-Domino'\n",
    "conda_env_name = 'mlbp'\n",
    "\n",
    "# Create command (single set of params)\n",
    "cmd = [\n",
    "    f\"/nfs_home/users/sbxw/mambaforge/condabin/conda run --no-capture-output -n {conda_env_name} python\",\n",
    "    f\"{repo_dir}/src/cli/training.py\",\n",
    "    \"mlflow=datalab\", \"persistence=lovelace\",\n",
    "    \"dataset.use_predefined_split=true\",\n",
    "    \"dataset.data_name=sbxw_fibrillation_peptide_waltzdb-train-val_serrano-test_randpadded10x\", \"dataset.task=classification_binary\", \n",
    "    \"embedder=esm2_t6_8M\",\"embedder.mean_pool=false\",\n",
    "    \"dimred=noreduction\",\n",
    "    \"predictor=lightattention\",\n",
    "    \"predictor.hparams.kernel_size=1\", \"predictor.hparams.max_epochs=10\", \"predictor.hparams.patience=200\",\n",
    "    \"predictor.hparams.batch_size=1000\", \"predictor.hparams.learning_rate=0.0005\",\n",
    "    \"predictor.hparams.reduction_mode=mean\",\n",
    "    \"mlflow.experiment_name=ML-BP-Domino\",\n",
    "    \"plots.generate_plots=false\",\n",
    "]\n",
    "\n",
    "command_str = \" \".join(cmd)\n",
    "print(command_str)\n",
    "!PYTHONPATH=repo_dir; $command_str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72bb8acd-51f8-4d23-afdf-db19a1dfa08d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8004cda-0478-4aa0-8a10-2e1ff3873b5b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mlbp",
   "language": "python",
   "name": "mlbp"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
