{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e7ea2ac1-fac7-45ba-a2c1-400cc8b53562",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: AWS_ACCESS_KEY_ID=ASIATIJCHR3KIBHT4CJJ\n",
      "env: AWS_SECRET_ACCESS_KEY=xIGEdnXCFX+ZYZnrhXhufFN9gmrHuypzZ1CiT7vz\n",
      "env: AWS_SESSION_TOKEN=FwoGZXIvYXdzECcaDEsf+Ibwksbize3jTiL0Awr1pSJRhVJHPHGlq05J5vAqAFN9acPInuJdAUEQCgjD639mjABp16fgQ74C+fM6tTVAMsuqNcHjHU/hVuYjoBcUoawUazYHDbDFEJTHDwkMRhCeR9PR+rAtXYoM1tU+LyttUBdvirWQhzFRvigEj1YTQn0oQYFOhOZOW5c4RcdlDhNztpz0TVoXHG8rXvPcGI3CejKZ4O5aDwouJ431Q0mmhN6L1tdjhbYS1eVhxcgPHwpNWPG9b/0T87gmec0a5ft/qE6+CWQhKSXHsN1ld/VHOryvsdcEpP9lQtYw3oMWnt7SMHRijgBbGkgo1Wn6lKG6sbrRJier7WgDlnRt3s6HXG5mxfxvsyNc6VssGhShMCe18nDniv0cg4SoqdwLsOb14wDxi7fD2T0/tXRRrjUEuyXD9BFdGloVZnWOhUsrYptoy501px/6SkTSYVOHsT/JG+FnBf65h/kZ0jH2zVsuxVYeprdUeYkP/YOJkRKbBUHPOhk2RbZjC7F7VA2ODEglGTtTXsxpp5s0VxstlMLlvLgyJA1H5mgj2Qu2L0aoQGcpQMR+A9b7yAm2SOCdj1L75LV/QGJyElIIJRJc2pDNkfBT5zQ0hRyCBgEJk5YWof/LIqYdxQjFqmgW4oqaYqXAVIw6fu5HJlT62Y+rfNcbxm6CKJD6+L0GMpQBELbEsvTtXAtUP5eSPHVmLmIL9JVZHfj/3U8ayUIezj1yCzH32pv5nHoErAXnPdKKw35qroqKMw9sPi3SdO5RcKclba1IGULmGu8nmCAUo8bVAx6WhcLVT8/CD9T3o3UdBuQ0eFTeqnH34G0lWOR6u/tDiAZP5/haLi6RG5EHQ9xx2pPVTLtxcLi8lBqTVydPbPoKHA==\n",
      "/nfs_home/users/sbxw/mambaforge/condabin/conda run --no-capture-output -n mlbp python /novo/projects/departments/cdd/molecular_ai/sbxw/repos/ML-BP-Domino/src/cli/training.py mlflow=datalab persistence=lovelace dataset.use_predefined_split=true dataset.data_name=sbxw_fibrillation_peptide_waltzdb-train-val_serrano-test dataset.task=classification_binary embedder=esm2_t6_8M embedder.mean_pool=false dimred=noreduction predictor=lightattention predictor.hparams.kernel_size=3 predictor.hparams.max_epochs=10 predictor.hparams.patience=200 predictor.hparams.batch_size=1000 predictor.hparams.learning_rate=0.0005 mlflow.experiment_name=ML-BP-Domino plots.generate_plots=false\n",
      "2025-02-25 22:36:04.466493: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2025-02-25 22:36:04.466537: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2025-02-25 22:36:04.468040: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2025-02-25 22:36:04.475510: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2025-02-25 22:36:07.162246: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "[2025-02-25 22:36:15,729][__main__][INFO] - Workflow configuration:\n",
      "\n",
      "general:\n",
      "  run_mode: train\n",
      "  abs_repo_path: null\n",
      "  composite_model_name: null\n",
      "  composite_model_path: null\n",
      "  precomputed_embeddings_path: null\n",
      "  random_state: 42\n",
      "dataset:\n",
      "  data_name: sbxw_fibrillation_peptide_waltzdb-train-val_serrano-test\n",
      "  add_data_columns: false\n",
      "  data_columns_dimred: false\n",
      "  data_columns_standard: false\n",
      "  group_column: null\n",
      "  data_scaler: RobustScaler\n",
      "  target_scaling: null\n",
      "  rbf_encoder: RadialBasisFunctionGaussian\n",
      "  rbf_n_kernels: 10\n",
      "  task: classification_binary\n",
      "  use_predefined_split: true\n",
      "  use_sample_weights: false\n",
      "  residue_prediction_labels: null\n",
      "  data_split_column: data_split\n",
      "  data_split:\n",
      "    train: 0.8\n",
      "    val: 0.0\n",
      "    test: 0.2\n",
      "embedder:\n",
      "  class_name: ESM\n",
      "  model_name: esm2_t6_8M_UR50D\n",
      "  model_path: null\n",
      "  standardize: false\n",
      "  scalar_type: StandardScaler\n",
      "  hparams: null\n",
      "  n_copies: 1\n",
      "  chain_break: poly-gly-linker\n",
      "  buffer_scale_factor: 2.0\n",
      "  max_batch_size: 400\n",
      "  simple_batching: false\n",
      "  strict: true\n",
      "  verbose: false\n",
      "  mean_pool: false\n",
      "  output_hidden_states: false\n",
      "dimred:\n",
      "  class_name: NoReduction\n",
      "  transform_name: null\n",
      "  fraction_variance_explained: null\n",
      "predictor:\n",
      "  class_name: LightAttention\n",
      "  model_name: null\n",
      "  model_type: classification_binary\n",
      "  mem_per_job: null\n",
      "  residue_prediction_mode: false\n",
      "  hparams:\n",
      "    kernel_size: 3\n",
      "    dropout: 0.25\n",
      "    conv_dropout: 0.25\n",
      "    learning_rate: 0.0005\n",
      "    batch_size: 1000\n",
      "    max_epochs: 10\n",
      "    patience: 200\n",
      "    post_attention: mlp\n",
      "    conv1d_output_dim: -1\n",
      "    optimal_cutoff: 0.5\n",
      "    reduction_mode: max\n",
      "persistence:\n",
      "  type: lovelace\n",
      "  data_root_folder: /novo/projects/departments/cdd/molecular_ai/mlbp/data\n",
      "  artifacts_root_folder: /novo/projects/departments/cdd/molecular_ai/mlbp/artifacts\n",
      "  training_data: static_input_data\n",
      "  pretrained_weights: static_pretrained_weights\n",
      "mlflow:\n",
      "  tracking_uri: https://datalab.corp.novocorp.net/mlflow/\n",
      "  experiment_name: ML-BP-Domino\n",
      "plots:\n",
      "  generate_plots: false\n",
      "\n",
      "[2025-02-25 22:36:15,729][src.model.dimred][INFO] - Load class (NoReduction): NoReduction\n",
      "[2025-02-25 22:36:15,729][src.model.abstract_components][INFO] - Load class (DimRed Model): NoReduction\n",
      "[2025-02-25 22:36:15,730][src.model.predictors][INFO] - Load class (LightAttention): LightAttention\n",
      "[2025-02-25 22:36:15,730][src.model.abstract_components][INFO] - Load class (TorchPredictorModel): LightAttention\n",
      "[2025-02-25 22:36:15,730][src.model.abstract_components][INFO] - Load class (Predictor Model): LightAttention\n",
      "[2025-02-25 22:36:15,730][src.model.composite_model][INFO] - Composite model name: esm2t68MUR50D_LightAttention_sbxwfibrillationpeptidewaltzdb-train-valserrano-test\n",
      "[2025-02-25 22:36:15,730][src.model.composite_model][INFO] - Initialized model: esm2t68MUR50D_LightAttention_sbxwfibrillationpeptidewaltzdb-train-valserrano-test in run_mode = train\n",
      "[2025-02-25 22:36:15,734][src.helpers.dataset][INFO] - Loading file: /novo/projects/departments/cdd/molecular_ai/mlbp/data/static_input_data/sbxw_fibrillation_peptide_waltzdb-train-val_serrano-test.csv\n",
      "[2025-02-25 22:36:15,735][src.helpers.dataset][INFO] - Using group_column \"None\".\n",
      "[2025-02-25 22:36:15,735][src.helpers.dataset][INFO] - No additional data columns found while parsing.\n",
      "[2025-02-25 22:36:15,737][src.helpers.dataset][INFO] - Select data according to predetermined splits in the dataframe, train (N = 1122), validation (N = 277), test (N = 248)\n",
      "[2025-02-25 22:36:15,737][src.helpers.dataset][INFO] - Loaded columns: {}\n",
      "[2025-02-25 22:36:15,738][src.helpers.mlflow_helpers][INFO] - Setting up MLflow...\n",
      "[2025-02-25 22:36:15,738][src.helpers.mlflow_helpers][INFO] - Experiment name: ML-BP-Domino\n",
      "[2025-02-25 22:36:15,738][src.helpers.mlflow_helpers][INFO] - Setting MLflow tracking URI to https://datalab.corp.novocorp.net/mlflow/\n",
      "[2025-02-25 22:36:16,713][src.helpers.mlflow_helpers][INFO] - Setting MLflow experiment to ML-BP-Domino\n",
      "[2025-02-25 22:36:17,158][__main__][INFO] - <RunInfo: artifact_uri='s3://nnedl-core-prd-eu-central-1-curated/mlops/378/db15bc7b3cfa4297940f79e70f538d54/artifacts', end_time=None, experiment_id='378', lifecycle_stage='active', run_id='db15bc7b3cfa4297940f79e70f538d54', run_name='', run_uuid='db15bc7b3cfa4297940f79e70f538d54', start_time=1740522976898, status='RUNNING', user_id='sbxw'>\n",
      "[2025-02-25 22:36:17,960][__main__][INFO] - Compute embeddings on-the-fly and train model\n",
      "[2025-02-25 22:36:17,960][src.model.abstract_components][INFO] - Load class (LLMEmbedderModel): ESM\n",
      "[2025-02-25 22:36:17,961][src.model.abstract_components][INFO] - Load class (Embedder Model): ESM\n",
      "[2025-02-25 22:36:17,961][src.model.embedders][INFO] - Loading model: esm2_t6_8M_UR50D, will extract embeddings from 6-th layer\n",
      "Some weights of EsmModel were not initialized from the model checkpoint at facebook/esm2_t6_8M_UR50D and are newly initialized: ['esm.pooler.dense.bias', 'esm.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "[2025-02-25 22:36:18,696][src.model.embedders][INFO] - Moving model to cuda\n",
      "[2025-02-25 22:36:18,854][src.model.abstract_components][INFO] - Total memory: 23.58378496GB\n",
      "Memory already allocated: 0.031387648GB\n",
      "[2025-02-25 22:36:19,337][src.model.embedders][INFO] - Per-residue embeddings count: 1122\n",
      "[2025-02-25 22:36:19,337][src.model.composite_model][INFO] - Residue embeddings\n",
      "[2025-02-25 22:36:19,338][src.model.abstract_components][INFO] - Total memory: 23.58378496GB\n",
      "Memory already allocated: 0.043664896GB\n",
      "[2025-02-25 22:36:19,361][src.model.embedders][INFO] - Per-residue embeddings count: 277\n",
      "[2025-02-25 22:36:19,361][src.model.scalers][INFO] - Fitted scaler: PassThroughScaler\n",
      "[2025-02-25 22:36:19,361][src.model.scalers][INFO] - Before standardization - min: 0.0, max: 1.0\n",
      "[2025-02-25 22:36:19,361][src.model.scalers][INFO] - After standardization - min: 0.0, max: 1.0\n",
      "[2025-02-25 22:36:19,361][src.model.scalers][INFO] - Before standardization - min: 0.0, max: 1.0\n",
      "[2025-02-25 22:36:19,361][src.model.scalers][INFO] - After standardization - min: 0.0, max: 1.0\n",
      "[2025-02-25 22:36:19,361][src.model.scalers][INFO] - Before standardization - min: 0.0, max: 1.0\n",
      "[2025-02-25 22:36:19,361][src.model.scalers][INFO] - After standardization - min: 0.0, max: 1.0\n",
      "/nfs_home/users/sbxw/mambaforge/envs/mlbp/lib/python3.10/site-packages/lightning/fabric/plugins/environments/slurm.py:204: The `srun` command is available on your system but is not used. HINT: If your intention is to run Lightning on SLURM, prepend your python command with `srun` like so: srun python /novo/projects/departments/cdd/molecular_ai/sbxw/rep ...\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/nfs_home/users/sbxw/mambaforge/envs/mlbp/lib/python3.10/site-packages/lightning/fabric/plugins/environments/slurm.py:204: The `srun` command is available on your system but is not used. HINT: If your intention is to run Lightning on SLURM, prepend your python command with `srun` like so: srun python /novo/projects/departments/cdd/molecular_ai/sbxw/rep ...\n",
      "[2025-02-25 22:36:20,630][pytorch_lightning.utilities.rank_zero][INFO] - You are using a CUDA device ('NVIDIA L4') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name                  | Type       | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | feature_convolution   | Conv1d     | 307 K  | train\n",
      "1 | attention_convolution | Conv1d     | 307 K  | train\n",
      "2 | softmax               | Softmax    | 0      | train\n",
      "3 | dropout               | Dropout    | 0      | train\n",
      "4 | sigmoid               | Sigmoid    | 0      | train\n",
      "5 | mlp                   | Sequential | 10.4 K | train\n",
      "6 | loss_fxn              | BCELoss    | 0      | train\n",
      "-------------------------------------------------------------\n",
      "625 K     Trainable params\n",
      "0         Non-trainable params\n",
      "625 K     Total params\n",
      "2.502     Total estimated model params size (MB)\n",
      "12        Modules in train mode\n",
      "0         Modules in eval mode\n",
      "/nfs_home/users/sbxw/mambaforge/envs/mlbp/lib/python3.10/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:424: The 'val_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=7` in the `DataLoader` to improve performance.\n",
      "/nfs_home/users/sbxw/mambaforge/envs/mlbp/lib/python3.10/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:424: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=7` in the `DataLoader` to improve performance.\n",
      "[2025-02-25 22:36:24,440][botocore.credentials][INFO] - Found credentials in environment variables.\n",
      "[2025-02-25 22:36:42,201][pytorch_lightning.utilities.rank_zero][INFO] - `Trainer.fit` stopped: `max_epochs=10` reached.\n",
      "üèÉ View run  at: https://datalab.corp.novocorp.net/mlflow/#/experiments/378/runs/db15bc7b3cfa4297940f79e70f538d54\n",
      "üß™ View experiment at: https://datalab.corp.novocorp.net/mlflow/#/experiments/378\n",
      "\u001b[31m2025/02/25 22:37:04 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\u001b[0m\n",
      "[2025-02-25 22:37:13,324][src.model.abstract_components][INFO] - MODEL STOPPED BY EARLY STOPPER AT EPOCH 0\n",
      "[2025-02-25 22:37:13,325][src.model.abstract_components][INFO] - BEST MODEL VALIDATION LOSS IS 0.6786574125289917\n",
      "[2025-02-25 22:37:13,325][src.model.abstract_components][INFO] - BEST MODEL SAVED AT /novo/projects/departments/cdd/public/users/ehec/sbxw_files_2/378/db15bc7b3cfa4297940f79e70f538d54/checkpoints/epoch=0-step=2.ckpt\n",
      "[2025-02-25 22:37:13,325][src.model.abstract_components][INFO] - FINAL MODEL SAVED AT None\n",
      "[2025-02-25 22:37:13,597][src.model.predictors][INFO] - Moving embeddings to device: cuda\n",
      "[2025-02-25 22:37:13,696][src.model.predictors][INFO] - Optimal cutoff is: 0.47000000000000003 with MCC: 0.11342485376933736\n",
      "[2025-02-25 22:37:13,707][src.model.predictors][INFO] - Moving embeddings to device: cuda\n",
      "[2025-02-25 22:37:13,714][src.model.predictors][INFO] - Moving embeddings to device: cuda\n",
      "[2025-02-25 22:37:13,715][src.model.scalers][INFO] - Before standardization - min: False, max: True\n",
      "[2025-02-25 22:37:13,716][src.model.scalers][INFO] - After standardization - min: False, max: True\n",
      "[2025-02-25 22:37:13,716][src.model.scalers][INFO] - Before standardization - min: False, max: True\n",
      "[2025-02-25 22:37:13,716][src.model.scalers][INFO] - After standardization - min: False, max: True\n",
      "[2025-02-25 22:37:13,716][src.model.composite_model][INFO] - This is the updated predictor name: lightattention_kernel_size_3_dropout_0.25_conv_dropout_0.25_learning_rate_0.0005_batch_size_1000_max_epochs_10_patience_200_post_attention_mlp_conv1d_output_dim_-1_optimal_cutoff_0.47000000000000003_reduction_mode_max\n",
      "[2025-02-25 22:37:13,716][src.model.composite_model][INFO] - Composite model name: esm2t68MUR50D_LightAttention_sbxwfibrillationpeptidewaltzdb-train-valserrano-test\n",
      "[2025-02-25 22:37:13,717][src.model.composite_model][INFO] - Best model is: kernel_size_3_dropout_0.25_conv_dropout_0.25_learning_rate_0.0005_batch_size_1000_max_epochs_10_patience_200_post_attention_mlp_conv1d_output_dim_-1_optimal_cutoff_0.47000000000000003_reduction_mode_max\n",
      "[2025-02-25 22:37:13,717][src.model.composite_model][INFO] - Moving to test mode\n",
      "[2025-02-25 22:37:13,717][src.model.composite_model][INFO] - Composite model name: esm2t68MUR50D_LightAttention_sbxwfibrillationpeptidewaltzdb-train-valserrano-test\n",
      "[2025-02-25 22:37:13,717][src.model.composite_model][INFO] - Saving model: esm2t68MUR50D_LightAttention_sbxwfibrillationpeptidewaltzdb-train-valserrano-test\n",
      "<RunInfo: artifact_uri='s3://nnedl-core-prd-eu-central-1-curated/mlops/378/db15bc7b3cfa4297940f79e70f538d54/artifacts', end_time=None, experiment_id='378', lifecycle_stage='active', run_id='db15bc7b3cfa4297940f79e70f538d54', run_name='', run_uuid='db15bc7b3cfa4297940f79e70f538d54', start_time=1740522976898, status='RUNNING', user_id='sbxw'>\n",
      "[2025-02-25 22:37:20,254][src.model.abstract_components][INFO] - Total memory: 23.58378496GB\n",
      "Memory already allocated: 0.055517184GB\n",
      "[2025-02-25 22:37:20,324][src.model.embedders][INFO] - Per-residue embeddings count: 248\n",
      "[2025-02-25 22:37:20,324][src.model.composite_model][INFO] - Residue embeddings\n",
      "[2025-02-25 22:37:20,328][src.model.predictors][INFO] - Moving embeddings to device: cuda\n",
      "[2025-02-25 22:37:20,333][src.model.scalers][INFO] - Before standardization - min: True, max: True\n",
      "[2025-02-25 22:37:20,333][src.model.scalers][INFO] - After standardization - min: True, max: True\n",
      "sequences: (1122,)\n",
      "sequence_embeddings: 1122\n",
      "predictions: (1122,)\n",
      "predictions_scaled: (1122,)\n",
      "data_split: train\n",
      "labels: (1122,)\n",
      "predictions_probability: (1122,)\n",
      "residue_level_prediction: False\n",
      "sequences: (277,)\n",
      "sequence_embeddings: 277\n",
      "predictions: (277,)\n",
      "predictions_scaled: (277,)\n",
      "data_split: val\n",
      "labels: (277,)\n",
      "predictions_probability: (277,)\n",
      "residue_level_prediction: False\n",
      "sequences: (248,)\n",
      "sequence_embeddings: 248\n",
      "predictions: (248,)\n",
      "predictions_scaled: (248,)\n",
      "data_split: test\n",
      "labels: (248,)\n",
      "predictions_probability: (248,)\n",
      "residue_level_prediction: False\n",
      "[2025-02-25 22:37:21,621][src.model.composite_model][INFO] - Composite model name: esm2t68MUR50D_LightAttention_sbxwfibrillationpeptidewaltzdb-train-valserrano-test\n",
      "[2025-02-25 22:37:22,384][__main__][INFO] - Done!\n",
      "run_id: db15bc7b3cfa4297940f79e70f538d54\n",
      "artifacts: ['model/MLmodel', 'model/checkpoints', 'model/conda.yaml', 'model/data', 'model/python_env.yaml', 'model/requirements.txt']\n",
      "params: {'model_type': 'classification_binary', 'general.run_mode': 'train', 'general.abs_repo_path': 'None', 'general.composite_model_name': 'esm2t68MUR50D_LightAttention_sbxwfibrillationpeptidewaltzdb-train-valserrano-test', 'general.composite_model_path': 'None', 'general.precomputed_embeddings_path': 'None', 'general.random_state': '42', 'dataset.data_name': 'sbxw_fibrillation_peptide_waltzdb-train-val_serrano-test', 'dataset.add_data_columns': 'False', 'dataset.data_columns_dimred': 'False', 'dataset.data_columns_standard': 'False', 'dataset.group_column': 'None', 'dataset.data_scaler': 'RobustScaler', 'dataset.target_scaling': 'None', 'dataset.rbf_encoder': 'RadialBasisFunctionGaussian', 'dataset.rbf_n_kernels': '10', 'dataset.task': 'classification_binary', 'dataset.use_predefined_split': 'True', 'dataset.use_sample_weights': 'False', 'dataset.residue_prediction_labels': 'None', 'dataset.data_split_column': 'data_split', 'dataset.data_split.train': '0.8', 'dataset.data_split.val': '0.0', 'dataset.data_split.test': '0.2', 'embedder.class_name': 'ESM', 'embedder.model_name': 'esm2_t6_8M_UR50D', 'embedder.model_path': 'None', 'embedder.standardize': 'False', 'embedder.scalar_type': 'StandardScaler', 'embedder.hparams': 'None', 'embedder.n_copies': '1', 'embedder.chain_break': 'poly-gly-linker', 'embedder.buffer_scale_factor': '2.0', 'embedder.max_batch_size': '400', 'embedder.simple_batching': 'False', 'embedder.strict': 'True', 'embedder.verbose': 'False', 'embedder.mean_pool': 'False', 'embedder.output_hidden_states': 'False', 'dimred.class_name': 'NoReduction', 'dimred.transform_name': 'None', 'dimred.fraction_variance_explained': 'None', 'predictor.class_name': 'LightAttention', 'predictor.model_name': 'None', 'predictor.model_type': 'classification_binary', 'predictor.mem_per_job': 'None', 'predictor.residue_prediction_mode': 'False', 'predictor.hparams.kernel_size': '3', 'predictor.hparams.dropout': '0.25', 'predictor.hparams.conv_dropout': '0.25', 'predictor.hparams.learning_rate': '0.0005', 'predictor.hparams.batch_size': '1000', 'predictor.hparams.max_epochs': '10', 'predictor.hparams.patience': '200', 'predictor.hparams.post_attention': 'mlp', 'predictor.hparams.conv1d_output_dim': '-1', 'predictor.hparams.optimal_cutoff': '0.5', 'predictor.hparams.reduction_mode': 'max', 'persistence.type': 'lovelace', 'persistence.data_root_folder': '/novo/projects/departments/cdd/molecular_ai/mlbp/data', 'persistence.artifacts_root_folder': '/novo/projects/departments/cdd/molecular_ai/mlbp/artifacts', 'persistence.training_data': 'static_input_data', 'persistence.pretrained_weights': 'static_pretrained_weights', 'mlflow.tracking_uri': 'https://datalab.corp.novocorp.net/mlflow/', 'mlflow.experiment_name': 'ML-BP-Domino', 'plots.generate_plots': 'False', 'embeddings_dim': '320', 'output_dim': '1', 'kernel_size': '3', 'dropout': '0.25', 'conv_dropout': '0.25', 'learning_rate': '0.0005', 'post_attention': 'mlp', 'conv1d_output_dim': '-1', 'residue_prediction_mode': 'False', 'reduction_mode': 'max', 'epochs': '10', 'optimizer_name': 'SGD', 'lr': '0.0005', 'momentum': '0', 'dampening': '0', 'weight_decay': '0', 'nesterov': 'False', 'maximize': 'False', 'foreach': 'None', 'differentiable': 'False', 'fused': 'None'}\n",
      "metrics: {'train.loss_step': 0.7599684596061707, 'train.loss_epoch': 0.7820597887039185, 'epoch': 9.0, 'train.loss': 0.7820597887039185, 'val_loss': 0.680533766746521, 'test.accuracy': 0.3064516129032258, 'test.precision': 0.3064516129032258, 'test.recall': 1.0, 'test.specificity': 0.0, 'test.f_score': 0.4691358024691358, 'test.matthews_corr_coef': 0.0, 'test.optimal_mcc': 0.0, 'test.optimal_mcc_cutoff': 0.0, 'test.balanced_accuracy': 0.5, 'test.roc_auc_score': 0.6503212974296205, 'val.loss': 0.680533766746521, 'train.accuracy': 0.3983957219251337, 'train.precision': 0.37406015037593987, 'train.recall': 0.9778869778869779, 'train.specificity': 0.06853146853146853, 'train.f_score': 0.5411284840244731, 'train.matthews_corr_coef': 0.10079895174169921, 'train.optimal_mcc': 0.10079895174169921, 'train.optimal_mcc_cutoff': 0.47000000000000003, 'train.balanced_accuracy': 0.5232092232092233, 'train.roc_auc_score': 0.5877510695692514, 'val.accuracy': 0.4007220216606498, 'val.precision': 0.37404580152671757, 'val.recall': 0.98, 'val.specificity': 0.07344632768361582, 'val.f_score': 0.5414364640883977, 'val.matthews_corr_coef': 0.11342485376933736, 'val.optimal_mcc': 0.11342485376933736, 'val.optimal_mcc_cutoff': 0.47000000000000003, 'val.balanced_accuracy': 0.526723163841808, 'val.roc_auc_score': 0.4963559322033898}\n",
      "tags: {'Mode': 'training'}\n",
      "results stored in /novo/projects/departments/cdd/molecular_ai/mlbp/artifacts/2025-02-25-2236_db15bc7b3cfa4297940f79e70f538d54/esm2t68MUR50D_LightAttention_sbxwfibrillationpeptidewaltzdb-train-valserrano-test_stats.csv\n",
      "s3://nnedl-core-prd-eu-central-1-curated/mlops/378/db15bc7b3cfa4297940f79e70f538d54/artifacts\n",
      "\u001b[34mSystem information\u001b[0m: Linux #70~20.04.1-Ubuntu SMP Fri Jun 14 15:42:13 UTC 2024\n",
      "\u001b[34mPython version\u001b[0m: 3.10.14\n",
      "\u001b[34mMLflow version\u001b[0m: 2.20.2\n",
      "\u001b[34mMLflow module location\u001b[0m: /nfs_home/users/sbxw/mambaforge/envs/mlbp/lib/python3.10/site-packages/mlflow/__init__.py\n",
      "\u001b[34mTracking URI\u001b[0m: https://datalab.corp.novocorp.net/mlflow/\n",
      "\u001b[34mRegistry URI\u001b[0m: https://datalab.corp.novocorp.net/mlflow/\n",
      "\u001b[34mActive experiment ID\u001b[0m: 378\n",
      "\u001b[34mActive run ID\u001b[0m: db15bc7b3cfa4297940f79e70f538d54\n",
      "\u001b[34mActive run artifact URI\u001b[0m: s3://nnedl-core-prd-eu-central-1-curated/mlops/378/db15bc7b3cfa4297940f79e70f538d54/artifacts\n",
      "\u001b[34mMLflow environment variables\u001b[0m: \n",
      "  MLFLOW_EXPERIMENT_ID: 378\n",
      "  MLFLOW_TRACKING_URI: https://datalab.corp.novocorp.net/mlflow/\n",
      "\u001b[34mMLflow dependencies\u001b[0m: \n",
      "  Flask: 2.2.5\n",
      "  Jinja2: 3.1.4\n",
      "  aiohttp: 3.9.5\n",
      "  alembic: 1.13.1\n",
      "  boto3: 1.36.23\n",
      "  botocore: 1.36.23\n",
      "  docker: 7.0.0\n",
      "  graphene: 3.3\n",
      "  gunicorn: 22.0.0\n",
      "  markdown: 3.6\n",
      "  matplotlib: 3.9.0\n",
      "  mlflow-skinny: 2.20.2\n",
      "  numpy: 1.26.4\n",
      "  pandas: 2.2.2\n",
      "  pyarrow: 15.0.2\n",
      "  scikit-learn: 1.4.2\n",
      "  scipy: 1.13.0\n",
      "  sqlalchemy: 2.0.30\n",
      "  virtualenv: 20.26.2\n",
      "None\n",
      "üèÉ View run  at: https://datalab.corp.novocorp.net/mlflow/#/experiments/378/runs/db15bc7b3cfa4297940f79e70f538d54\n",
      "üß™ View experiment at: https://datalab.corp.novocorp.net/mlflow/#/experiments/378\n"
     ]
    }
   ],
   "source": [
    "%env AWS_ACCESS_KEY_ID=ASIATIJCHR3KIBHT4CJJ\n",
    "%env AWS_SECRET_ACCESS_KEY=xIGEdnXCFX+ZYZnrhXhufFN9gmrHuypzZ1CiT7vz\n",
    "%env AWS_SESSION_TOKEN=FwoGZXIvYXdzECcaDEsf+Ibwksbize3jTiL0Awr1pSJRhVJHPHGlq05J5vAqAFN9acPInuJdAUEQCgjD639mjABp16fgQ74C+fM6tTVAMsuqNcHjHU/hVuYjoBcUoawUazYHDbDFEJTHDwkMRhCeR9PR+rAtXYoM1tU+LyttUBdvirWQhzFRvigEj1YTQn0oQYFOhOZOW5c4RcdlDhNztpz0TVoXHG8rXvPcGI3CejKZ4O5aDwouJ431Q0mmhN6L1tdjhbYS1eVhxcgPHwpNWPG9b/0T87gmec0a5ft/qE6+CWQhKSXHsN1ld/VHOryvsdcEpP9lQtYw3oMWnt7SMHRijgBbGkgo1Wn6lKG6sbrRJier7WgDlnRt3s6HXG5mxfxvsyNc6VssGhShMCe18nDniv0cg4SoqdwLsOb14wDxi7fD2T0/tXRRrjUEuyXD9BFdGloVZnWOhUsrYptoy501px/6SkTSYVOHsT/JG+FnBf65h/kZ0jH2zVsuxVYeprdUeYkP/YOJkRKbBUHPOhk2RbZjC7F7VA2ODEglGTtTXsxpp5s0VxstlMLlvLgyJA1H5mgj2Qu2L0aoQGcpQMR+A9b7yAm2SOCdj1L75LV/QGJyElIIJRJc2pDNkfBT5zQ0hRyCBgEJk5YWof/LIqYdxQjFqmgW4oqaYqXAVIw6fu5HJlT62Y+rfNcbxm6CKJD6+L0GMpQBELbEsvTtXAtUP5eSPHVmLmIL9JVZHfj/3U8ayUIezj1yCzH32pv5nHoErAXnPdKKw35qroqKMw9sPi3SdO5RcKclba1IGULmGu8nmCAUo8bVAx6WhcLVT8/CD9T3o3UdBuQ0eFTeqnH34G0lWOR6u/tDiAZP5/haLi6RG5EHQ9xx2pPVTLtxcLi8lBqTVydPbPoKHA==\n",
    "\n",
    "repo_dir = '/novo/projects/departments/cdd/molecular_ai/sbxw/repos/ML-BP-Domino'\n",
    "conda_env_name = 'mlbp'\n",
    "\n",
    "# Create command (single set of params)\n",
    "cmd = [\n",
    "    f\"/nfs_home/users/sbxw/mambaforge/condabin/conda run --no-capture-output -n {conda_env_name} python\",\n",
    "    f\"{repo_dir}/src/cli/training.py\",\n",
    "    \"mlflow=datalab\", \"persistence=lovelace\",\n",
    "    \"dataset.use_predefined_split=true\",\n",
    "    \"dataset.data_name=sbxw_fibrillation_peptide_waltzdb-train-val_serrano-test\", \"dataset.task=classification_binary\", \n",
    "    \"embedder=esm2_t6_8M\",\"embedder.mean_pool=false\",\n",
    "    \"dimred=noreduction\",\n",
    "    \"predictor=lightattention\",\n",
    "    \"predictor.hparams.kernel_size=3\", \"predictor.hparams.max_epochs=10\", \"predictor.hparams.patience=200\",\n",
    "    \"predictor.hparams.batch_size=1000\", \"predictor.hparams.learning_rate=0.0005\",\n",
    "    \"mlflow.experiment_name=ML-BP-Domino\",\n",
    "    \"plots.generate_plots=false\",\n",
    "]\n",
    "\n",
    "command_str = \" \".join(cmd)\n",
    "print(command_str)\n",
    "!$command_str"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5646494a-58bd-46e7-b267-1298a36c02cc",
   "metadata": {},
   "source": [
    "# Run job with pytorch main merge branch (3 tests)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "20f69d8f-4079-428b-abba-d798596c83a8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: AWS_ACCESS_KEY_ID=ASIATIJCHR3KA5YYSX4C\n",
      "env: AWS_SECRET_ACCESS_KEY=aPDRW7A6aUdgjnE2CdQeYG2IpZseMrimkIxc0H//\n",
      "env: AWS_SESSION_TOKEN=FwoGZXIvYXdzEMX//////////wEaDONh6B2GwAQwnkGFRSL0AwI0ymgCmmLalzZXga+CfvhC0RiboEHABvkZiIl6GOVwtQtrORvwMGFLYd5RwDFo+fKXDl5P3zXzI0hnN2nHWf9e+jNJ1wZVVr7JEmw1XZwZn7zyOMG0skT8+BYhtkkZPYUhZB+DPOrrszHfomSSbBuox+/5P/7M492NM2zMnLRPomrOHsCMpc5rTlpv2Qp/zMgP0wKud0NJLjgq46dZkJ7rr7STpYwqc3x+gQ0peDIDGWqtdgeX75v74lpSCBgLU1YwmhUFBBenqDWxFPnYZ+81Q8DAuwtGFABQAUHScu04lM352nNNDTM21nGW50KMXqubIFyBvNcwP7hK61HcxvDZtdXkOc0o/Rg/oVkfa3INcmwV3P8g8qsjmrWhWyfCi3zeXJmH4QJl4rksNLCPMNugzkljoFOxhXFW4dzcfjk/pIZ2RohVcbwsiVHpwR9SXVM+0YzFE2MYSSUomqt5ahlxuUyK2IAJRvggiGOlSBN0T3ADN45y0U+JIFpl92MoIGkaW6Tr0RNT8eIOEGPzBB4g9FILg+CfYT1tMPaVJmlKGkRY+/vJkaE3h4DelnO49JhB1wRJgdtwZlBuFgqRRAPatgbZwhG79EwkmwTTXd5i5AxMeqQymz8jVurFoMBfALEuASskEoLoZIIc65PA+n0xz422KLCh470GMpQBMYrXpVze1m5G2VeOYzklnn6hsbiLu63zI7T4XX5GLExc4eoffUYBO4hlZAvEKYKJoR1Rx+iNlFz2RoQNQAHbfydjTrp7srnbSTGcwtJP3pyxxuqwXIHpWw0wHWx0mAuxWrujzsSyReGInQd+bDpRYsHUTZBd7aHDPrUK7ctcczNzIiVwgFD8g1hroB4ZCAucGRTjjw==\n",
      "/nfs_home/users/sbxw/mambaforge/condabin/conda run --no-capture-output -n mlbp python /novo/projects/departments/cdd/molecular_ai/sbxw/repos/ML-BP-Domino/src/cli/training.py mlflow=datalab persistence=lovelace dataset.use_predefined_split=true dataset.data_name=sbxw_fibrillation_peptide_waltzdb-train-val_serrano-test dataset.task=classification_binary embedder=esm2_t6_8M embedder.mean_pool=false dimred=noreduction predictor=lightattention predictor.hparams.kernel_size=3 predictor.hparams.max_epochs=10 predictor.hparams.patience=200 predictor.hparams.batch_size=1000 predictor.hparams.learning_rate=0.0005 mlflow.experiment_name=ML-BP-Domino plots.generate_plots=false\n",
      "2025-02-21 20:25:44.630460: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2025-02-21 20:25:44.630508: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2025-02-21 20:25:44.632046: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2025-02-21 20:25:44.639521: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2025-02-21 20:25:48.314288: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "[2025-02-21 20:26:00,275][__main__][INFO] - Workflow configuration:\n",
      "\n",
      "general:\n",
      "  run_mode: train\n",
      "  abs_repo_path: null\n",
      "  composite_model_name: null\n",
      "  composite_model_path: null\n",
      "  precomputed_embeddings_path: null\n",
      "  random_state: 42\n",
      "dataset:\n",
      "  data_name: sbxw_fibrillation_peptide_waltzdb-train-val_serrano-test\n",
      "  add_data_columns: false\n",
      "  data_columns_dimred: false\n",
      "  data_columns_standard: false\n",
      "  group_column: null\n",
      "  data_scaler: RobustScaler\n",
      "  target_scaling: null\n",
      "  rbf_encoder: RadialBasisFunctionGaussian\n",
      "  rbf_n_kernels: 10\n",
      "  task: classification_binary\n",
      "  use_predefined_split: true\n",
      "  use_sample_weights: false\n",
      "  residue_prediction_labels: null\n",
      "  data_split_column: data_split\n",
      "  data_split:\n",
      "    train: 0.8\n",
      "    val: 0.0\n",
      "    test: 0.2\n",
      "embedder:\n",
      "  class_name: ESM\n",
      "  model_name: esm2_t6_8M_UR50D\n",
      "  model_path: null\n",
      "  standardize: false\n",
      "  scalar_type: StandardScaler\n",
      "  hparams: null\n",
      "  n_copies: 1\n",
      "  chain_break: poly-gly-linker\n",
      "  buffer_scale_factor: 2.0\n",
      "  max_batch_size: 400\n",
      "  simple_batching: false\n",
      "  strict: true\n",
      "  verbose: false\n",
      "  mean_pool: false\n",
      "  output_hidden_states: false\n",
      "dimred:\n",
      "  class_name: NoReduction\n",
      "  transform_name: null\n",
      "  fraction_variance_explained: null\n",
      "predictor:\n",
      "  class_name: LightAttention\n",
      "  model_name: null\n",
      "  model_type: classification_binary\n",
      "  mem_per_job: null\n",
      "  residue_prediction_mode: false\n",
      "  hparams:\n",
      "    kernel_size: 3\n",
      "    dropout: 0.25\n",
      "    conv_dropout: 0.25\n",
      "    learning_rate: 0.0005\n",
      "    batch_size: 1000\n",
      "    max_epochs: 10\n",
      "    patience: 200\n",
      "    post_attention: mlp\n",
      "    conv1d_output_dim: -1\n",
      "    optimal_cutoff: 0.5\n",
      "persistence:\n",
      "  type: lovelace\n",
      "  data_root_folder: /novo/projects/departments/cdd/molecular_ai/mlbp/data\n",
      "  artifacts_root_folder: /novo/projects/departments/cdd/molecular_ai/mlbp/artifacts\n",
      "  training_data: static_input_data\n",
      "  pretrained_weights: static_pretrained_weights\n",
      "mlflow:\n",
      "  tracking_uri: https://datalab.corp.novocorp.net/mlflow/\n",
      "  experiment_name: ML-BP-Domino\n",
      "plots:\n",
      "  generate_plots: false\n",
      "\n",
      "[2025-02-21 20:26:00,276][src.model.dimred][INFO] - Load class (NoReduction): NoReduction\n",
      "[2025-02-21 20:26:00,276][src.model.abstract_components][INFO] - Load class (DimRed Model): NoReduction\n",
      "[2025-02-21 20:26:00,277][src.model.predictors][INFO] - Load class (LightAttention): LightAttention\n",
      "[2025-02-21 20:26:00,277][src.model.abstract_components][INFO] - Load class (TorchPredictorModel): LightAttention\n",
      "[2025-02-21 20:26:00,277][src.model.abstract_components][INFO] - Load class (Predictor Model): LightAttention\n",
      "[2025-02-21 20:26:00,277][src.model.composite_model][INFO] - Composite model name: esm2t68MUR50D_LightAttention_sbxwfibrillationpeptidewaltzdb-train-valserrano-test\n",
      "[2025-02-21 20:26:00,277][src.model.composite_model][INFO] - Initialized model: esm2t68MUR50D_LightAttention_sbxwfibrillationpeptidewaltzdb-train-valserrano-test in run_mode = train\n",
      "[2025-02-21 20:26:00,282][src.helpers.dataset][INFO] - Loading file: /novo/projects/departments/cdd/molecular_ai/mlbp/data/static_input_data/sbxw_fibrillation_peptide_waltzdb-train-val_serrano-test.csv\n",
      "[2025-02-21 20:26:00,282][src.helpers.dataset][INFO] - Using group_column \"None\".\n",
      "[2025-02-21 20:26:00,283][src.helpers.dataset][INFO] - No additional data columns found while parsing.\n",
      "[2025-02-21 20:26:00,284][src.helpers.dataset][INFO] - Select data according to predetermined splits in the dataframe, train (N = 1122), validation (N = 277), test (N = 248)\n",
      "[2025-02-21 20:26:00,284][src.helpers.dataset][INFO] - Loaded columns: {}\n",
      "[2025-02-21 20:26:00,285][src.helpers.mlflow_helpers][INFO] - Setting up MLflow...\n",
      "[2025-02-21 20:26:00,285][src.helpers.mlflow_helpers][INFO] - Experiment name: ML-BP-Domino\n",
      "[2025-02-21 20:26:00,285][src.helpers.mlflow_helpers][INFO] - Setting MLflow tracking URI to https://datalab.corp.novocorp.net/mlflow/\n",
      "[2025-02-21 20:26:01,645][src.helpers.mlflow_helpers][INFO] - Setting MLflow experiment to ML-BP-Domino\n",
      "[2025-02-21 20:26:02,849][__main__][INFO] - Compute embeddings on-the-fly and train model\n",
      "[2025-02-21 20:26:02,849][src.model.abstract_components][INFO] - Load class (LLMEmbedderModel): ESM\n",
      "[2025-02-21 20:26:02,849][src.model.abstract_components][INFO] - Load class (Embedder Model): ESM\n",
      "[2025-02-21 20:26:02,850][src.model.embedders][INFO] - Loading model: esm2_t6_8M_UR50D, will extract embeddings from 6-th layer\n",
      "Some weights of EsmModel were not initialized from the model checkpoint at facebook/esm2_t6_8M_UR50D and are newly initialized: ['esm.pooler.dense.bias', 'esm.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "[2025-02-21 20:26:03,969][src.model.embedders][INFO] - Moving model to cuda\n",
      "[2025-02-21 20:26:04,239][src.model.abstract_components][INFO] - Total memory: 23.58378496GB\n",
      "Memory already allocated: 0.031387648GB\n",
      "[2025-02-21 20:26:04,740][src.model.embedders][INFO] - Per-residue embeddings count: 1122\n",
      "[2025-02-21 20:26:04,740][src.model.composite_model][INFO] - Residue embeddings\n",
      "[2025-02-21 20:26:04,741][src.model.abstract_components][INFO] - Total memory: 23.58378496GB\n",
      "Memory already allocated: 0.043664896GB\n",
      "[2025-02-21 20:26:04,764][src.model.embedders][INFO] - Per-residue embeddings count: 277\n",
      "[2025-02-21 20:26:04,764][src.model.scalers][INFO] - Fitted scaler: PassThroughScaler\n",
      "[2025-02-21 20:26:04,769][src.model.scalers][INFO] - Before standardization - min: 0.0, max: 1.0\n",
      "[2025-02-21 20:26:04,769][src.model.scalers][INFO] - After standardization - min: 0.0, max: 1.0\n",
      "[2025-02-21 20:26:04,769][src.model.scalers][INFO] - Before standardization - min: 0.0, max: 1.0\n",
      "[2025-02-21 20:26:04,769][src.model.scalers][INFO] - After standardization - min: 0.0, max: 1.0\n",
      "[2025-02-21 20:26:04,769][src.model.scalers][INFO] - Before standardization - min: 0.0, max: 1.0\n",
      "[2025-02-21 20:26:04,769][src.model.scalers][INFO] - After standardization - min: 0.0, max: 1.0\n",
      "/nfs_home/users/sbxw/mambaforge/envs/mlbp/lib/python3.10/site-packages/lightning/fabric/plugins/environments/slurm.py:204: The `srun` command is available on your system but is not used. HINT: If your intention is to run Lightning on SLURM, prepend your python command with `srun` like so: srun python /novo/projects/departments/cdd/molecular_ai/sbxw/rep ...\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/nfs_home/users/sbxw/mambaforge/envs/mlbp/lib/python3.10/site-packages/lightning/fabric/plugins/environments/slurm.py:204: The `srun` command is available on your system but is not used. HINT: If your intention is to run Lightning on SLURM, prepend your python command with `srun` like so: srun python /novo/projects/departments/cdd/molecular_ai/sbxw/rep ...\n",
      "[2025-02-21 20:26:06,335][pytorch_lightning.utilities.rank_zero][INFO] - You are using a CUDA device ('NVIDIA L4') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name                  | Type       | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | feature_convolution   | Conv1d     | 307 K  | train\n",
      "1 | attention_convolution | Conv1d     | 307 K  | train\n",
      "2 | softmax               | Softmax    | 0      | train\n",
      "3 | dropout               | Dropout    | 0      | train\n",
      "4 | sigmoid               | Sigmoid    | 0      | train\n",
      "5 | mlp                   | Sequential | 20.6 K | train\n",
      "6 | loss_fxn              | BCELoss    | 0      | train\n",
      "-------------------------------------------------------------\n",
      "635 K     Trainable params\n",
      "0         Non-trainable params\n",
      "635 K     Total params\n",
      "2.543     Total estimated model params size (MB)\n",
      "12        Modules in train mode\n",
      "0         Modules in eval mode\n",
      "/nfs_home/users/sbxw/mambaforge/envs/mlbp/lib/python3.10/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:424: The 'val_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=7` in the `DataLoader` to improve performance.\n",
      "/nfs_home/users/sbxw/mambaforge/envs/mlbp/lib/python3.10/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:424: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=7` in the `DataLoader` to improve performance.\n",
      "[2025-02-21 20:26:10,051][botocore.credentials][INFO] - Found credentials in environment variables.\n",
      "[2025-02-21 20:26:35,778][pytorch_lightning.utilities.rank_zero][INFO] - `Trainer.fit` stopped: `max_epochs=10` reached.\n",
      "üèÉ View run  at: https://datalab.corp.novocorp.net/mlflow/#/experiments/378/runs/99c476f32f3347a693bc88622e97a7a0\n",
      "üß™ View experiment at: https://datalab.corp.novocorp.net/mlflow/#/experiments/378\n",
      "\u001b[31m2025/02/21 20:27:04 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\u001b[0m\n",
      "[2025-02-21 20:27:09,838][src.model.abstract_components][INFO] - MODEL STOPPED BY EARLY STOPPER AT EPOCH 0\n",
      "[2025-02-21 20:27:09,838][src.model.abstract_components][INFO] - BEST MODEL VALIDATION LOSS IS 0.6722960472106934\n",
      "[2025-02-21 20:27:09,838][src.model.abstract_components][INFO] - BEST MODEL SAVED AT /novo/projects/departments/cdd/public/users/ehec/sbxw_files_2/378/99c476f32f3347a693bc88622e97a7a0/checkpoints/epoch=9-step=20.ckpt\n",
      "[2025-02-21 20:27:09,839][src.model.abstract_components][INFO] - FINAL MODEL SAVED AT None\n",
      "[2025-02-21 20:27:10,127][src.model.predictors][INFO] - Moving embeddings to device: cuda\n",
      "[2025-02-21 20:27:10,234][src.model.predictors][INFO] - Optimal cutoff is: 0.45 with MCC: 0.24175942417297044\n",
      "[2025-02-21 20:27:10,245][src.model.predictors][INFO] - Moving embeddings to device: cuda\n",
      "[2025-02-21 20:27:10,253][src.model.predictors][INFO] - Moving embeddings to device: cuda\n",
      "[2025-02-21 20:27:10,254][src.model.scalers][INFO] - Before standardization - min: False, max: True\n",
      "[2025-02-21 20:27:10,254][src.model.scalers][INFO] - After standardization - min: False, max: True\n",
      "[2025-02-21 20:27:10,254][src.model.scalers][INFO] - Before standardization - min: False, max: True\n",
      "[2025-02-21 20:27:10,254][src.model.scalers][INFO] - After standardization - min: False, max: True\n",
      "[2025-02-21 20:27:10,255][src.model.composite_model][INFO] - This is the updated predictor name: lightattention_kernel_size_3_dropout_0.25_conv_dropout_0.25_learning_rate_0.0005_batch_size_1000_max_epochs_10_patience_200_post_attention_mlp_conv1d_output_dim_-1_optimal_cutoff_0.45\n",
      "[2025-02-21 20:27:10,255][src.model.composite_model][INFO] - Composite model name: esm2t68MUR50D_LightAttention_sbxwfibrillationpeptidewaltzdb-train-valserrano-test\n",
      "[2025-02-21 20:27:10,255][src.model.composite_model][INFO] - Best model is: kernel_size_3_dropout_0.25_conv_dropout_0.25_learning_rate_0.0005_batch_size_1000_max_epochs_10_patience_200_post_attention_mlp_conv1d_output_dim_-1_optimal_cutoff_0.45\n",
      "[2025-02-21 20:27:10,255][src.model.composite_model][INFO] - Moving to test mode\n",
      "[2025-02-21 20:27:10,256][src.model.composite_model][INFO] - Composite model name: esm2t68MUR50D_LightAttention_sbxwfibrillationpeptidewaltzdb-train-valserrano-test\n",
      "[2025-02-21 20:27:10,256][src.model.composite_model][INFO] - Saving model: esm2t68MUR50D_LightAttention_sbxwfibrillationpeptidewaltzdb-train-valserrano-test\n",
      "<RunInfo: artifact_uri='s3://nnedl-core-prd-eu-central-1-curated/mlops/378/99c476f32f3347a693bc88622e97a7a0/artifacts', end_time=None, experiment_id='378', lifecycle_stage='active', run_id='99c476f32f3347a693bc88622e97a7a0', run_name='', run_uuid='99c476f32f3347a693bc88622e97a7a0', start_time=1740169561915, status='RUNNING', user_id='sbxw'>\n",
      "[2025-02-21 20:27:14,599][src.model.abstract_components][INFO] - Total memory: 23.58378496GB\n",
      "Memory already allocated: 0.04955648GB\n",
      "[2025-02-21 20:27:14,670][src.model.embedders][INFO] - Per-residue embeddings count: 248\n",
      "[2025-02-21 20:27:14,670][src.model.composite_model][INFO] - Residue embeddings\n",
      "[2025-02-21 20:27:14,673][src.model.predictors][INFO] - Moving embeddings to device: cuda\n",
      "[2025-02-21 20:27:14,677][src.model.scalers][INFO] - Before standardization - min: False, max: True\n",
      "[2025-02-21 20:27:14,678][src.model.scalers][INFO] - After standardization - min: False, max: True\n",
      "sequences: (1122,)\n",
      "sequence_embeddings: 1122\n",
      "predictions: (1122,)\n",
      "predictions_scaled: (1122,)\n",
      "data_split: train\n",
      "labels: (1122,)\n",
      "predictions_probability: (1122,)\n",
      "residue_level_prediction: False\n",
      "sequences: (277,)\n",
      "sequence_embeddings: 277\n",
      "predictions: (277,)\n",
      "predictions_scaled: (277,)\n",
      "data_split: val\n",
      "labels: (277,)\n",
      "predictions_probability: (277,)\n",
      "residue_level_prediction: False\n",
      "sequences: (248,)\n",
      "sequence_embeddings: 248\n",
      "predictions: (248,)\n",
      "predictions_scaled: (248,)\n",
      "data_split: test\n",
      "labels: (248,)\n",
      "predictions_probability: (248,)\n",
      "residue_level_prediction: False\n",
      "[2025-02-21 20:27:16,024][src.model.composite_model][INFO] - Composite model name: esm2t68MUR50D_LightAttention_sbxwfibrillationpeptidewaltzdb-train-valserrano-test\n",
      "[2025-02-21 20:27:16,864][__main__][INFO] - Done!\n",
      "run_id: 99c476f32f3347a693bc88622e97a7a0\n",
      "artifacts: ['model/MLmodel', 'model/checkpoints', 'model/conda.yaml', 'model/data', 'model/python_env.yaml', 'model/requirements.txt']\n",
      "params: {'epochs': '10', 'optimizer_name': 'SGD', 'lr': '0.0005', 'momentum': '0', 'dampening': '0', 'weight_decay': '0', 'nesterov': 'False', 'maximize': 'False', 'foreach': 'None', 'differentiable': 'False', 'fused': 'None', 'embeddings_dim': '320', 'output_dim': '1', 'kernel_size': '3', 'dropout': '0.25', 'conv_dropout': '0.25', 'learning_rate': '0.0005', 'post_attention': 'mlp', 'conv1d_output_dim': '-1', 'residue_prediction_mode': 'False', 'general.run_mode': 'train', 'general.abs_repo_path': 'None', 'general.composite_model_name': 'esm2t68MUR50D_LightAttention_sbxwfibrillationpeptidewaltzdb-train-valserrano-test', 'general.composite_model_path': 'None', 'general.precomputed_embeddings_path': 'None', 'general.random_state': '42', 'dataset.data_name': 'sbxw_fibrillation_peptide_waltzdb-train-val_serrano-test', 'dataset.add_data_columns': 'False', 'dataset.data_columns_dimred': 'False', 'dataset.data_columns_standard': 'False', 'dataset.group_column': 'None', 'dataset.data_scaler': 'RobustScaler', 'dataset.target_scaling': 'None', 'dataset.rbf_encoder': 'RadialBasisFunctionGaussian', 'dataset.rbf_n_kernels': '10', 'dataset.task': 'classification_binary', 'dataset.use_predefined_split': 'True', 'dataset.use_sample_weights': 'False', 'dataset.residue_prediction_labels': 'None', 'dataset.data_split_column': 'data_split', 'dataset.data_split.train': '0.8', 'dataset.data_split.val': '0.0', 'dataset.data_split.test': '0.2', 'embedder.class_name': 'ESM', 'embedder.model_name': 'esm2_t6_8M_UR50D', 'embedder.model_path': 'None', 'embedder.standardize': 'False', 'embedder.scalar_type': 'StandardScaler', 'embedder.hparams': 'None', 'embedder.n_copies': '1', 'embedder.chain_break': 'poly-gly-linker', 'embedder.buffer_scale_factor': '2.0', 'embedder.max_batch_size': '400', 'embedder.simple_batching': 'False', 'embedder.strict': 'True', 'embedder.verbose': 'False', 'embedder.mean_pool': 'False', 'embedder.output_hidden_states': 'False', 'dimred.class_name': 'NoReduction', 'dimred.transform_name': 'None', 'dimred.fraction_variance_explained': 'None', 'predictor.class_name': 'LightAttention', 'predictor.model_name': 'None', 'predictor.model_type': 'classification_binary', 'predictor.mem_per_job': 'None', 'predictor.residue_prediction_mode': 'False', 'predictor.hparams.kernel_size': '3', 'predictor.hparams.dropout': '0.25', 'predictor.hparams.conv_dropout': '0.25', 'predictor.hparams.learning_rate': '0.0005', 'predictor.hparams.batch_size': '1000', 'predictor.hparams.max_epochs': '10', 'predictor.hparams.patience': '200', 'predictor.hparams.post_attention': 'mlp', 'predictor.hparams.conv1d_output_dim': '-1', 'predictor.hparams.optimal_cutoff': '0.5', 'persistence.type': 'lovelace', 'persistence.data_root_folder': '/novo/projects/departments/cdd/molecular_ai/mlbp/data', 'persistence.artifacts_root_folder': '/novo/projects/departments/cdd/molecular_ai/mlbp/artifacts', 'persistence.training_data': 'static_input_data', 'persistence.pretrained_weights': 'static_pretrained_weights', 'mlflow.tracking_uri': 'https://datalab.corp.novocorp.net/mlflow/', 'mlflow.experiment_name': 'ML-BP-Domino', 'plots.generate_plots': 'False', 'model_type': 'classification_binary'}\n",
      "metrics: {'val_loss': 0.6722960472106934, 'train.accuracy': 0.5169340463458111, 'train.precision': 0.4028776978417266, 'train.recall': 0.687960687960688, 'train.specificity': 0.4195804195804196, 'train.f_score': 0.5081669691470054, 'train.matthews_corr_coef': 0.10649234502599098, 'train.optimal_mcc': 0.1588864982783678, 'train.optimal_mcc_cutoff': 0.49, 'train.balanced_accuracy': 0.5537705537705537, 'train.roc_auc_score': 0.5930001202728477, 'val.accuracy': 0.47653429602888087, 'val.precision': 0.3699421965317919, 'val.recall': 0.64, 'val.specificity': 0.384180790960452, 'val.f_score': 0.46886446886446886, 'val.matthews_corr_coef': 0.023983768006364117, 'val.optimal_mcc': 0.13125485028599299, 'val.optimal_mcc_cutoff': 0.3, 'val.balanced_accuracy': 0.5120903954802261, 'val.roc_auc_score': 0.5215254237288136, 'train.loss_step': 0.6521094441413879, 'epoch': 9.0, 'test.accuracy': 0.5282258064516129, 'test.precision': 0.36774193548387096, 'test.recall': 0.75, 'test.specificity': 0.43023255813953487, 'test.f_score': 0.4935064935064935, 'test.matthews_corr_coef': 0.17163147829313036, 'test.optimal_mcc': 0.19106586058692035, 'test.optimal_mcc_cutoff': 0.48, 'test.balanced_accuracy': 0.5901162790697674, 'test.roc_auc_score': 0.6090881272949815, 'val.loss': 0.6722960472106934, 'train.loss': 0.6749476194381714, 'train.loss_epoch': 0.6749476194381714}\n",
      "tags: {'Mode': 'training'}\n",
      "results stored in /novo/projects/departments/cdd/molecular_ai/mlbp/artifacts/2025-02-21-2026_/esm2t68MUR50D_LightAttention_sbxwfibrillationpeptidewaltzdb-train-valserrano-test_stats.csv\n",
      "s3://nnedl-core-prd-eu-central-1-curated/mlops/378/99c476f32f3347a693bc88622e97a7a0/artifacts\n",
      "\u001b[34mSystem information\u001b[0m: Linux #70~20.04.1-Ubuntu SMP Fri Jun 14 15:42:13 UTC 2024\n",
      "\u001b[34mPython version\u001b[0m: 3.10.14\n",
      "\u001b[34mMLflow version\u001b[0m: 2.20.2\n",
      "\u001b[34mMLflow module location\u001b[0m: /nfs_home/users/sbxw/mambaforge/envs/mlbp/lib/python3.10/site-packages/mlflow/__init__.py\n",
      "\u001b[34mTracking URI\u001b[0m: https://datalab.corp.novocorp.net/mlflow/\n",
      "\u001b[34mRegistry URI\u001b[0m: https://datalab.corp.novocorp.net/mlflow/\n",
      "\u001b[34mActive experiment ID\u001b[0m: 378\n",
      "\u001b[34mActive run ID\u001b[0m: 99c476f32f3347a693bc88622e97a7a0\n",
      "\u001b[34mActive run artifact URI\u001b[0m: s3://nnedl-core-prd-eu-central-1-curated/mlops/378/99c476f32f3347a693bc88622e97a7a0/artifacts\n",
      "\u001b[34mMLflow environment variables\u001b[0m: \n",
      "  MLFLOW_EXPERIMENT_ID: 378\n",
      "  MLFLOW_TRACKING_URI: https://datalab.corp.novocorp.net/mlflow/\n",
      "\u001b[34mMLflow dependencies\u001b[0m: \n",
      "  Flask: 2.2.5\n",
      "  Jinja2: 3.1.4\n",
      "  aiohttp: 3.9.5\n",
      "  alembic: 1.13.1\n",
      "  boto3: 1.36.23\n",
      "  botocore: 1.36.23\n",
      "  docker: 7.0.0\n",
      "  graphene: 3.3\n",
      "  gunicorn: 22.0.0\n",
      "  markdown: 3.6\n",
      "  matplotlib: 3.9.0\n",
      "  mlflow-skinny: 2.20.2\n",
      "  numpy: 1.26.4\n",
      "  pandas: 2.2.2\n",
      "  pyarrow: 15.0.2\n",
      "  scikit-learn: 1.4.2\n",
      "  scipy: 1.13.0\n",
      "  sqlalchemy: 2.0.30\n",
      "  virtualenv: 20.26.2\n",
      "None\n",
      "üèÉ View run  at: https://datalab.corp.novocorp.net/mlflow/#/experiments/378/runs/99c476f32f3347a693bc88622e97a7a0\n",
      "üß™ View experiment at: https://datalab.corp.novocorp.net/mlflow/#/experiments/378\n"
     ]
    }
   ],
   "source": [
    "%env AWS_ACCESS_KEY_ID=ASIATIJCHR3KA5YYSX4C\n",
    "%env AWS_SECRET_ACCESS_KEY=aPDRW7A6aUdgjnE2CdQeYG2IpZseMrimkIxc0H//\n",
    "%env AWS_SESSION_TOKEN=FwoGZXIvYXdzEMX//////////wEaDONh6B2GwAQwnkGFRSL0AwI0ymgCmmLalzZXga+CfvhC0RiboEHABvkZiIl6GOVwtQtrORvwMGFLYd5RwDFo+fKXDl5P3zXzI0hnN2nHWf9e+jNJ1wZVVr7JEmw1XZwZn7zyOMG0skT8+BYhtkkZPYUhZB+DPOrrszHfomSSbBuox+/5P/7M492NM2zMnLRPomrOHsCMpc5rTlpv2Qp/zMgP0wKud0NJLjgq46dZkJ7rr7STpYwqc3x+gQ0peDIDGWqtdgeX75v74lpSCBgLU1YwmhUFBBenqDWxFPnYZ+81Q8DAuwtGFABQAUHScu04lM352nNNDTM21nGW50KMXqubIFyBvNcwP7hK61HcxvDZtdXkOc0o/Rg/oVkfa3INcmwV3P8g8qsjmrWhWyfCi3zeXJmH4QJl4rksNLCPMNugzkljoFOxhXFW4dzcfjk/pIZ2RohVcbwsiVHpwR9SXVM+0YzFE2MYSSUomqt5ahlxuUyK2IAJRvggiGOlSBN0T3ADN45y0U+JIFpl92MoIGkaW6Tr0RNT8eIOEGPzBB4g9FILg+CfYT1tMPaVJmlKGkRY+/vJkaE3h4DelnO49JhB1wRJgdtwZlBuFgqRRAPatgbZwhG79EwkmwTTXd5i5AxMeqQymz8jVurFoMBfALEuASskEoLoZIIc65PA+n0xz422KLCh470GMpQBMYrXpVze1m5G2VeOYzklnn6hsbiLu63zI7T4XX5GLExc4eoffUYBO4hlZAvEKYKJoR1Rx+iNlFz2RoQNQAHbfydjTrp7srnbSTGcwtJP3pyxxuqwXIHpWw0wHWx0mAuxWrujzsSyReGInQd+bDpRYsHUTZBd7aHDPrUK7ctcczNzIiVwgFD8g1hroB4ZCAucGRTjjw==\n",
    "\n",
    "repo_dir = '/novo/projects/departments/cdd/molecular_ai/sbxw/repos/ML-BP-Domino'\n",
    "conda_env_name = 'mlbp'\n",
    "\n",
    "# Create command (single set of params)\n",
    "cmd = [\n",
    "    f\"/nfs_home/users/sbxw/mambaforge/condabin/conda run --no-capture-output -n {conda_env_name} python\",\n",
    "    f\"{repo_dir}/src/cli/training.py\",\n",
    "    \"mlflow=datalab\", \"persistence=lovelace\",\n",
    "    \"dataset.use_predefined_split=true\",\n",
    "    \"dataset.data_name=sbxw_fibrillation_peptide_waltzdb-train-val_serrano-test\", \"dataset.task=classification_binary\", \n",
    "    \"embedder=esm2_t6_8M\",\"embedder.mean_pool=false\",\n",
    "    \"dimred=noreduction\",\n",
    "    \"predictor=lightattention\",\n",
    "    \"predictor.hparams.kernel_size=3\", \"predictor.hparams.max_epochs=10\", \"predictor.hparams.patience=200\",\n",
    "    \"predictor.hparams.batch_size=1000\", \"predictor.hparams.learning_rate=0.0005\",\n",
    "    \"mlflow.experiment_name=ML-BP-Domino\",\n",
    "    \"plots.generate_plots=false\",\n",
    "]\n",
    "\n",
    "command_str = \" \".join(cmd)\n",
    "print(command_str)\n",
    "!PYTHONPATH=repo_dir; $command_str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "71e34511-5732-4ab3-b614-93dee2891218",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: AWS_ACCESS_KEY_ID=ASIATIJCHR3KA5YYSX4C\n",
      "env: AWS_SECRET_ACCESS_KEY=aPDRW7A6aUdgjnE2CdQeYG2IpZseMrimkIxc0H//\n",
      "env: AWS_SESSION_TOKEN=FwoGZXIvYXdzEMX//////////wEaDONh6B2GwAQwnkGFRSL0AwI0ymgCmmLalzZXga+CfvhC0RiboEHABvkZiIl6GOVwtQtrORvwMGFLYd5RwDFo+fKXDl5P3zXzI0hnN2nHWf9e+jNJ1wZVVr7JEmw1XZwZn7zyOMG0skT8+BYhtkkZPYUhZB+DPOrrszHfomSSbBuox+/5P/7M492NM2zMnLRPomrOHsCMpc5rTlpv2Qp/zMgP0wKud0NJLjgq46dZkJ7rr7STpYwqc3x+gQ0peDIDGWqtdgeX75v74lpSCBgLU1YwmhUFBBenqDWxFPnYZ+81Q8DAuwtGFABQAUHScu04lM352nNNDTM21nGW50KMXqubIFyBvNcwP7hK61HcxvDZtdXkOc0o/Rg/oVkfa3INcmwV3P8g8qsjmrWhWyfCi3zeXJmH4QJl4rksNLCPMNugzkljoFOxhXFW4dzcfjk/pIZ2RohVcbwsiVHpwR9SXVM+0YzFE2MYSSUomqt5ahlxuUyK2IAJRvggiGOlSBN0T3ADN45y0U+JIFpl92MoIGkaW6Tr0RNT8eIOEGPzBB4g9FILg+CfYT1tMPaVJmlKGkRY+/vJkaE3h4DelnO49JhB1wRJgdtwZlBuFgqRRAPatgbZwhG79EwkmwTTXd5i5AxMeqQymz8jVurFoMBfALEuASskEoLoZIIc65PA+n0xz422KLCh470GMpQBMYrXpVze1m5G2VeOYzklnn6hsbiLu63zI7T4XX5GLExc4eoffUYBO4hlZAvEKYKJoR1Rx+iNlFz2RoQNQAHbfydjTrp7srnbSTGcwtJP3pyxxuqwXIHpWw0wHWx0mAuxWrujzsSyReGInQd+bDpRYsHUTZBd7aHDPrUK7ctcczNzIiVwgFD8g1hroB4ZCAucGRTjjw==\n",
      "/nfs_home/users/sbxw/mambaforge/condabin/conda run --no-capture-output -n mlbp python /novo/projects/departments/cdd/molecular_ai/sbxw/repos/ML-BP-Domino/src/cli/training.py mlflow=datalab persistence=lovelace dataset.use_predefined_split=true dataset.data_name=sbxw_fibrillation_peptide_waltzdb-train-val_amypro27-test_randpadded10x dataset.task=classification_binary dataset.residue_prediction_labels=res_value_bool embedder=esm2_t6_8M embedder.mean_pool=false dimred=noreduction predictor=lightattention predictor.residue_prediction_mode=true predictor.hparams.kernel_size=3 predictor.hparams.max_epochs=10 predictor.hparams.patience=200 predictor.hparams.batch_size=1000 predictor.hparams.learning_rate=0.0005 mlflow.experiment_name=ML-BP-Domino plots.generate_plots=false\n",
      "2025-02-21 20:35:02.787558: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2025-02-21 20:35:02.787603: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2025-02-21 20:35:02.789126: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2025-02-21 20:35:02.796578: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2025-02-21 20:35:06.498751: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "[2025-02-21 20:35:18,359][__main__][INFO] - Workflow configuration:\n",
      "\n",
      "general:\n",
      "  run_mode: train\n",
      "  abs_repo_path: null\n",
      "  composite_model_name: null\n",
      "  composite_model_path: null\n",
      "  precomputed_embeddings_path: null\n",
      "  random_state: 42\n",
      "dataset:\n",
      "  data_name: sbxw_fibrillation_peptide_waltzdb-train-val_amypro27-test_randpadded10x\n",
      "  add_data_columns: false\n",
      "  data_columns_dimred: false\n",
      "  data_columns_standard: false\n",
      "  group_column: null\n",
      "  data_scaler: RobustScaler\n",
      "  target_scaling: null\n",
      "  rbf_encoder: RadialBasisFunctionGaussian\n",
      "  rbf_n_kernels: 10\n",
      "  task: classification_binary\n",
      "  use_predefined_split: true\n",
      "  use_sample_weights: false\n",
      "  residue_prediction_labels: res_value_bool\n",
      "  data_split_column: data_split\n",
      "  data_split:\n",
      "    train: 0.8\n",
      "    val: 0.0\n",
      "    test: 0.2\n",
      "embedder:\n",
      "  class_name: ESM\n",
      "  model_name: esm2_t6_8M_UR50D\n",
      "  model_path: null\n",
      "  standardize: false\n",
      "  scalar_type: StandardScaler\n",
      "  hparams: null\n",
      "  n_copies: 1\n",
      "  chain_break: poly-gly-linker\n",
      "  buffer_scale_factor: 2.0\n",
      "  max_batch_size: 400\n",
      "  simple_batching: false\n",
      "  strict: true\n",
      "  verbose: false\n",
      "  mean_pool: false\n",
      "  output_hidden_states: false\n",
      "dimred:\n",
      "  class_name: NoReduction\n",
      "  transform_name: null\n",
      "  fraction_variance_explained: null\n",
      "predictor:\n",
      "  class_name: LightAttention\n",
      "  model_name: null\n",
      "  model_type: classification_binary\n",
      "  mem_per_job: null\n",
      "  residue_prediction_mode: true\n",
      "  hparams:\n",
      "    kernel_size: 3\n",
      "    dropout: 0.25\n",
      "    conv_dropout: 0.25\n",
      "    learning_rate: 0.0005\n",
      "    batch_size: 1000\n",
      "    max_epochs: 10\n",
      "    patience: 200\n",
      "    post_attention: mlp\n",
      "    conv1d_output_dim: -1\n",
      "    optimal_cutoff: 0.5\n",
      "persistence:\n",
      "  type: lovelace\n",
      "  data_root_folder: /novo/projects/departments/cdd/molecular_ai/mlbp/data\n",
      "  artifacts_root_folder: /novo/projects/departments/cdd/molecular_ai/mlbp/artifacts\n",
      "  training_data: static_input_data\n",
      "  pretrained_weights: static_pretrained_weights\n",
      "mlflow:\n",
      "  tracking_uri: https://datalab.corp.novocorp.net/mlflow/\n",
      "  experiment_name: ML-BP-Domino\n",
      "plots:\n",
      "  generate_plots: false\n",
      "\n",
      "[2025-02-21 20:35:18,361][src.model.dimred][INFO] - Load class (NoReduction): NoReduction\n",
      "[2025-02-21 20:35:18,361][src.model.abstract_components][INFO] - Load class (DimRed Model): NoReduction\n",
      "[2025-02-21 20:35:18,361][src.model.predictors][INFO] - Load class (LightAttention): LightAttention\n",
      "[2025-02-21 20:35:18,361][src.model.abstract_components][INFO] - Load class (TorchPredictorModel): LightAttention\n",
      "[2025-02-21 20:35:18,361][src.model.abstract_components][INFO] - Load class (Predictor Model): LightAttention\n",
      "[2025-02-21 20:35:18,362][src.model.composite_model][INFO] - Composite model name: esm2t68MUR50D_LightAttention_sbxwfibrillationpeptidewaltzdb-train-valamypro27-testrandpadded10x\n",
      "[2025-02-21 20:35:18,362][src.model.composite_model][INFO] - Initialized model: esm2t68MUR50D_LightAttention_sbxwfibrillationpeptidewaltzdb-train-valamypro27-testrandpadded10x in run_mode = train\n",
      "[2025-02-21 20:35:18,381][src.helpers.dataset][INFO] - Loading file: /novo/projects/departments/cdd/molecular_ai/mlbp/data/static_input_data/sbxw_fibrillation_peptide_waltzdb-train-val_amypro27-test_randpadded10x.csv\n",
      "[2025-02-21 20:35:18,382][src.helpers.dataset][INFO] - Using group_column \"None\".\n",
      "[2025-02-21 20:35:18,382][src.helpers.dataset][INFO] - No additional data columns found while parsing.\n",
      "[2025-02-21 20:35:18,389][src.helpers.dataset][INFO] - Select data according to predetermined splits in the dataframe, train (N = 11220), validation (N = 2770), test (N = 27)\n",
      "[2025-02-21 20:35:18,389][src.helpers.dataset][INFO] - Loaded columns: {}\n",
      "[2025-02-21 20:35:18,392][src.helpers.mlflow_helpers][INFO] - Setting up MLflow...\n",
      "[2025-02-21 20:35:18,392][src.helpers.mlflow_helpers][INFO] - Experiment name: ML-BP-Domino\n",
      "[2025-02-21 20:35:18,392][src.helpers.mlflow_helpers][INFO] - Setting MLflow tracking URI to https://datalab.corp.novocorp.net/mlflow/\n",
      "[2025-02-21 20:35:19,769][src.helpers.mlflow_helpers][INFO] - Setting MLflow experiment to ML-BP-Domino\n",
      "[2025-02-21 20:35:21,025][__main__][INFO] - Compute embeddings on-the-fly and train model\n",
      "[2025-02-21 20:35:21,027][src.model.abstract_components][INFO] - Load class (LLMEmbedderModel): ESM\n",
      "[2025-02-21 20:35:21,027][src.model.abstract_components][INFO] - Load class (Embedder Model): ESM\n",
      "[2025-02-21 20:35:21,028][src.model.embedders][INFO] - Loading model: esm2_t6_8M_UR50D, will extract embeddings from 6-th layer\n",
      "Some weights of EsmModel were not initialized from the model checkpoint at facebook/esm2_t6_8M_UR50D and are newly initialized: ['esm.pooler.dense.bias', 'esm.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "[2025-02-21 20:35:21,862][src.model.embedders][INFO] - Moving model to cuda\n",
      "[2025-02-21 20:35:22,385][src.model.abstract_components][INFO] - Total memory: 23.58378496GB\n",
      "Memory already allocated: 0.031387648GB\n",
      "[2025-02-21 20:35:24,711][src.model.embedders][INFO] - Per-residue embeddings count: 11220\n",
      "[2025-02-21 20:35:24,711][src.model.composite_model][INFO] - Residue embeddings\n",
      "[2025-02-21 20:35:24,713][src.model.abstract_components][INFO] - Total memory: 23.58378496GB\n",
      "Memory already allocated: 0.039919616GB\n",
      "[2025-02-21 20:35:25,202][src.model.embedders][INFO] - Per-residue embeddings count: 2770\n",
      "[2025-02-21 20:35:25,202][src.model.scalers][INFO] - Fitted scaler: PassThroughScaler\n",
      "[2025-02-21 20:35:25,203][src.model.scalers][INFO] - Before standardization - min: 00000000, max: 01111110000000000\n",
      "[2025-02-21 20:35:25,203][src.model.scalers][INFO] - After standardization - min: 00000000, max: 01111110000000000\n",
      "[2025-02-21 20:35:25,203][src.model.scalers][INFO] - Before standardization - min: 00000000, max: 01111110000000000\n",
      "[2025-02-21 20:35:25,204][src.model.scalers][INFO] - After standardization - min: 00000000, max: 01111110000000000\n",
      "[2025-02-21 20:35:25,204][src.model.scalers][INFO] - Before standardization - min: 000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000001111111111111111110000000000000000000000000000000000000011111111111111111100000000000000000000001111111111111111111111111111111100000000000000000000000000000000000000000, max: 111111111111111111111111111110000000000000000000000000000000000000000000000000000000000000000000000011111111111111111100000000000000000000000000000000000\n",
      "[2025-02-21 20:35:25,204][src.model.scalers][INFO] - After standardization - min: 000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000001111111111111111110000000000000000000000000000000000000011111111111111111100000000000000000000001111111111111111111111111111111100000000000000000000000000000000000000000, max: 111111111111111111111111111110000000000000000000000000000000000000000000000000000000000000000000000011111111111111111100000000000000000000000000000000000\n",
      "/nfs_home/users/sbxw/mambaforge/envs/mlbp/lib/python3.10/site-packages/lightning/fabric/plugins/environments/slurm.py:204: The `srun` command is available on your system but is not used. HINT: If your intention is to run Lightning on SLURM, prepend your python command with `srun` like so: srun python /novo/projects/departments/cdd/molecular_ai/sbxw/rep ...\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/nfs_home/users/sbxw/mambaforge/envs/mlbp/lib/python3.10/site-packages/lightning/fabric/plugins/environments/slurm.py:204: The `srun` command is available on your system but is not used. HINT: If your intention is to run Lightning on SLURM, prepend your python command with `srun` like so: srun python /novo/projects/departments/cdd/molecular_ai/sbxw/rep ...\n",
      "[2025-02-21 20:35:26,938][pytorch_lightning.utilities.rank_zero][INFO] - You are using a CUDA device ('NVIDIA L4') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name                  | Type       | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | feature_convolution   | Conv1d     | 307 K  | train\n",
      "1 | attention_convolution | Conv1d     | 307 K  | train\n",
      "2 | softmax               | Softmax    | 0      | train\n",
      "3 | dropout               | Dropout    | 0      | train\n",
      "4 | sigmoid               | Sigmoid    | 0      | train\n",
      "5 | mlp                   | Sequential | 10.4 K | train\n",
      "6 | loss_fxn              | BCELoss    | 0      | train\n",
      "-------------------------------------------------------------\n",
      "625 K     Trainable params\n",
      "0         Non-trainable params\n",
      "625 K     Total params\n",
      "2.502     Total estimated model params size (MB)\n",
      "12        Modules in train mode\n",
      "0         Modules in eval mode\n",
      "/nfs_home/users/sbxw/mambaforge/envs/mlbp/lib/python3.10/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:424: The 'val_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=7` in the `DataLoader` to improve performance.\n",
      "/nfs_home/users/sbxw/mambaforge/envs/mlbp/lib/python3.10/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:424: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=7` in the `DataLoader` to improve performance.\n",
      "[2025-02-21 20:35:34,230][botocore.credentials][INFO] - Found credentials in environment variables.\n",
      "[2025-02-21 20:36:44,405][pytorch_lightning.utilities.rank_zero][INFO] - `Trainer.fit` stopped: `max_epochs=10` reached.\n",
      "üèÉ View run  at: https://datalab.corp.novocorp.net/mlflow/#/experiments/378/runs/f46088299bb24cd4b9702026bc3bc197\n",
      "üß™ View experiment at: https://datalab.corp.novocorp.net/mlflow/#/experiments/378\n",
      "\u001b[31m2025/02/21 20:37:13 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\u001b[0m\n",
      "[2025-02-21 20:37:22,357][src.model.abstract_components][INFO] - MODEL STOPPED BY EARLY STOPPER AT EPOCH 0\n",
      "[2025-02-21 20:37:22,357][src.model.abstract_components][INFO] - BEST MODEL VALIDATION LOSS IS 0.5608060359954834\n",
      "[2025-02-21 20:37:22,357][src.model.abstract_components][INFO] - BEST MODEL SAVED AT /novo/projects/departments/cdd/public/users/ehec/sbxw_files_2/378/f46088299bb24cd4b9702026bc3bc197/checkpoints/epoch=9-step=120.ckpt\n",
      "[2025-02-21 20:37:22,357][src.model.abstract_components][INFO] - FINAL MODEL SAVED AT None\n",
      "[2025-02-21 20:37:22,678][src.model.predictors][INFO] - Moving embeddings to device: cuda\n",
      "[2025-02-21 20:37:23,619][src.model.predictors][INFO] - Optimal cutoff is: 0.71 with MCC: 0.0031666614567243405\n",
      "[2025-02-21 20:37:23,750][src.model.predictors][INFO] - Moving embeddings to device: cuda\n",
      "[2025-02-21 20:37:23,894][src.model.predictors][INFO] - Moving embeddings to device: cuda\n",
      "[2025-02-21 20:37:23,923][src.model.scalers][INFO] - Before standardization - min: False, max: True\n",
      "[2025-02-21 20:37:23,924][src.model.scalers][INFO] - After standardization - min: False, max: True\n",
      "[2025-02-21 20:37:23,924][src.model.scalers][INFO] - Before standardization - min: False, max: True\n",
      "[2025-02-21 20:37:23,924][src.model.scalers][INFO] - After standardization - min: False, max: True\n",
      "[2025-02-21 20:37:23,925][src.model.composite_model][INFO] - This is the updated predictor name: lightattention_kernel_size_3_dropout_0.25_conv_dropout_0.25_learning_rate_0.0005_batch_size_1000_max_epochs_10_patience_200_post_attention_mlp_conv1d_output_dim_-1_optimal_cutoff_0.71\n",
      "[2025-02-21 20:37:23,925][src.model.composite_model][INFO] - Composite model name: esm2t68MUR50D_LightAttention_sbxwfibrillationpeptidewaltzdb-train-valamypro27-testrandpadded10x\n",
      "[2025-02-21 20:37:23,925][src.model.composite_model][INFO] - Best model is: kernel_size_3_dropout_0.25_conv_dropout_0.25_learning_rate_0.0005_batch_size_1000_max_epochs_10_patience_200_post_attention_mlp_conv1d_output_dim_-1_optimal_cutoff_0.71\n",
      "[2025-02-21 20:37:23,925][src.model.composite_model][INFO] - Moving to test mode\n",
      "[2025-02-21 20:37:23,925][src.model.composite_model][INFO] - Composite model name: esm2t68MUR50D_LightAttention_sbxwfibrillationpeptidewaltzdb-train-valamypro27-testrandpadded10x\n",
      "[2025-02-21 20:37:23,926][src.model.composite_model][INFO] - Saving model: esm2t68MUR50D_LightAttention_sbxwfibrillationpeptidewaltzdb-train-valamypro27-testrandpadded10x\n",
      "<RunInfo: artifact_uri='s3://nnedl-core-prd-eu-central-1-curated/mlops/378/f46088299bb24cd4b9702026bc3bc197/artifacts', end_time=None, experiment_id='378', lifecycle_stage='active', run_id='f46088299bb24cd4b9702026bc3bc197', run_name='', run_uuid='f46088299bb24cd4b9702026bc3bc197', start_time=1740170120035, status='RUNNING', user_id='sbxw'>\n",
      "[2025-02-21 20:37:46,484][src.model.abstract_components][INFO] - Total memory: 23.58378496GB\n",
      "Memory already allocated: 0.396289536GB\n",
      "[2025-02-21 20:37:46,717][src.model.embedders][INFO] - Per-residue embeddings count: 27\n",
      "[2025-02-21 20:37:46,717][src.model.composite_model][INFO] - Residue embeddings\n",
      "[2025-02-21 20:37:46,724][src.model.predictors][INFO] - Moving embeddings to device: cuda\n",
      "/nfs_home/users/sbxw/mambaforge/envs/mlbp/lib/python3.10/site-packages/torch/nn/modules/conv.py:306: UserWarning: Plan failed with a cudnnException: CUDNN_BACKEND_EXECUTION_PLAN_DESCRIPTOR: cudnnFinalize Descriptor Failed cudnn_status: CUDNN_STATUS_NOT_SUPPORTED (Triggered internally at ../aten/src/ATen/native/cudnn/Conv_v8.cpp:919.)\n",
      "  return F.conv1d(input, weight, bias, self.stride,\n",
      "[2025-02-21 20:37:46,735][src.model.scalers][INFO] - Before standardization - min: False, max: True\n",
      "[2025-02-21 20:37:46,735][src.model.scalers][INFO] - After standardization - min: False, max: True\n",
      "sequences: (11220,)\n",
      "sequence_embeddings: 11220\n",
      "predictions: (11220, 26)\n",
      "predictions_scaled: (11220, 26)\n",
      "data_split: train\n",
      "labels: (11220,)\n",
      "predictions_probability: (11220, 26)\n",
      "residue_level_prediction: True\n",
      "sequences: (2770,)\n",
      "sequence_embeddings: 2770\n",
      "predictions: (2770, 26)\n",
      "predictions_scaled: (2770, 26)\n",
      "data_split: val\n",
      "labels: (2770,)\n",
      "predictions_probability: (2770, 26)\n",
      "residue_level_prediction: True\n",
      "sequences: (27,)\n",
      "sequence_embeddings: 27\n",
      "predictions: (27, 660)\n",
      "predictions_scaled: (27, 660)\n",
      "data_split: test\n",
      "labels: (27,)\n",
      "predictions_probability: (27, 660)\n",
      "residue_level_prediction: True\n",
      "[2025-02-21 20:37:52,875][src.model.composite_model][INFO] - Composite model name: esm2t68MUR50D_LightAttention_sbxwfibrillationpeptidewaltzdb-train-valamypro27-testrandpadded10x\n",
      "[2025-02-21 20:38:00,728][__main__][INFO] - Done!\n",
      "run_id: f46088299bb24cd4b9702026bc3bc197\n",
      "artifacts: ['model/MLmodel', 'model/checkpoints', 'model/conda.yaml', 'model/data', 'model/python_env.yaml', 'model/requirements.txt']\n",
      "params: {'general.run_mode': 'train', 'general.abs_repo_path': 'None', 'general.composite_model_name': 'esm2t68MUR50D_LightAttention_sbxwfibrillationpeptidewaltzdb-train-valamypro27-testrandpadded10x', 'general.composite_model_path': 'None', 'general.precomputed_embeddings_path': 'None', 'general.random_state': '42', 'dataset.data_name': 'sbxw_fibrillation_peptide_waltzdb-train-val_amypro27-test_randpadded10x', 'dataset.add_data_columns': 'False', 'dataset.data_columns_dimred': 'False', 'dataset.data_columns_standard': 'False', 'dataset.group_column': 'None', 'dataset.data_scaler': 'RobustScaler', 'dataset.target_scaling': 'None', 'dataset.rbf_encoder': 'RadialBasisFunctionGaussian', 'dataset.rbf_n_kernels': '10', 'dataset.task': 'classification_binary', 'dataset.use_predefined_split': 'True', 'dataset.use_sample_weights': 'False', 'dataset.residue_prediction_labels': 'res_value_bool', 'dataset.data_split_column': 'data_split', 'dataset.data_split.train': '0.8', 'dataset.data_split.val': '0.0', 'dataset.data_split.test': '0.2', 'embedder.class_name': 'ESM', 'embedder.model_name': 'esm2_t6_8M_UR50D', 'embedder.model_path': 'None', 'embedder.standardize': 'False', 'embedder.scalar_type': 'StandardScaler', 'embedder.hparams': 'None', 'embedder.n_copies': '1', 'embedder.chain_break': 'poly-gly-linker', 'embedder.buffer_scale_factor': '2.0', 'embedder.max_batch_size': '400', 'embedder.simple_batching': 'False', 'embedder.strict': 'True', 'embedder.verbose': 'False', 'embedder.mean_pool': 'False', 'embedder.output_hidden_states': 'False', 'dimred.class_name': 'NoReduction', 'dimred.transform_name': 'None', 'dimred.fraction_variance_explained': 'None', 'predictor.class_name': 'LightAttention', 'embeddings_dim': '320', 'output_dim': '1', 'kernel_size': '3', 'dropout': '0.25', 'conv_dropout': '0.25', 'learning_rate': '0.0005', 'post_attention': 'mlp', 'conv1d_output_dim': '-1', 'residue_prediction_mode': 'True', 'epochs': '10', 'optimizer_name': 'SGD', 'lr': '0.0005', 'momentum': '0', 'dampening': '0', 'weight_decay': '0', 'nesterov': 'False', 'maximize': 'False', 'foreach': 'None', 'differentiable': 'False', 'fused': 'None', 'predictor.model_name': 'None', 'predictor.model_type': 'classification_binary', 'predictor.mem_per_job': 'None', 'predictor.residue_prediction_mode': 'True', 'predictor.hparams.kernel_size': '3', 'predictor.hparams.dropout': '0.25', 'predictor.hparams.conv_dropout': '0.25', 'predictor.hparams.learning_rate': '0.0005', 'predictor.hparams.batch_size': '1000', 'predictor.hparams.max_epochs': '10', 'predictor.hparams.patience': '200', 'predictor.hparams.post_attention': 'mlp', 'predictor.hparams.conv1d_output_dim': '-1', 'predictor.hparams.optimal_cutoff': '0.5', 'persistence.type': 'lovelace', 'persistence.data_root_folder': '/novo/projects/departments/cdd/molecular_ai/mlbp/data', 'persistence.artifacts_root_folder': '/novo/projects/departments/cdd/molecular_ai/mlbp/artifacts', 'persistence.training_data': 'static_input_data', 'persistence.pretrained_weights': 'static_pretrained_weights', 'mlflow.tracking_uri': 'https://datalab.corp.novocorp.net/mlflow/', 'mlflow.experiment_name': 'ML-BP-Domino', 'plots.generate_plots': 'False', 'model_type': 'classification_binary'}\n",
      "metrics: {'train.loss_step': 0.5879999399185181, 'train.loss': 0.585083544254303, 'train.loss_epoch': 0.585083544254303, 'epoch': 9.0, 'val.accuracy': 0.8722522216080616, 'val.precision': 0.0, 'val.recall': 0.0, 'val.specificity': 0.9997806910668161, 'val.f_score': 0.0, 'val.matthews_corr_coef': -0.0052895766433425405, 'val.optimal_mcc': 0.0024933447895292577, 'val.optimal_mcc_cutoff': 0.15, 'val.balanced_accuracy': 0.49989034553340805, 'val.roc_auc_score': 0.4836582009357181, 'val_loss': 0.5659210085868835, 'test.accuracy': 0.7967516354613129, 'test.precision': 0.0, 'test.recall': 0.0, 'test.specificity': 0.998868778280543, 'test.f_score': 0.0, 'val.loss': 0.5608060359954834, 'test.matthews_corr_coef': -0.015136213637392894, 'test.optimal_mcc': 0.0, 'test.optimal_mcc_cutoff': 0.0, 'test.balanced_accuracy': 0.4994343891402715, 'test.roc_auc_score': 0.45882296190922983, 'train.accuracy': 0.8711354597413543, 'train.precision': 0.022222222222222223, 'train.recall': 4.095004095004095e-05, 'train.specificity': 0.9997340023577064, 'train.f_score': 8.174943797261394e-05, 'train.matthews_corr_coef': -0.00489431303653257, 'train.optimal_mcc': 0.0008818574449684712, 'train.optimal_mcc_cutoff': 0.12, 'train.balanced_accuracy': 0.4998874761993282, 'train.roc_auc_score': 0.48533738721780917}\n",
      "tags: {'Mode': 'training'}\n",
      "results stored in /novo/projects/departments/cdd/molecular_ai/mlbp/artifacts/2025-02-21-2035_/esm2t68MUR50D_LightAttention_sbxwfibrillationpeptidewaltzdb-train-valamypro27-testrandpadded10x_stats.csv\n",
      "s3://nnedl-core-prd-eu-central-1-curated/mlops/378/f46088299bb24cd4b9702026bc3bc197/artifacts\n",
      "\u001b[34mSystem information\u001b[0m: Linux #70~20.04.1-Ubuntu SMP Fri Jun 14 15:42:13 UTC 2024\n",
      "\u001b[34mPython version\u001b[0m: 3.10.14\n",
      "\u001b[34mMLflow version\u001b[0m: 2.20.2\n",
      "\u001b[34mMLflow module location\u001b[0m: /nfs_home/users/sbxw/mambaforge/envs/mlbp/lib/python3.10/site-packages/mlflow/__init__.py\n",
      "\u001b[34mTracking URI\u001b[0m: https://datalab.corp.novocorp.net/mlflow/\n",
      "\u001b[34mRegistry URI\u001b[0m: https://datalab.corp.novocorp.net/mlflow/\n",
      "\u001b[34mActive experiment ID\u001b[0m: 378\n",
      "\u001b[34mActive run ID\u001b[0m: f46088299bb24cd4b9702026bc3bc197\n",
      "\u001b[34mActive run artifact URI\u001b[0m: s3://nnedl-core-prd-eu-central-1-curated/mlops/378/f46088299bb24cd4b9702026bc3bc197/artifacts\n",
      "\u001b[34mMLflow environment variables\u001b[0m: \n",
      "  MLFLOW_EXPERIMENT_ID: 378\n",
      "  MLFLOW_TRACKING_URI: https://datalab.corp.novocorp.net/mlflow/\n",
      "\u001b[34mMLflow dependencies\u001b[0m: \n",
      "  Flask: 2.2.5\n",
      "  Jinja2: 3.1.4\n",
      "  aiohttp: 3.9.5\n",
      "  alembic: 1.13.1\n",
      "  boto3: 1.36.23\n",
      "  botocore: 1.36.23\n",
      "  docker: 7.0.0\n",
      "  graphene: 3.3\n",
      "  gunicorn: 22.0.0\n",
      "  markdown: 3.6\n",
      "  matplotlib: 3.9.0\n",
      "  mlflow-skinny: 2.20.2\n",
      "  numpy: 1.26.4\n",
      "  pandas: 2.2.2\n",
      "  pyarrow: 15.0.2\n",
      "  scikit-learn: 1.4.2\n",
      "  scipy: 1.13.0\n",
      "  sqlalchemy: 2.0.30\n",
      "  virtualenv: 20.26.2\n",
      "None\n",
      "üèÉ View run  at: https://datalab.corp.novocorp.net/mlflow/#/experiments/378/runs/f46088299bb24cd4b9702026bc3bc197\n",
      "üß™ View experiment at: https://datalab.corp.novocorp.net/mlflow/#/experiments/378\n"
     ]
    }
   ],
   "source": [
    "%env AWS_ACCESS_KEY_ID=ASIATIJCHR3KA5YYSX4C\n",
    "%env AWS_SECRET_ACCESS_KEY=aPDRW7A6aUdgjnE2CdQeYG2IpZseMrimkIxc0H//\n",
    "%env AWS_SESSION_TOKEN=FwoGZXIvYXdzEMX//////////wEaDONh6B2GwAQwnkGFRSL0AwI0ymgCmmLalzZXga+CfvhC0RiboEHABvkZiIl6GOVwtQtrORvwMGFLYd5RwDFo+fKXDl5P3zXzI0hnN2nHWf9e+jNJ1wZVVr7JEmw1XZwZn7zyOMG0skT8+BYhtkkZPYUhZB+DPOrrszHfomSSbBuox+/5P/7M492NM2zMnLRPomrOHsCMpc5rTlpv2Qp/zMgP0wKud0NJLjgq46dZkJ7rr7STpYwqc3x+gQ0peDIDGWqtdgeX75v74lpSCBgLU1YwmhUFBBenqDWxFPnYZ+81Q8DAuwtGFABQAUHScu04lM352nNNDTM21nGW50KMXqubIFyBvNcwP7hK61HcxvDZtdXkOc0o/Rg/oVkfa3INcmwV3P8g8qsjmrWhWyfCi3zeXJmH4QJl4rksNLCPMNugzkljoFOxhXFW4dzcfjk/pIZ2RohVcbwsiVHpwR9SXVM+0YzFE2MYSSUomqt5ahlxuUyK2IAJRvggiGOlSBN0T3ADN45y0U+JIFpl92MoIGkaW6Tr0RNT8eIOEGPzBB4g9FILg+CfYT1tMPaVJmlKGkRY+/vJkaE3h4DelnO49JhB1wRJgdtwZlBuFgqRRAPatgbZwhG79EwkmwTTXd5i5AxMeqQymz8jVurFoMBfALEuASskEoLoZIIc65PA+n0xz422KLCh470GMpQBMYrXpVze1m5G2VeOYzklnn6hsbiLu63zI7T4XX5GLExc4eoffUYBO4hlZAvEKYKJoR1Rx+iNlFz2RoQNQAHbfydjTrp7srnbSTGcwtJP3pyxxuqwXIHpWw0wHWx0mAuxWrujzsSyReGInQd+bDpRYsHUTZBd7aHDPrUK7ctcczNzIiVwgFD8g1hroB4ZCAucGRTjjw==\n",
    "\n",
    "repo_dir = '/novo/projects/departments/cdd/molecular_ai/sbxw/repos/ML-BP-Domino'\n",
    "conda_env_name = 'mlbp'\n",
    "\n",
    "# Create command (single set of params)\n",
    "cmd = [\n",
    "    f\"/nfs_home/users/sbxw/mambaforge/condabin/conda run --no-capture-output -n {conda_env_name} python\",\n",
    "    f\"{repo_dir}/src/cli/training.py\",\n",
    "    \"mlflow=datalab\", \"persistence=lovelace\",\n",
    "    \"dataset.use_predefined_split=true\",\n",
    "    \"dataset.data_name=sbxw_fibrillation_peptide_waltzdb-train-val_amypro27-test_randpadded10x\", \"dataset.task=classification_binary\", \n",
    "    \"dataset.residue_prediction_labels=res_value_bool\",\n",
    "    \"embedder=esm2_t6_8M\",\"embedder.mean_pool=false\",\n",
    "    \"dimred=noreduction\",\n",
    "    \"predictor=lightattention\", \"predictor.residue_prediction_mode=true\",\n",
    "    \"predictor.hparams.kernel_size=3\", \"predictor.hparams.max_epochs=10\", \"predictor.hparams.patience=200\",\n",
    "    \"predictor.hparams.batch_size=1000\", \"predictor.hparams.learning_rate=0.0005\",\n",
    "    \"mlflow.experiment_name=ML-BP-Domino\",\n",
    "    \"plots.generate_plots=false\",\n",
    "]\n",
    "command_str = \" \".join(cmd)\n",
    "print(command_str)\n",
    "!PYTHONPATH=repo_dir; $command_str"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6700587c-0f29-44a9-a230-fcaa6b9ba861",
   "metadata": {},
   "source": [
    "# Run test with pytorch reduction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11e38d3c-b544-4a3a-8355-ed9681f41c3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "%env AWS_ACCESS_KEY_ID=ASIATIJCHR3KIBHT4CJJ\n",
    "%env AWS_SECRET_ACCESS_KEY=xIGEdnXCFX+ZYZnrhXhufFN9gmrHuypzZ1CiT7vz\n",
    "%env AWS_SESSION_TOKEN=FwoGZXIvYXdzECcaDEsf+Ibwksbize3jTiL0Awr1pSJRhVJHPHGlq05J5vAqAFN9acPInuJdAUEQCgjD639mjABp16fgQ74C+fM6tTVAMsuqNcHjHU/hVuYjoBcUoawUazYHDbDFEJTHDwkMRhCeR9PR+rAtXYoM1tU+LyttUBdvirWQhzFRvigEj1YTQn0oQYFOhOZOW5c4RcdlDhNztpz0TVoXHG8rXvPcGI3CejKZ4O5aDwouJ431Q0mmhN6L1tdjhbYS1eVhxcgPHwpNWPG9b/0T87gmec0a5ft/qE6+CWQhKSXHsN1ld/VHOryvsdcEpP9lQtYw3oMWnt7SMHRijgBbGkgo1Wn6lKG6sbrRJier7WgDlnRt3s6HXG5mxfxvsyNc6VssGhShMCe18nDniv0cg4SoqdwLsOb14wDxi7fD2T0/tXRRrjUEuyXD9BFdGloVZnWOhUsrYptoy501px/6SkTSYVOHsT/JG+FnBf65h/kZ0jH2zVsuxVYeprdUeYkP/YOJkRKbBUHPOhk2RbZjC7F7VA2ODEglGTtTXsxpp5s0VxstlMLlvLgyJA1H5mgj2Qu2L0aoQGcpQMR+A9b7yAm2SOCdj1L75LV/QGJyElIIJRJc2pDNkfBT5zQ0hRyCBgEJk5YWof/LIqYdxQjFqmgW4oqaYqXAVIw6fu5HJlT62Y+rfNcbxm6CKJD6+L0GMpQBELbEsvTtXAtUP5eSPHVmLmIL9JVZHfj/3U8ayUIezj1yCzH32pv5nHoErAXnPdKKw35qroqKMw9sPi3SdO5RcKclba1IGULmGu8nmCAUo8bVAx6WhcLVT8/CD9T3o3UdBuQ0eFTeqnH34G0lWOR6u/tDiAZP5/haLi6RG5EHQ9xx2pPVTLtxcLi8lBqTVydPbPoKHA==\n",
    "\n",
    "repo_dir = '/novo/projects/departments/cdd/molecular_ai/sbxw/repos/ML-BP-Domino'\n",
    "conda_env_name = 'mlbp'\n",
    "\n",
    "# Create command (single set of params)\n",
    "cmd = [\n",
    "    f\"/nfs_home/users/sbxw/mambaforge/condabin/conda run --no-capture-output -n {conda_env_name} python\",\n",
    "    f\"{repo_dir}/src/cli/training.py\",\n",
    "    \"mlflow=datalab\", \"persistence=lovelace\",\n",
    "    \"dataset.use_predefined_split=true\",\n",
    "    \"dataset.data_name=sbxw_fibrillation_peptide_waltzdb-train-val_serrano-test\", \"dataset.task=classification_binary\", \n",
    "    \"embedder=esm2_t6_8M\",\"embedder.mean_pool=false\",\n",
    "    \"dimred=noreduction\",\n",
    "    \"predictor=lightattention\",\n",
    "    \"predictor.hparams.kernel_size=3\", \"predictor.hparams.max_epochs=10\", \"predictor.hparams.patience=200\",\n",
    "    \"predictor.hparams.batch_size=1000\", \"predictor.hparams.learning_rate=0.0005\",\n",
    "    \"mlflow.experiment_name=ML-BP-Domino\",\n",
    "    \"plots.generate_plots=false\",\n",
    "]\n",
    "\n",
    "command_str = \" \".join(cmd)\n",
    "print(command_str)\n",
    "!$command_str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "80f2b571-ff0d-4a25-9ea5-974fa352d8d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: AWS_ACCESS_KEY_ID=ASIATIJCHR3KIBHT4CJJ\n",
      "env: AWS_SECRET_ACCESS_KEY=xIGEdnXCFX+ZYZnrhXhufFN9gmrHuypzZ1CiT7vz\n",
      "env: AWS_SESSION_TOKEN=FwoGZXIvYXdzECcaDEsf+Ibwksbize3jTiL0Awr1pSJRhVJHPHGlq05J5vAqAFN9acPInuJdAUEQCgjD639mjABp16fgQ74C+fM6tTVAMsuqNcHjHU/hVuYjoBcUoawUazYHDbDFEJTHDwkMRhCeR9PR+rAtXYoM1tU+LyttUBdvirWQhzFRvigEj1YTQn0oQYFOhOZOW5c4RcdlDhNztpz0TVoXHG8rXvPcGI3CejKZ4O5aDwouJ431Q0mmhN6L1tdjhbYS1eVhxcgPHwpNWPG9b/0T87gmec0a5ft/qE6+CWQhKSXHsN1ld/VHOryvsdcEpP9lQtYw3oMWnt7SMHRijgBbGkgo1Wn6lKG6sbrRJier7WgDlnRt3s6HXG5mxfxvsyNc6VssGhShMCe18nDniv0cg4SoqdwLsOb14wDxi7fD2T0/tXRRrjUEuyXD9BFdGloVZnWOhUsrYptoy501px/6SkTSYVOHsT/JG+FnBf65h/kZ0jH2zVsuxVYeprdUeYkP/YOJkRKbBUHPOhk2RbZjC7F7VA2ODEglGTtTXsxpp5s0VxstlMLlvLgyJA1H5mgj2Qu2L0aoQGcpQMR+A9b7yAm2SOCdj1L75LV/QGJyElIIJRJc2pDNkfBT5zQ0hRyCBgEJk5YWof/LIqYdxQjFqmgW4oqaYqXAVIw6fu5HJlT62Y+rfNcbxm6CKJD6+L0GMpQBELbEsvTtXAtUP5eSPHVmLmIL9JVZHfj/3U8ayUIezj1yCzH32pv5nHoErAXnPdKKw35qroqKMw9sPi3SdO5RcKclba1IGULmGu8nmCAUo8bVAx6WhcLVT8/CD9T3o3UdBuQ0eFTeqnH34G0lWOR6u/tDiAZP5/haLi6RG5EHQ9xx2pPVTLtxcLi8lBqTVydPbPoKHA==\n",
      "/nfs_home/users/sbxw/mambaforge/condabin/conda run --no-capture-output -n mlbp python /novo/projects/departments/cdd/molecular_ai/sbxw/repos/ML-BP-Domino/src/cli/training.py mlflow=datalab persistence=lovelace dataset.use_predefined_split=true dataset.data_name=sbxw_fibrillation_peptide_waltzdb-train-val_serrano-test dataset.task=classification_binary embedder=esm2_t6_8M embedder.mean_pool=false dimred=noreduction predictor=lightattention predictor.hparams.kernel_size=3 predictor.hparams.max_epochs=10 predictor.hparams.patience=200 predictor.hparams.batch_size=1000 predictor.hparams.learning_rate=0.0005 predictor.hparams.reduction_mode=max mlflow.experiment_name=ML-BP-Domino plots.generate_plots=false\n",
      "2025-02-25 22:34:02.283107: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2025-02-25 22:34:02.283153: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2025-02-25 22:34:02.284668: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2025-02-25 22:34:02.292120: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2025-02-25 22:34:04.936247: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "[2025-02-25 22:34:13,333][__main__][INFO] - Workflow configuration:\n",
      "\n",
      "general:\n",
      "  run_mode: train\n",
      "  abs_repo_path: null\n",
      "  composite_model_name: null\n",
      "  composite_model_path: null\n",
      "  precomputed_embeddings_path: null\n",
      "  random_state: 42\n",
      "dataset:\n",
      "  data_name: sbxw_fibrillation_peptide_waltzdb-train-val_serrano-test\n",
      "  add_data_columns: false\n",
      "  data_columns_dimred: false\n",
      "  data_columns_standard: false\n",
      "  group_column: null\n",
      "  data_scaler: RobustScaler\n",
      "  target_scaling: null\n",
      "  rbf_encoder: RadialBasisFunctionGaussian\n",
      "  rbf_n_kernels: 10\n",
      "  task: classification_binary\n",
      "  use_predefined_split: true\n",
      "  use_sample_weights: false\n",
      "  residue_prediction_labels: null\n",
      "  data_split_column: data_split\n",
      "  data_split:\n",
      "    train: 0.8\n",
      "    val: 0.0\n",
      "    test: 0.2\n",
      "embedder:\n",
      "  class_name: ESM\n",
      "  model_name: esm2_t6_8M_UR50D\n",
      "  model_path: null\n",
      "  standardize: false\n",
      "  scalar_type: StandardScaler\n",
      "  hparams: null\n",
      "  n_copies: 1\n",
      "  chain_break: poly-gly-linker\n",
      "  buffer_scale_factor: 2.0\n",
      "  max_batch_size: 400\n",
      "  simple_batching: false\n",
      "  strict: true\n",
      "  verbose: false\n",
      "  mean_pool: false\n",
      "  output_hidden_states: false\n",
      "dimred:\n",
      "  class_name: NoReduction\n",
      "  transform_name: null\n",
      "  fraction_variance_explained: null\n",
      "predictor:\n",
      "  class_name: LightAttention\n",
      "  model_name: null\n",
      "  model_type: classification_binary\n",
      "  mem_per_job: null\n",
      "  residue_prediction_mode: false\n",
      "  hparams:\n",
      "    kernel_size: 3\n",
      "    dropout: 0.25\n",
      "    conv_dropout: 0.25\n",
      "    learning_rate: 0.0005\n",
      "    batch_size: 1000\n",
      "    max_epochs: 10\n",
      "    patience: 200\n",
      "    post_attention: mlp\n",
      "    conv1d_output_dim: -1\n",
      "    optimal_cutoff: 0.5\n",
      "    reduction_mode: max\n",
      "persistence:\n",
      "  type: lovelace\n",
      "  data_root_folder: /novo/projects/departments/cdd/molecular_ai/mlbp/data\n",
      "  artifacts_root_folder: /novo/projects/departments/cdd/molecular_ai/mlbp/artifacts\n",
      "  training_data: static_input_data\n",
      "  pretrained_weights: static_pretrained_weights\n",
      "mlflow:\n",
      "  tracking_uri: https://datalab.corp.novocorp.net/mlflow/\n",
      "  experiment_name: ML-BP-Domino\n",
      "plots:\n",
      "  generate_plots: false\n",
      "\n",
      "[2025-02-25 22:34:13,334][src.model.dimred][INFO] - Load class (NoReduction): NoReduction\n",
      "[2025-02-25 22:34:13,334][src.model.abstract_components][INFO] - Load class (DimRed Model): NoReduction\n",
      "[2025-02-25 22:34:13,334][src.model.predictors][INFO] - Load class (LightAttention): LightAttention\n",
      "[2025-02-25 22:34:13,334][src.model.abstract_components][INFO] - Load class (TorchPredictorModel): LightAttention\n",
      "[2025-02-25 22:34:13,334][src.model.abstract_components][INFO] - Load class (Predictor Model): LightAttention\n",
      "[2025-02-25 22:34:13,334][src.model.composite_model][INFO] - Composite model name: esm2t68MUR50D_LightAttention_sbxwfibrillationpeptidewaltzdb-train-valserrano-test\n",
      "[2025-02-25 22:34:13,335][src.model.composite_model][INFO] - Initialized model: esm2t68MUR50D_LightAttention_sbxwfibrillationpeptidewaltzdb-train-valserrano-test in run_mode = train\n",
      "[2025-02-25 22:34:13,339][src.helpers.dataset][INFO] - Loading file: /novo/projects/departments/cdd/molecular_ai/mlbp/data/static_input_data/sbxw_fibrillation_peptide_waltzdb-train-val_serrano-test.csv\n",
      "[2025-02-25 22:34:13,339][src.helpers.dataset][INFO] - Using group_column \"None\".\n",
      "[2025-02-25 22:34:13,339][src.helpers.dataset][INFO] - No additional data columns found while parsing.\n",
      "[2025-02-25 22:34:13,341][src.helpers.dataset][INFO] - Select data according to predetermined splits in the dataframe, train (N = 1122), validation (N = 277), test (N = 248)\n",
      "[2025-02-25 22:34:13,341][src.helpers.dataset][INFO] - Loaded columns: {}\n",
      "[2025-02-25 22:34:13,342][src.helpers.mlflow_helpers][INFO] - Setting up MLflow...\n",
      "[2025-02-25 22:34:13,342][src.helpers.mlflow_helpers][INFO] - Experiment name: ML-BP-Domino\n",
      "[2025-02-25 22:34:13,342][src.helpers.mlflow_helpers][INFO] - Setting MLflow tracking URI to https://datalab.corp.novocorp.net/mlflow/\n",
      "[2025-02-25 22:34:14,684][src.helpers.mlflow_helpers][INFO] - Setting MLflow experiment to ML-BP-Domino\n",
      "[2025-02-25 22:34:15,111][__main__][INFO] - <RunInfo: artifact_uri='s3://nnedl-core-prd-eu-central-1-curated/mlops/378/c431a21ed2c642c291143c4f257e29f5/artifacts', end_time=None, experiment_id='378', lifecycle_stage='active', run_id='c431a21ed2c642c291143c4f257e29f5', run_name='', run_uuid='c431a21ed2c642c291143c4f257e29f5', start_time=1740522854868, status='RUNNING', user_id='sbxw'>\n",
      "[2025-02-25 22:34:15,850][__main__][INFO] - Compute embeddings on-the-fly and train model\n",
      "[2025-02-25 22:34:15,850][src.model.abstract_components][INFO] - Load class (LLMEmbedderModel): ESM\n",
      "[2025-02-25 22:34:15,850][src.model.abstract_components][INFO] - Load class (Embedder Model): ESM\n",
      "[2025-02-25 22:34:15,851][src.model.embedders][INFO] - Loading model: esm2_t6_8M_UR50D, will extract embeddings from 6-th layer\n",
      "Some weights of EsmModel were not initialized from the model checkpoint at facebook/esm2_t6_8M_UR50D and are newly initialized: ['esm.pooler.dense.bias', 'esm.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "[2025-02-25 22:34:16,582][src.model.embedders][INFO] - Moving model to cuda\n",
      "[2025-02-25 22:34:16,742][src.model.abstract_components][INFO] - Total memory: 23.58378496GB\n",
      "Memory already allocated: 0.031387648GB\n",
      "[2025-02-25 22:34:17,223][src.model.embedders][INFO] - Per-residue embeddings count: 1122\n",
      "[2025-02-25 22:34:17,223][src.model.composite_model][INFO] - Residue embeddings\n",
      "[2025-02-25 22:34:17,223][src.model.abstract_components][INFO] - Total memory: 23.58378496GB\n",
      "Memory already allocated: 0.043664896GB\n",
      "[2025-02-25 22:34:17,246][src.model.embedders][INFO] - Per-residue embeddings count: 277\n",
      "[2025-02-25 22:34:17,247][src.model.scalers][INFO] - Fitted scaler: PassThroughScaler\n",
      "[2025-02-25 22:34:17,247][src.model.scalers][INFO] - Before standardization - min: 0.0, max: 1.0\n",
      "[2025-02-25 22:34:17,247][src.model.scalers][INFO] - After standardization - min: 0.0, max: 1.0\n",
      "[2025-02-25 22:34:17,247][src.model.scalers][INFO] - Before standardization - min: 0.0, max: 1.0\n",
      "[2025-02-25 22:34:17,247][src.model.scalers][INFO] - After standardization - min: 0.0, max: 1.0\n",
      "[2025-02-25 22:34:17,247][src.model.scalers][INFO] - Before standardization - min: 0.0, max: 1.0\n",
      "[2025-02-25 22:34:17,247][src.model.scalers][INFO] - After standardization - min: 0.0, max: 1.0\n",
      "/nfs_home/users/sbxw/mambaforge/envs/mlbp/lib/python3.10/site-packages/lightning/fabric/plugins/environments/slurm.py:204: The `srun` command is available on your system but is not used. HINT: If your intention is to run Lightning on SLURM, prepend your python command with `srun` like so: srun python /novo/projects/departments/cdd/molecular_ai/sbxw/rep ...\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/nfs_home/users/sbxw/mambaforge/envs/mlbp/lib/python3.10/site-packages/lightning/fabric/plugins/environments/slurm.py:204: The `srun` command is available on your system but is not used. HINT: If your intention is to run Lightning on SLURM, prepend your python command with `srun` like so: srun python /novo/projects/departments/cdd/molecular_ai/sbxw/rep ...\n",
      "[2025-02-25 22:34:18,463][pytorch_lightning.utilities.rank_zero][INFO] - You are using a CUDA device ('NVIDIA L4') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name                  | Type       | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | feature_convolution   | Conv1d     | 307 K  | train\n",
      "1 | attention_convolution | Conv1d     | 307 K  | train\n",
      "2 | softmax               | Softmax    | 0      | train\n",
      "3 | dropout               | Dropout    | 0      | train\n",
      "4 | sigmoid               | Sigmoid    | 0      | train\n",
      "5 | mlp                   | Sequential | 10.4 K | train\n",
      "6 | loss_fxn              | BCELoss    | 0      | train\n",
      "-------------------------------------------------------------\n",
      "625 K     Trainable params\n",
      "0         Non-trainable params\n",
      "625 K     Total params\n",
      "2.502     Total estimated model params size (MB)\n",
      "12        Modules in train mode\n",
      "0         Modules in eval mode\n",
      "/nfs_home/users/sbxw/mambaforge/envs/mlbp/lib/python3.10/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:424: The 'val_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=7` in the `DataLoader` to improve performance.\n",
      "/nfs_home/users/sbxw/mambaforge/envs/mlbp/lib/python3.10/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:424: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=7` in the `DataLoader` to improve performance.\n",
      "[2025-02-25 22:34:22,144][botocore.credentials][INFO] - Found credentials in environment variables.\n",
      "[2025-02-25 22:34:39,800][pytorch_lightning.utilities.rank_zero][INFO] - `Trainer.fit` stopped: `max_epochs=10` reached.\n",
      "üèÉ View run  at: https://datalab.corp.novocorp.net/mlflow/#/experiments/378/runs/c431a21ed2c642c291143c4f257e29f5\n",
      "üß™ View experiment at: https://datalab.corp.novocorp.net/mlflow/#/experiments/378\n",
      "\u001b[31m2025/02/25 22:35:02 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\u001b[0m\n",
      "[2025-02-25 22:35:10,257][src.model.abstract_components][INFO] - MODEL STOPPED BY EARLY STOPPER AT EPOCH 0\n",
      "[2025-02-25 22:35:10,257][src.model.abstract_components][INFO] - BEST MODEL VALIDATION LOSS IS 0.6780571937561035\n",
      "[2025-02-25 22:35:10,257][src.model.abstract_components][INFO] - BEST MODEL SAVED AT /novo/projects/departments/cdd/public/users/ehec/sbxw_files_2/378/c431a21ed2c642c291143c4f257e29f5/checkpoints/epoch=0-step=2.ckpt\n",
      "[2025-02-25 22:35:10,257][src.model.abstract_components][INFO] - FINAL MODEL SAVED AT None\n",
      "[2025-02-25 22:35:10,534][src.model.predictors][INFO] - Moving embeddings to device: cuda\n",
      "[2025-02-25 22:35:10,638][src.model.predictors][INFO] - Optimal cutoff is: 0.0 with MCC: 0.0\n",
      "[2025-02-25 22:35:10,648][src.model.predictors][INFO] - Moving embeddings to device: cuda\n",
      "[2025-02-25 22:35:10,655][src.model.predictors][INFO] - Moving embeddings to device: cuda\n",
      "[2025-02-25 22:35:10,656][src.model.composite_model][INFO] - This is the updated predictor name: lightattention_kernel_size_3_dropout_0.25_conv_dropout_0.25_learning_rate_0.0005_batch_size_1000_max_epochs_10_patience_200_post_attention_mlp_conv1d_output_dim_-1_optimal_cutoff_0.0_reduction_mode_max\n",
      "[2025-02-25 22:35:10,656][src.model.composite_model][INFO] - Composite model name: esm2t68MUR50D_LightAttention_sbxwfibrillationpeptidewaltzdb-train-valserrano-test\n",
      "[2025-02-25 22:35:10,656][src.model.composite_model][INFO] - Best model is: kernel_size_3_dropout_0.25_conv_dropout_0.25_learning_rate_0.0005_batch_size_1000_max_epochs_10_patience_200_post_attention_mlp_conv1d_output_dim_-1_optimal_cutoff_0.0_reduction_mode_max\n",
      "[2025-02-25 22:35:10,656][src.model.composite_model][INFO] - Moving to test mode\n",
      "[2025-02-25 22:35:10,657][src.model.composite_model][INFO] - Composite model name: esm2t68MUR50D_LightAttention_sbxwfibrillationpeptidewaltzdb-train-valserrano-test\n",
      "[2025-02-25 22:35:10,657][src.model.composite_model][INFO] - Saving model: esm2t68MUR50D_LightAttention_sbxwfibrillationpeptidewaltzdb-train-valserrano-test\n",
      "<RunInfo: artifact_uri='s3://nnedl-core-prd-eu-central-1-curated/mlops/378/c431a21ed2c642c291143c4f257e29f5/artifacts', end_time=None, experiment_id='378', lifecycle_stage='active', run_id='c431a21ed2c642c291143c4f257e29f5', run_name='', run_uuid='c431a21ed2c642c291143c4f257e29f5', start_time=1740522854868, status='RUNNING', user_id='sbxw'>\n",
      "[2025-02-25 22:35:18,550][src.model.abstract_components][INFO] - Total memory: 23.58378496GB\n",
      "Memory already allocated: 0.055517184GB\n",
      "[2025-02-25 22:35:18,620][src.model.embedders][INFO] - Per-residue embeddings count: 248\n",
      "[2025-02-25 22:35:18,620][src.model.composite_model][INFO] - Residue embeddings\n",
      "[2025-02-25 22:35:18,624][src.model.predictors][INFO] - Moving embeddings to device: cuda\n",
      "sequences: (1122,)\n",
      "sequence_embeddings: 1122\n",
      "data_split: train\n",
      "labels: (1122,)\n",
      "predictions_probability: (1122,)\n",
      "residue_level_prediction: False\n",
      "sequences: (277,)\n",
      "sequence_embeddings: 277\n",
      "data_split: val\n",
      "labels: (277,)\n",
      "predictions_probability: (277,)\n",
      "residue_level_prediction: False\n",
      "sequences: (248,)\n",
      "sequence_embeddings: 248\n",
      "data_split: test\n",
      "labels: (248,)\n",
      "predictions_probability: (248,)\n",
      "residue_level_prediction: False\n",
      "üèÉ View run  at: https://datalab.corp.novocorp.net/mlflow/#/experiments/378/runs/c431a21ed2c642c291143c4f257e29f5\n",
      "üß™ View experiment at: https://datalab.corp.novocorp.net/mlflow/#/experiments/378\n",
      "Error executing job with overrides: ['mlflow=datalab', 'persistence=lovelace', 'dataset.use_predefined_split=true', 'dataset.data_name=sbxw_fibrillation_peptide_waltzdb-train-val_serrano-test', 'dataset.task=classification_binary', 'embedder=esm2_t6_8M', 'embedder.mean_pool=false', 'dimred=noreduction', 'predictor=lightattention', 'predictor.hparams.kernel_size=3', 'predictor.hparams.max_epochs=10', 'predictor.hparams.patience=200', 'predictor.hparams.batch_size=1000', 'predictor.hparams.learning_rate=0.0005', 'predictor.hparams.reduction_mode=max', 'mlflow.experiment_name=ML-BP-Domino', 'plots.generate_plots=false']\n",
      "Traceback (most recent call last):\n",
      "  File \"/novo/projects/departments/cdd/molecular_ai/sbxw/repos/ML-BP-Domino/src/cli/training.py\", line 82, in my_app\n",
      "    stats_df = calculate_statistics_from_df(\n",
      "  File \"/novo/projects/departments/cdd/molecular_ai/sbxw/repos/ML-BP-Domino/src/helpers/stats_utilities.py\", line 276, in calculate_statistics_from_df\n",
      "    stat_dict = calculate_classification_statistics(\n",
      "  File \"/novo/projects/departments/cdd/molecular_ai/sbxw/repos/ML-BP-Domino/src/helpers/stats_utilities.py\", line 140, in calculate_classification_statistics\n",
      "    balanced_accuracy = float(balanced_accuracy_score(y, y_pred))\n",
      "  File \"/nfs_home/users/sbxw/mambaforge/envs/mlbp/lib/python3.10/site-packages/sklearn/utils/_param_validation.py\", line 213, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/nfs_home/users/sbxw/mambaforge/envs/mlbp/lib/python3.10/site-packages/sklearn/metrics/_classification.py\", line 2454, in balanced_accuracy_score\n",
      "    C = confusion_matrix(y_true, y_pred, sample_weight=sample_weight)\n",
      "  File \"/nfs_home/users/sbxw/mambaforge/envs/mlbp/lib/python3.10/site-packages/sklearn/utils/_param_validation.py\", line 186, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/nfs_home/users/sbxw/mambaforge/envs/mlbp/lib/python3.10/site-packages/sklearn/metrics/_classification.py\", line 319, in confusion_matrix\n",
      "    y_type, y_true, y_pred = _check_targets(y_true, y_pred)\n",
      "  File \"/nfs_home/users/sbxw/mambaforge/envs/mlbp/lib/python3.10/site-packages/sklearn/metrics/_classification.py\", line 94, in _check_targets\n",
      "    raise ValueError(\n",
      "ValueError: Classification metrics can't handle a mix of binary and unknown targets\n",
      "\n",
      "Set the environment variable HYDRA_FULL_ERROR=1 for a complete stack trace.\n",
      "ERROR conda.cli.main_run:execute(47): `conda run python /novo/projects/departments/cdd/molecular_ai/sbxw/repos/ML-BP-Domino/src/cli/training.py mlflow=datalab persistence=lovelace dataset.use_predefined_split=true dataset.data_name=sbxw_fibrillation_peptide_waltzdb-train-val_serrano-test dataset.task=classification_binary embedder=esm2_t6_8M embedder.mean_pool=false dimred=noreduction predictor=lightattention predictor.hparams.kernel_size=3 predictor.hparams.max_epochs=10 predictor.hparams.patience=200 predictor.hparams.batch_size=1000 predictor.hparams.learning_rate=0.0005 predictor.hparams.reduction_mode=max mlflow.experiment_name=ML-BP-Domino plots.generate_plots=false` failed. (See above for error)\n"
     ]
    }
   ],
   "source": [
    "%env AWS_ACCESS_KEY_ID=ASIATIJCHR3KIBHT4CJJ\n",
    "%env AWS_SECRET_ACCESS_KEY=xIGEdnXCFX+ZYZnrhXhufFN9gmrHuypzZ1CiT7vz\n",
    "%env AWS_SESSION_TOKEN=FwoGZXIvYXdzECcaDEsf+Ibwksbize3jTiL0Awr1pSJRhVJHPHGlq05J5vAqAFN9acPInuJdAUEQCgjD639mjABp16fgQ74C+fM6tTVAMsuqNcHjHU/hVuYjoBcUoawUazYHDbDFEJTHDwkMRhCeR9PR+rAtXYoM1tU+LyttUBdvirWQhzFRvigEj1YTQn0oQYFOhOZOW5c4RcdlDhNztpz0TVoXHG8rXvPcGI3CejKZ4O5aDwouJ431Q0mmhN6L1tdjhbYS1eVhxcgPHwpNWPG9b/0T87gmec0a5ft/qE6+CWQhKSXHsN1ld/VHOryvsdcEpP9lQtYw3oMWnt7SMHRijgBbGkgo1Wn6lKG6sbrRJier7WgDlnRt3s6HXG5mxfxvsyNc6VssGhShMCe18nDniv0cg4SoqdwLsOb14wDxi7fD2T0/tXRRrjUEuyXD9BFdGloVZnWOhUsrYptoy501px/6SkTSYVOHsT/JG+FnBf65h/kZ0jH2zVsuxVYeprdUeYkP/YOJkRKbBUHPOhk2RbZjC7F7VA2ODEglGTtTXsxpp5s0VxstlMLlvLgyJA1H5mgj2Qu2L0aoQGcpQMR+A9b7yAm2SOCdj1L75LV/QGJyElIIJRJc2pDNkfBT5zQ0hRyCBgEJk5YWof/LIqYdxQjFqmgW4oqaYqXAVIw6fu5HJlT62Y+rfNcbxm6CKJD6+L0GMpQBELbEsvTtXAtUP5eSPHVmLmIL9JVZHfj/3U8ayUIezj1yCzH32pv5nHoErAXnPdKKw35qroqKMw9sPi3SdO5RcKclba1IGULmGu8nmCAUo8bVAx6WhcLVT8/CD9T3o3UdBuQ0eFTeqnH34G0lWOR6u/tDiAZP5/haLi6RG5EHQ9xx2pPVTLtxcLi8lBqTVydPbPoKHA==\n",
    "\n",
    "repo_dir = '/novo/projects/departments/cdd/molecular_ai/sbxw/repos/ML-BP-Domino'\n",
    "conda_env_name = 'mlbp'\n",
    "\n",
    "# Create command (single set of params)\n",
    "cmd = [\n",
    "    f\"/nfs_home/users/sbxw/mambaforge/condabin/conda run --no-capture-output -n {conda_env_name} python\",\n",
    "    f\"{repo_dir}/src/cli/training.py\",\n",
    "    \"mlflow=datalab\", \"persistence=lovelace\",\n",
    "    \"dataset.use_predefined_split=true\",\n",
    "    \"dataset.data_name=sbxw_fibrillation_peptide_waltzdb-train-val_serrano-test\", \"dataset.task=classification_binary\", \n",
    "    \"embedder=esm2_t6_8M\",\"embedder.mean_pool=false\",\n",
    "    \"dimred=noreduction\",\n",
    "    \"predictor=lightattention\",\n",
    "    \"predictor.hparams.kernel_size=3\", \"predictor.hparams.max_epochs=10\", \"predictor.hparams.patience=200\",\n",
    "    \"predictor.hparams.batch_size=1000\", \"predictor.hparams.learning_rate=0.0005\",\n",
    "    \"predictor.hparams.reduction_mode=max\",\n",
    "    \"mlflow.experiment_name=ML-BP-Domino\",\n",
    "    \"plots.generate_plots=false\",\n",
    "]\n",
    "\n",
    "command_str = \" \".join(cmd)\n",
    "print(command_str)\n",
    "!$command_str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72bb8acd-51f8-4d23-afdf-db19a1dfa08d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8004cda-0478-4aa0-8a10-2e1ff3873b5b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (3.10.5) {SYSTEM}",
   "language": "python",
   "name": "py3.10.5"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
