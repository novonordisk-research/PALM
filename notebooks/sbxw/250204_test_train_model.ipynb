{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "75f51494-53dd-4279-9738-1f901eb440e3",
   "metadata": {},
   "source": [
    "# train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "77b81de7-e07f-4e6d-ae28-061355bf74fc",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/nfs_home/users/sbxw/mambaforge/condabin/conda run --no-capture-output -n mlbp python /novo/projects/departments/cdd/molecular_ai/sbxw/repos/ML-BP-Domino/src/cli/training.py mlflow=lovelace persistence=lovelace dataset.use_predefined_split=true dataset.data_name=sbxw_fibrillation_peptide_waltzdb-train-val_serrano-test dataset.task=classification_binary embedder=esm2_t6_8M embedder.mean_pool=false dimred=noreduction predictor=lightattention predictor.hparams.kernel_size=1 predictor.hparams.max_epochs=10000 predictor.hparams.patience=200 predictor.hparams.batch_size=5000 predictor.hparams.learning_rate=0.0005 predictor.hparams.linear_post_concat=true predictor.hparams.conv1d_downsizing_factor=1 mlflow.experiment_name=ML-BP-Domino plots.generate_plots=false\n",
      "[2025-02-05 00:16:06,539][__main__][INFO] - Workflow configuration:\n",
      "\n",
      "general:\n",
      "  run_mode: train\n",
      "  abs_repo_path: null\n",
      "  composite_model_name: null\n",
      "  composite_model_path: null\n",
      "  precomputed_embeddings_path: null\n",
      "  random_state: 42\n",
      "dataset:\n",
      "  data_name: sbxw_fibrillation_peptide_waltzdb-train-val_serrano-test\n",
      "  add_data_columns: false\n",
      "  data_columns_dimred: false\n",
      "  data_columns_standard: false\n",
      "  data_scaler: RobustScaler\n",
      "  rbf_encoder: RadialBasisFunctionGaussian\n",
      "  rbf_n_kernels: 10\n",
      "  task: classification_binary\n",
      "  use_predefined_split: true\n",
      "  data_split:\n",
      "    train: 0.8\n",
      "    val: 0.0\n",
      "    test: 0.2\n",
      "embedder:\n",
      "  class_name: ESM\n",
      "  model_name: esm2_t6_8M_UR50D\n",
      "  model_path: null\n",
      "  standardize: false\n",
      "  scalar_type: StandardScaler\n",
      "  hparams: null\n",
      "  n_copies: 1\n",
      "  chain_break: poly-gly-linker\n",
      "  buffer_scale_factor: 2.0\n",
      "  max_batch_size: 400\n",
      "  simple_batching: false\n",
      "  strict: true\n",
      "  verbose: false\n",
      "  mean_pool: false\n",
      "dimred:\n",
      "  class_name: NoReduction\n",
      "  transform_name: null\n",
      "  fraction_variance_explained: null\n",
      "predictor:\n",
      "  class_name: LightAttention\n",
      "  model_name: null\n",
      "  model_type: classification_binary\n",
      "  mem_per_job: null\n",
      "  hparams:\n",
      "    kernel_size: 1\n",
      "    dropout: 0.25\n",
      "    conv_dropout: 0.25\n",
      "    learning_rate: 0.0005\n",
      "    batch_size: 5000\n",
      "    max_epochs: 10000\n",
      "    patience: 200\n",
      "    linear_post_concat: true\n",
      "    conv1d_downsizing_factor: 1\n",
      "    plain_LA: false\n",
      "    kernel_two_size: 5\n",
      "    multi_conv: false\n",
      "    optimal_cutoff: 0.5\n",
      "persistence:\n",
      "  type: lovelace\n",
      "  data_root_folder: /novo/projects/departments/cdd/molecular_ai/mlbp/data\n",
      "  artifacts_root_folder: /novo/projects/departments/cdd/molecular_ai/mlbp/artifacts\n",
      "  training_data: static_input_data\n",
      "  pretrained_weights: static_pretrained_weights\n",
      "mlflow:\n",
      "  tracking_uri: DOMINO_TRACKING_URI\n",
      "  experiment_name: ML-BP-Domino\n",
      "plots:\n",
      "  generate_plots: false\n",
      "\n",
      "2025-02-05 00:16:19.196106: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2025-02-05 00:16:19.198010: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2025-02-05 00:16:19.407069: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2025-02-05 00:16:19.817831: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2025-02-05 00:16:26.200785: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "[2025-02-05 00:16:37,004][src.model.composite_model][INFO] - Amorprot: <class 'src.model.embedders.Amorprot'>\n",
      "[2025-02-05 00:16:37,004][src.model.composite_model][INFO] - Ankh: <class 'src.model.embedders.Ankh'>\n",
      "[2025-02-05 00:16:37,004][src.model.composite_model][INFO] - Biophys: <class 'src.model.embedders.Biophys'>\n",
      "[2025-02-05 00:16:37,004][src.model.composite_model][INFO] - ESM: <class 'src.model.embedders.ESM'>\n",
      "[2025-02-05 00:16:37,004][src.model.composite_model][INFO] - Kmer: <class 'src.model.embedders.Kmer'>\n",
      "[2025-02-05 00:16:37,004][src.model.composite_model][INFO] - PrecomputedDescriptors: <class 'src.model.embedders.PrecomputedDescriptors'>\n",
      "[2025-02-05 00:16:37,005][src.model.composite_model][INFO] - ProtT5: <class 'src.model.embedders.ProtT5'>\n",
      "[2025-02-05 00:16:37,007][src.model.composite_model][INFO] - NoReduction: <class 'src.model.dimred.NoReduction'>\n",
      "[2025-02-05 00:16:37,007][src.model.composite_model][INFO] - PCADimReduction: <class 'src.model.dimred.PCADimReduction'>\n",
      "[2025-02-05 00:16:37,475][src.model.composite_model][INFO] - KNearestNeighbors: <class 'src.model.predictors.KNearestNeighbors'>\n",
      "[2025-02-05 00:16:37,476][src.model.composite_model][INFO] - LightAttention: <class 'src.model.predictors.LightAttention'>\n",
      "[2025-02-05 00:16:37,476][src.model.composite_model][INFO] - LogisticRegression: <class 'src.model.predictors.LogisticRegression'>\n",
      "[2025-02-05 00:16:37,476][src.model.composite_model][INFO] - MLP: <class 'src.model.predictors.MLP'>\n",
      "[2025-02-05 00:16:37,476][src.model.composite_model][INFO] - RandomForest: <class 'src.model.predictors.RandomForest'>\n",
      "[2025-02-05 00:16:37,476][src.model.composite_model][INFO] - RidgeRegression: <class 'src.model.predictors.RidgeRegression'>\n",
      "[2025-02-05 00:16:37,476][src.model.composite_model][INFO] - XGBoost: <class 'src.model.predictors.XGBoost'>\n",
      "[2025-02-05 00:16:37,476][src.model.dimred][INFO] - Load class (NoReduction): NoReduction\n",
      "[2025-02-05 00:16:37,476][src.model.abstract_components][INFO] - Load class (DimRed Model): NoReduction\n",
      "[2025-02-05 00:16:37,476][src.model.predictors][INFO] - Load class (LightAttention): LightAttention\n",
      "[2025-02-05 00:16:37,476][src.model.abstract_components][INFO] - Load class (TorchPredictorModel): LightAttention\n",
      "[2025-02-05 00:16:37,476][src.model.abstract_components][INFO] - Load class (Predictor Model): LightAttention\n",
      "[2025-02-05 00:16:37,477][src.model.composite_model][INFO] - Composite model name: esm2t68MUR50D_LightAttention_sbxwfibrillationpeptidewaltzdb-train-valserrano-test\n",
      "[2025-02-05 00:16:37,477][src.model.composite_model][INFO] - Initialized model: esm2t68MUR50D_LightAttention_sbxwfibrillationpeptidewaltzdb-train-valserrano-test in run_mode = train\n",
      "[2025-02-05 00:16:37,479][src.helpers.dataset][INFO] - Loading csv file: /novo/projects/departments/cdd/molecular_ai/mlbp/data/static_input_data/sbxw_fibrillation_peptide_waltzdb-train-val_serrano-test.csv\n",
      "[2025-02-05 00:16:37,490][src.helpers.dataset][INFO] - No additional data columns found while parsing.\n",
      "[2025-02-05 00:16:37,494][src.helpers.dataset][INFO] - Select data according to predetermined splits in the dataframe, train (N = 1122), validation (N = 277), test (N = 248)\n",
      "[2025-02-05 00:16:37,494][src.helpers.dataset][INFO] - Loaded columns: {}\n",
      "[2025-02-05 00:16:37,495][src.helpers.mlflow_helpers][INFO] - Setting up MLflow...\n",
      "[2025-02-05 00:16:37,495][src.helpers.mlflow_helpers][INFO] - Experiment name: ML-BP-Domino\n",
      "[2025-02-05 00:16:37,509][src.helpers.mlflow_helpers][INFO] - Setting MLflow experiment to ML-BP-Domino\n",
      "[2025-02-05 00:16:38,179][__main__][INFO] - Compute embeddings on-the-fly and train model\n",
      "[2025-02-05 00:16:38,179][src.model.abstract_components][INFO] - Load class (LLMEmbedderModel): ESM\n",
      "[2025-02-05 00:16:38,179][src.model.abstract_components][INFO] - Load class (Embedder Model): ESM\n",
      "[2025-02-05 00:16:38,180][src.model.embedders][INFO] - Using existing cache directory: /novo/projects/departments/cdd/molecular_ai/mlbp/data/static_pretrained_weights\n",
      "Using cache found in /novo/projects/departments/cdd/molecular_ai/mlbp/data/static_pretrained_weights/facebookresearch_esm_main\n",
      "[2025-02-05 00:16:38,465][src.model.embedders][INFO] - moving model to cuda\n",
      "[2025-02-05 00:16:39,106][src.model.abstract_components][INFO] - Total memory: 23.58378496GB\n",
      "Memory already allocated: 0.030069248GB\n",
      "[2025-02-05 00:16:40,190][src.model.embedders][INFO] - Final results len: 1122\n",
      "[2025-02-05 00:16:40,191][src.model.composite_model][INFO] - Residue embeddings\n",
      "[2025-02-05 00:16:40,191][src.model.abstract_components][INFO] - Total memory: 23.58378496GB\n",
      "Memory already allocated: 0.038758912GB\n",
      "[2025-02-05 00:16:40,230][src.model.embedders][INFO] - Final results len: 277\n",
      "/nfs_home/users/sbxw/mambaforge/envs/mlbp/lib/python3.10/site-packages/lightning/fabric/plugins/environments/slurm.py:204: The `srun` command is available on your system but is not used. HINT: If your intention is to run Lightning on SLURM, prepend your python command with `srun` like so: srun python /novo/projects/departments/cdd/molecular_ai/sbxw/rep ...\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "You are using a CUDA device ('NVIDIA L4') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n",
      "/nfs_home/users/sbxw/mambaforge/envs/mlbp/lib/python3.10/site-packages/lightning/pytorch/callbacks/model_checkpoint.py:654: Checkpoint directory /novo/projects/departments/cdd/public/users/ehec/sbxw_files_2/lightning_logs/version_2610694/checkpoints exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name                    | Type       | Params | Mode \n",
      "---------------------------------------------------------------\n",
      "0 | feature_convolution     | Conv1d     | 321    | train\n",
      "1 | attention_convolution   | Conv1d     | 321    | train\n",
      "2 | feature_convolution_2   | Conv1d     | 1.6 K  | train\n",
      "3 | attention_convolution_2 | Conv1d     | 1.6 K  | train\n",
      "4 | softmax                 | Softmax    | 0      | train\n",
      "5 | dropout                 | Dropout    | 0      | train\n",
      "6 | dropout_2               | Dropout    | 0      | train\n",
      "7 | sigmoid                 | Sigmoid    | 0      | train\n",
      "8 | mlp                     | Sequential | 19.4 K | train\n",
      "9 | loss_fxn                | BCELoss    | 0      | train\n",
      "---------------------------------------------------------------\n",
      "23.2 K    Trainable params\n",
      "0         Non-trainable params\n",
      "23.2 K    Total params\n",
      "0.093     Total estimated model params size (MB)\n",
      "20        Modules in train mode\n",
      "0         Modules in eval mode\n",
      "/nfs_home/users/sbxw/mambaforge/envs/mlbp/lib/python3.10/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:424: The 'val_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=3` in the `DataLoader` to improve performance.\n",
      "/nfs_home/users/sbxw/mambaforge/envs/mlbp/lib/python3.10/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:424: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=3` in the `DataLoader` to improve performance.\n",
      "/nfs_home/users/sbxw/mambaforge/envs/mlbp/lib/python3.10/site-packages/lightning/pytorch/loops/fit_loop.py:298: The number of training batches (1) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.\n",
      "[2025-02-05 00:16:49,145][src.model.abstract_components][INFO] - MODEL STOPPED BY EARLY STOPPER AT EPOCH 253\n",
      "[2025-02-05 00:16:49,145][src.model.abstract_components][INFO] - BEST MODEL VALIDATION LOSS IS 0.669636607170105\n",
      "[2025-02-05 00:16:49,145][src.model.abstract_components][INFO] - BEST MODEL SAVED AT /novo/projects/departments/cdd/public/users/ehec/sbxw_files_2/lightning_logs/version_2610694/checkpoints/epoch=53-step=54.ckpt\n",
      "[2025-02-05 00:16:49,774][src.model.predictors][INFO] - Moving embeddings to device: cuda\n",
      "[2025-02-05 00:16:49,892][src.model.predictors][INFO] - Optimal cutoff is: 0.61 with MCC: 0.07216016165440592\n",
      "[2025-02-05 00:16:49,902][src.model.predictors][INFO] - Moving embeddings to device: cuda\n",
      "[2025-02-05 00:16:49,907][src.model.predictors][INFO] - Moving embeddings to device: cuda\n",
      "[2025-02-05 00:16:49,908][src.model.composite_model][INFO] - This is the updated predictor name: TODO\n",
      "[2025-02-05 00:16:49,908][src.model.composite_model][INFO] - Composite model name: esm2t68MUR50D_LightAttention_sbxwfibrillationpeptidewaltzdb-train-valserrano-test\n",
      "[2025-02-05 00:16:49,909][src.model.composite_model][INFO] - Best model is: \n",
      "[2025-02-05 00:16:49,909][src.model.composite_model][INFO] - Moving to test mode\n",
      "[2025-02-05 00:16:49,909][src.model.composite_model][INFO] - Composite model name: esm2t68MUR50D_LightAttention_sbxwfibrillationpeptidewaltzdb-train-valserrano-test\n",
      "[2025-02-05 00:16:49,909][src.model.composite_model][INFO] - Saving model: esm2t68MUR50D_LightAttention_sbxwfibrillationpeptidewaltzdb-train-valserrano-test\n",
      "[2025-02-05 00:16:50,326][src.model.abstract_components][INFO] - Total memory: 23.58378496GB\n",
      "Memory already allocated: 0.038701056GB\n",
      "[2025-02-05 00:16:50,414][src.model.embedders][INFO] - Final results len: 248\n",
      "[2025-02-05 00:16:50,414][src.model.composite_model][INFO] - Residue embeddings\n",
      "[2025-02-05 00:16:50,418][src.model.predictors][INFO] - Moving embeddings to device: cuda\n",
      "sequences: (1122,)\n",
      "sequence_embeddings: 1122\n",
      "predictions: (1122,)\n",
      "data_split: train\n",
      "labels: (1122,)\n",
      "predictions_probability: (1122,)\n",
      "sequences: (277,)\n",
      "sequence_embeddings: 277\n",
      "predictions: (277,)\n",
      "data_split: val\n",
      "labels: (277,)\n",
      "predictions_probability: (277,)\n",
      "sequences: (248,)\n",
      "sequence_embeddings: 248\n",
      "predictions: (248,)\n",
      "data_split: test\n",
      "labels: (248,)\n",
      "predictions_probability: (248,)\n",
      "[2025-02-05 00:16:50,845][src.model.composite_model][INFO] - Composite model name: esm2t68MUR50D_LightAttention_sbxwfibrillationpeptidewaltzdb-train-valserrano-test\n",
      "[2025-02-05 00:16:50,865][__main__][INFO] - Done!\n",
      "run_id: 355865cfe1324682a01b734a5b3376ce\n",
      "artifacts: []\n",
      "params: {'persistence.data_root_folder': '/novo/projects/departments/cdd/molecular_ai/mlbp/data', 'dataset.data_name': 'sbxw_fibrillation_peptide_waltzdb-train-val_serrano-test', 'embedder.chain_break': 'poly-gly-linker', 'general.run_mode': 'train', 'predictor.class_name': 'LightAttention', 'dataset.data_scaler': 'RobustScaler', 'embedder.verbose': 'False', 'predictor.hparams.learning_rate': '0.0005', 'predictor.hparams.max_epochs': '10000', 'predictor.hparams.kernel_two_size': '5', 'persistence.type': 'lovelace', 'dataset.rbf_encoder': 'RadialBasisFunctionGaussian', 'dataset.data_split.val': '0.0', 'predictor.hparams.plain_LA': 'False', 'embedder.class_name': 'ESM', 'predictor.hparams.optimal_cutoff': '0.5', 'mlflow.tracking_uri': 'DOMINO_TRACKING_URI', 'dataset.data_split.test': '0.2', 'general.composite_model_name': 'esm2t68MUR50D_LightAttention_sbxwfibrillationpeptidewaltzdb-train-valserrano-test', 'general.precomputed_embeddings_path': 'None', 'predictor.hparams.dropout': '0.25', 'embedder.simple_batching': 'False', 'model_type': 'classification_binary', 'embedder.mean_pool': 'False', 'general.random_state': '42', 'embedder.strict': 'True', 'dimred.class_name': 'NoReduction', 'embedder.max_batch_size': '400', 'embedder.n_copies': '1', 'embedder.model_path': 'None', 'dataset.rbf_n_kernels': '10', 'dimred.transform_name': 'None', 'predictor.model_type': 'classification_binary', 'dataset.add_data_columns': 'False', 'predictor.hparams.batch_size': '5000', 'persistence.pretrained_weights': 'static_pretrained_weights', 'dataset.use_predefined_split': 'True', 'general.composite_model_path': 'None', 'dataset.data_columns_dimred': 'False', 'dataset.data_columns_standard': 'False', 'persistence.training_data': 'static_input_data', 'predictor.hparams.conv1d_downsizing_factor': '1', 'embedder.hparams': 'None', 'predictor.hparams.kernel_size': '1', 'mlflow.experiment_name': 'ML-BP-Domino', 'predictor.hparams.multi_conv': 'False', 'embedder.standardize': 'False', 'dataset.data_split.train': '0.8', 'embedder.scalar_type': 'StandardScaler', 'predictor.hparams.conv_dropout': '0.25', 'dimred.fraction_variance_explained': 'None', 'predictor.hparams.patience': '200', 'embedder.buffer_scale_factor': '2.0', 'embedder.model_name': 'esm2_t6_8M_UR50D', 'predictor.hparams.linear_post_concat': 'True', 'plots.generate_plots': 'False', 'persistence.artifacts_root_folder': '/novo/projects/departments/cdd/molecular_ai/mlbp/artifacts', 'predictor.mem_per_job': 'None', 'dataset.task': 'classification_binary', 'general.abs_repo_path': 'None', 'predictor.model_name': 'None'}\n",
      "metrics: {'test.balanced_accuracy': 0.5157588739290085, 'val.recall': 0.14, 'test.recall': 0.17105263157894737, 'train.accuracy': 0.6016042780748663, 'test.ROCAUC': 0.488984088127295, 'val.ROCAUC': 0.495593220338983, 'val.matthews_corr_coef': -0.009418224292232788, 'val.specificity': 0.8531073446327684, 'val.balanced_accuracy': 0.4965536723163842, 'train.balanced_accuracy': 0.5048384048384048, 'test.accuracy': 0.6491935483870968, 'test.precision': 0.35135135135135137, 'test.f_score': 0.23008849557522124, 'val.precision': 0.35, 'train.matthews_corr_coef': 0.013169756535559688, 'val.accuracy': 0.5956678700361011, 'test.specificity': 0.8604651162790697, 'train.precision': 0.3780487804878049, 'val.f_score': 0.2, 'train.ROCAUC': 0.508785072421436, 'train.specificity': 0.8573426573426574, 'train.f_score': 0.2171628721541156, 'train.recall': 0.15233415233415235, 'test.matthews_corr_coef': 0.04078346365672625}\n",
      "tags: {}\n",
      "results stored in /novo/projects/departments/cdd/molecular_ai/mlbp/artifacts/2025-02-05-0016_calm-fish-435/stats_metrics.yaml\n",
      "file:///novo/projects/departments/cdd/public/users/ehec/sbxw_files_2/mlruns/672490144989501938/355865cfe1324682a01b734a5b3376ce/artifacts\n",
      "\u001b[34mSystem information\u001b[0m: Linux #70~20.04.1-Ubuntu SMP Fri Jun 14 15:42:13 UTC 2024\n",
      "\u001b[34mPython version\u001b[0m: 3.10.14\n",
      "\u001b[34mMLflow version\u001b[0m: 2.13.0\n",
      "\u001b[34mMLflow module location\u001b[0m: /nfs_home/users/sbxw/mambaforge/envs/mlbp/lib/python3.10/site-packages/mlflow/__init__.py\n",
      "\u001b[34mTracking URI\u001b[0m: file:///novo/projects/departments/cdd/public/users/ehec/sbxw_files_2/mlruns\n",
      "\u001b[34mRegistry URI\u001b[0m: file:///novo/projects/departments/cdd/public/users/ehec/sbxw_files_2/mlruns\n",
      "\u001b[34mActive experiment ID\u001b[0m: 672490144989501938\n",
      "\u001b[34mActive run ID\u001b[0m: 355865cfe1324682a01b734a5b3376ce\n",
      "\u001b[34mActive run artifact URI\u001b[0m: file:///novo/projects/departments/cdd/public/users/ehec/sbxw_files_2/mlruns/672490144989501938/355865cfe1324682a01b734a5b3376ce/artifacts\n",
      "\u001b[34mMLflow dependencies\u001b[0m: \n",
      "  Flask: 2.2.5\n",
      "  Jinja2: 3.1.4\n",
      "  aiohttp: 3.9.5\n",
      "  alembic: 1.13.1\n",
      "  cachetools: 5.3.3\n",
      "  click: 8.1.7\n",
      "  cloudpickle: 3.0.0\n",
      "  docker: 7.0.0\n",
      "  entrypoints: 0.4\n",
      "  gitpython: 3.1.43\n",
      "  graphene: 3.3\n",
      "  gunicorn: 22.0.0\n",
      "  importlib-metadata: 7.1.0\n",
      "  markdown: 3.6\n",
      "  matplotlib: 3.9.0\n",
      "  numpy: 1.26.4\n",
      "  opentelemetry-api: 1.16.0\n",
      "  opentelemetry-sdk: 1.16.0\n",
      "  packaging: 24.0\n",
      "  pandas: 2.2.2\n",
      "  protobuf: 4.25.3\n",
      "  pyarrow: 15.0.2\n",
      "  pydantic: 2.7.1\n",
      "  pytz: 2024.1\n",
      "  pyyaml: 6.0.1\n",
      "  querystring-parser: 1.2.4\n",
      "  requests: 2.32.1\n",
      "  scikit-learn: 1.4.2\n",
      "  scipy: 1.13.0\n",
      "  sqlalchemy: 2.0.30\n",
      "  sqlparse: 0.5.0\n",
      "  virtualenv: 20.26.2\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "repo_dir = '/novo/projects/departments/cdd/molecular_ai/sbxw/repos/ML-BP-Domino'\n",
    "conda_env_name = 'mlbp'\n",
    "\n",
    "# Create command (single set of params)\n",
    "cmd = [\n",
    "    f\"/nfs_home/users/sbxw/mambaforge/condabin/conda run --no-capture-output -n {conda_env_name} python\",\n",
    "    f\"{repo_dir}/src/cli/training.py\",\n",
    "    \"mlflow=lovelace\", \"persistence=lovelace\",\n",
    "    \"dataset.use_predefined_split=true\",\n",
    "    \"dataset.data_name=sbxw_fibrillation_peptide_waltzdb-train-val_serrano-test\", \"dataset.task=classification_binary\", \n",
    "    \"embedder=esm2_t6_8M\",\"embedder.mean_pool=false\",\n",
    "    \"dimred=noreduction\",\n",
    "    \"predictor=lightattention\", \n",
    "    \"predictor.hparams.kernel_size=1\", \"predictor.hparams.max_epochs=10000\", \"predictor.hparams.patience=200\",\n",
    "    \"predictor.hparams.batch_size=5000\", \"predictor.hparams.learning_rate=0.0005\", \"predictor.hparams.linear_post_concat=true\",\n",
    "    \"predictor.hparams.conv1d_downsizing_factor=1\",\n",
    "    \"mlflow.experiment_name=ML-BP-Domino\",\n",
    "    \"plots.generate_plots=false\",\n",
    "]\n",
    "\n",
    "command_str = \" \".join(cmd)\n",
    "print(command_str)\n",
    "!PYTHONPATH=repo_dir; $command_str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a8b0724a-3ceb-4bb7-a92e-7508125fc7c5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'data_name': 'sbxw_fibrillation_peptide_waltzdb-train-val_serrano-test',\n",
       " 'run_id': '47e8875ea2f543c1999a273534f6ff6d',\n",
       " 'run_name': 'overjoyed-fish-385',\n",
       " 'test': {'ROCAUC': 0.5755813953488371,\n",
       "  'accuracy': 0.3870967741935484,\n",
       "  'balanced_accuracy': 0.5250917992656059,\n",
       "  'f_score': 0.46853146853146854,\n",
       "  'fn': 9,\n",
       "  'fp': 143,\n",
       "  'm_corr_coef': 0.06422903160418497,\n",
       "  'name': '',\n",
       "  'optimal_cutoff': 0.74,\n",
       "  'optimal_mcc': 0.1761883308637748,\n",
       "  'precision': 0.319047619047619,\n",
       "  'recall': 0.881578947368421,\n",
       "  'specificity': 0.1686046511627907,\n",
       "  'tn': 29,\n",
       "  'total': 248,\n",
       "  'tp': 67,\n",
       "  'tp+tn': 96},\n",
       " 'train': {'ROCAUC': 0.45822580368034915,\n",
       "  'accuracy': 0.4019607843137255,\n",
       "  'balanced_accuracy': 0.4921375921375921,\n",
       "  'f_score': 0.4988797610156833,\n",
       "  'fn': 73,\n",
       "  'fp': 598,\n",
       "  'm_corr_coef': -0.02015816676011827,\n",
       "  'name': '',\n",
       "  'optimal_cutoff': 0.24,\n",
       "  'optimal_mcc': 0.029719606788581064,\n",
       "  'precision': 0.3583690987124464,\n",
       "  'recall': 0.8206388206388207,\n",
       "  'specificity': 0.16363636363636364,\n",
       "  'tn': 117,\n",
       "  'total': 1122,\n",
       "  'tp': 334,\n",
       "  'tp+tn': 451},\n",
       " 'val': {'ROCAUC': 0.5245197740112995,\n",
       "  'accuracy': 0.4548736462093863,\n",
       "  'balanced_accuracy': 0.5495197740112995,\n",
       "  'f_score': 0.541033434650456,\n",
       "  'fn': 11,\n",
       "  'fp': 140,\n",
       "  'm_corr_coef': 0.1256773234773399,\n",
       "  'name': '',\n",
       "  'optimal_cutoff': 0.43,\n",
       "  'optimal_mcc': 0.1257588740306661,\n",
       "  'precision': 0.388646288209607,\n",
       "  'recall': 0.89,\n",
       "  'specificity': 0.20903954802259886,\n",
       "  'tn': 37,\n",
       "  'total': 277,\n",
       "  'tp': 89,\n",
       "  'tp+tn': 126}}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import yaml\n",
    "path = '/novo/projects/departments/cdd/molecular_ai/mlbp/artifacts/2025-02-04-2356_overjoyed-fish-385/stats_metrics.yaml'\n",
    "with open(path,'r') as stream:\n",
    "    data = yaml.safe_load(stream)\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e282a930-b707-417c-bc39-bc34723ce2ac",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/nfs_home/users/sbxw/mambaforge/condabin/conda run --no-capture-output -n mlbp python /novo/projects/departments/cdd/molecular_ai/sbxw/repos/ML-BP-Domino/src/cli/training.py mlflow=lovelace persistence=lovelace dataset.use_predefined_split=true dataset.data_name=sbxw_fibrillation_peptide_waltzdb-train-val_serrano-test dataset.task=classification_binary embedder=esm2_t6_8M embedder.mean_pool=false dimred=noreduction predictor=lightattention predictor.hparams.kernel_size=5 predictor.hparams.max_epochs=10000 predictor.hparams.patience=200 predictor.hparams.batch_size=5000 predictor.hparams.learning_rate=0.0005 predictor.hparams.linear_post_concat=true predictor.hparams.conv1d_downsizing_factor=256 mlflow.experiment_name=ML-BP-Domino plots.generate_plots=false\n",
      "[2025-02-15 00:41:05,012][__main__][INFO] - Workflow configuration:\n",
      "\n",
      "general:\n",
      "  run_mode: train\n",
      "  abs_repo_path: null\n",
      "  composite_model_name: null\n",
      "  composite_model_path: null\n",
      "  precomputed_embeddings_path: null\n",
      "  random_state: 42\n",
      "dataset:\n",
      "  data_name: sbxw_fibrillation_peptide_waltzdb-train-val_serrano-test\n",
      "  add_data_columns: false\n",
      "  data_columns_dimred: false\n",
      "  data_columns_standard: false\n",
      "  data_scaler: RobustScaler\n",
      "  rbf_encoder: RadialBasisFunctionGaussian\n",
      "  rbf_n_kernels: 10\n",
      "  task: classification_binary\n",
      "  use_predefined_split: true\n",
      "  data_split:\n",
      "    train: 0.8\n",
      "    val: 0.0\n",
      "    test: 0.2\n",
      "embedder:\n",
      "  class_name: ESM\n",
      "  model_name: esm2_t6_8M_UR50D\n",
      "  model_path: null\n",
      "  standardize: false\n",
      "  scalar_type: StandardScaler\n",
      "  hparams: null\n",
      "  n_copies: 1\n",
      "  chain_break: poly-gly-linker\n",
      "  buffer_scale_factor: 2.0\n",
      "  max_batch_size: 400\n",
      "  simple_batching: false\n",
      "  strict: true\n",
      "  verbose: false\n",
      "  mean_pool: false\n",
      "dimred:\n",
      "  class_name: NoReduction\n",
      "  transform_name: null\n",
      "  fraction_variance_explained: null\n",
      "predictor:\n",
      "  class_name: LightAttention\n",
      "  model_name: null\n",
      "  model_type: classification_binary\n",
      "  mem_per_job: null\n",
      "  hparams:\n",
      "    kernel_size: 5\n",
      "    dropout: 0.25\n",
      "    conv_dropout: 0.25\n",
      "    learning_rate: 0.0005\n",
      "    batch_size: 5000\n",
      "    max_epochs: 10000\n",
      "    patience: 200\n",
      "    linear_post_concat: true\n",
      "    conv1d_downsizing_factor: 256\n",
      "    plain_LA: false\n",
      "    kernel_two_size: 5\n",
      "    multi_conv: false\n",
      "    optimal_cutoff: 0.5\n",
      "persistence:\n",
      "  type: lovelace\n",
      "  data_root_folder: /novo/projects/departments/cdd/molecular_ai/mlbp/data\n",
      "  artifacts_root_folder: /novo/projects/departments/cdd/molecular_ai/mlbp/artifacts\n",
      "  training_data: static_input_data\n",
      "  pretrained_weights: static_pretrained_weights\n",
      "mlflow:\n",
      "  tracking_uri: http://0.0.0.0:5001\n",
      "  experiment_name: ML-BP-Domino\n",
      "plots:\n",
      "  generate_plots: false\n",
      "\n",
      "2025-02-15 00:41:05.786259: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2025-02-15 00:41:05.786306: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2025-02-15 00:41:05.787796: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2025-02-15 00:41:05.795224: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2025-02-15 00:41:09.344997: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "[2025-02-15 00:41:14,370][src.model.composite_model][INFO] - Amorprot: <class 'src.model.embedders.Amorprot'>\n",
      "[2025-02-15 00:41:14,370][src.model.composite_model][INFO] - Ankh: <class 'src.model.embedders.Ankh'>\n",
      "[2025-02-15 00:41:14,370][src.model.composite_model][INFO] - Biophys: <class 'src.model.embedders.Biophys'>\n",
      "[2025-02-15 00:41:14,370][src.model.composite_model][INFO] - ESM: <class 'src.model.embedders.ESM'>\n",
      "[2025-02-15 00:41:14,370][src.model.composite_model][INFO] - Kmer: <class 'src.model.embedders.Kmer'>\n",
      "[2025-02-15 00:41:14,370][src.model.composite_model][INFO] - PrecomputedDescriptors: <class 'src.model.embedders.PrecomputedDescriptors'>\n",
      "[2025-02-15 00:41:14,370][src.model.composite_model][INFO] - ProtT5: <class 'src.model.embedders.ProtT5'>\n",
      "[2025-02-15 00:41:14,372][src.model.composite_model][INFO] - NoReduction: <class 'src.model.dimred.NoReduction'>\n",
      "[2025-02-15 00:41:14,372][src.model.composite_model][INFO] - PCADimReduction: <class 'src.model.dimred.PCADimReduction'>\n",
      "[2025-02-15 00:41:14,439][src.model.composite_model][INFO] - KNearestNeighbors: <class 'src.model.predictors.KNearestNeighbors'>\n",
      "[2025-02-15 00:41:14,439][src.model.composite_model][INFO] - LightAttention: <class 'src.model.predictors.LightAttention'>\n",
      "[2025-02-15 00:41:14,439][src.model.composite_model][INFO] - LogisticRegression: <class 'src.model.predictors.LogisticRegression'>\n",
      "[2025-02-15 00:41:14,439][src.model.composite_model][INFO] - MLP: <class 'src.model.predictors.MLP'>\n",
      "[2025-02-15 00:41:14,439][src.model.composite_model][INFO] - RandomForest: <class 'src.model.predictors.RandomForest'>\n",
      "[2025-02-15 00:41:14,439][src.model.composite_model][INFO] - RidgeRegression: <class 'src.model.predictors.RidgeRegression'>\n",
      "[2025-02-15 00:41:14,440][src.model.composite_model][INFO] - XGBoost: <class 'src.model.predictors.XGBoost'>\n",
      "[2025-02-15 00:41:14,440][src.model.dimred][INFO] - Load class (NoReduction): NoReduction\n",
      "[2025-02-15 00:41:14,440][src.model.abstract_components][INFO] - Load class (DimRed Model): NoReduction\n",
      "[2025-02-15 00:41:14,440][src.model.predictors][INFO] - Load class (LightAttention): LightAttention\n",
      "[2025-02-15 00:41:14,440][src.model.abstract_components][INFO] - Load class (TorchPredictorModel): LightAttention\n",
      "[2025-02-15 00:41:14,440][src.model.abstract_components][INFO] - Load class (Predictor Model): LightAttention\n",
      "[2025-02-15 00:41:14,441][src.model.composite_model][INFO] - Composite model name: esm2t68MUR50D_LightAttention_sbxwfibrillationpeptidewaltzdb-train-valserrano-test\n",
      "[2025-02-15 00:41:14,441][src.model.composite_model][INFO] - Initialized model: esm2t68MUR50D_LightAttention_sbxwfibrillationpeptidewaltzdb-train-valserrano-test in run_mode = train\n",
      "[2025-02-15 00:41:14,442][src.helpers.dataset][INFO] - Loading csv file: /novo/projects/departments/cdd/molecular_ai/mlbp/data/static_input_data/sbxw_fibrillation_peptide_waltzdb-train-val_serrano-test.csv\n",
      "[2025-02-15 00:41:14,446][src.helpers.dataset][INFO] - No additional data columns found while parsing.\n",
      "[2025-02-15 00:41:14,448][src.helpers.dataset][INFO] - Select data according to predetermined splits in the dataframe, train (N = 1122), validation (N = 277), test (N = 248)\n",
      "[2025-02-15 00:41:14,448][src.helpers.dataset][INFO] - Loaded columns: {}\n",
      "[2025-02-15 00:41:14,449][src.helpers.mlflow_helpers][INFO] - Setting up MLflow...\n",
      "[2025-02-15 00:41:14,449][src.helpers.mlflow_helpers][INFO] - Experiment name: ML-BP-Domino\n",
      "[2025-02-15 00:41:14,449][src.helpers.mlflow_helpers][INFO] - Setting MLflow tracking URI to http://0.0.0.0:5001\n",
      "[2025-02-15 00:41:14,731][src.helpers.mlflow_helpers][INFO] - Setting MLflow experiment to ML-BP-Domino\n",
      "[2025-02-15 00:41:15,611][__main__][INFO] - Compute embeddings on-the-fly and train model\n",
      "[2025-02-15 00:41:15,612][src.model.abstract_components][INFO] - Load class (LLMEmbedderModel): ESM\n",
      "[2025-02-15 00:41:15,612][src.model.abstract_components][INFO] - Load class (Embedder Model): ESM\n",
      "[2025-02-15 00:41:15,612][src.model.embedders][INFO] - Using existing cache directory: /novo/projects/departments/cdd/molecular_ai/mlbp/data/static_pretrained_weights\n",
      "Using cache found in /novo/projects/departments/cdd/molecular_ai/mlbp/data/static_pretrained_weights/facebookresearch_esm_main\n",
      "[2025-02-15 00:41:15,975][src.model.embedders][INFO] - moving model to cuda\n",
      "[2025-02-15 00:41:16,242][src.model.abstract_components][INFO] - Total memory: 23.58378496GB\n",
      "Memory already allocated: 0.030069248GB\n",
      "[2025-02-15 00:41:16,812][src.model.embedders][INFO] - Final results len: 1122\n",
      "[2025-02-15 00:41:16,812][src.model.composite_model][INFO] - Residue embeddings\n",
      "[2025-02-15 00:41:16,812][src.model.abstract_components][INFO] - Total memory: 23.58378496GB\n",
      "Memory already allocated: 0.038758912GB\n",
      "[2025-02-15 00:41:16,850][src.model.embedders][INFO] - Final results len: 277\n",
      "/nfs_home/users/sbxw/mambaforge/envs/mlbp/lib/python3.10/site-packages/lightning/fabric/plugins/environments/slurm.py:204: The `srun` command is available on your system but is not used. HINT: If your intention is to run Lightning on SLURM, prepend your python command with `srun` like so: srun python /novo/projects/departments/cdd/molecular_ai/sbxw/rep ...\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "2025/02/15 00:41:17 WARNING mlflow.utils.autologging_utils: You are using an unsupported version of pytorch. If you encounter errors during autologging, try upgrading / downgrading pytorch to a supported version, or try upgrading MLflow.\n",
      "2025/02/15 00:41:17 WARNING mlflow.utils.autologging_utils: MLflow autologging encountered a warning: \"/nfs_home/users/sbxw/mambaforge/envs/mlbp/lib/python3.10/site-packages/mlflow/pytorch/_lightning_autolog.py:463: UserWarning: Autologging is known to be compatible with pytorch-lightning versions between 1.9.0 and 2.2.4 and may not succeed with packages outside this range.\"\n",
      "/nfs_home/users/sbxw/mambaforge/envs/mlbp/lib/python3.10/site-packages/lightning/fabric/plugins/environments/slurm.py:204: The `srun` command is available on your system but is not used. HINT: If your intention is to run Lightning on SLURM, prepend your python command with `srun` like so: srun python /novo/projects/departments/cdd/molecular_ai/sbxw/rep ...\n",
      "[2025-02-15 00:41:17,925][pytorch_lightning.utilities.rank_zero][INFO] - You are using a CUDA device ('NVIDIA L4') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name                    | Type       | Params | Mode \n",
      "---------------------------------------------------------------\n",
      "0 | feature_convolution     | Conv1d     | 409 K  | train\n",
      "1 | attention_convolution   | Conv1d     | 409 K  | train\n",
      "2 | feature_convolution_2   | Conv1d     | 409 K  | train\n",
      "3 | attention_convolution_2 | Conv1d     | 409 K  | train\n",
      "4 | softmax                 | Softmax    | 0      | train\n",
      "5 | dropout                 | Dropout    | 0      | train\n",
      "6 | dropout_2               | Dropout    | 0      | train\n",
      "7 | sigmoid                 | Sigmoid    | 0      | train\n",
      "8 | mlp                     | Sequential | 149 K  | train\n",
      "9 | loss_fxn                | BCELoss    | 0      | train\n",
      "---------------------------------------------------------------\n",
      "1.8 M     Trainable params\n",
      "0         Non-trainable params\n",
      "1.8 M     Total params\n",
      "7.158     Total estimated model params size (MB)\n",
      "20        Modules in train mode\n",
      "0         Modules in eval mode\n",
      "/nfs_home/users/sbxw/mambaforge/envs/mlbp/lib/python3.10/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:424: The 'val_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=7` in the `DataLoader` to improve performance.\n",
      "/nfs_home/users/sbxw/mambaforge/envs/mlbp/lib/python3.10/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:424: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=7` in the `DataLoader` to improve performance.\n",
      "/nfs_home/users/sbxw/mambaforge/envs/mlbp/lib/python3.10/site-packages/lightning/pytorch/loops/fit_loop.py:298: The number of training batches (1) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.\n",
      "2025/02/15 00:55:46 WARNING mlflow.utils.autologging_utils: MLflow autologging encountered a warning: \"/nfs_home/users/sbxw/mambaforge/envs/mlbp/lib/python3.10/site-packages/_distutils_hack/__init__.py:26: UserWarning: Setuptools is replacing distutils.\"\n",
      "[2025-02-15 00:55:46,965][src.model.abstract_components][INFO] - MODEL STOPPED BY EARLY STOPPER AT EPOCH 6575\n",
      "[2025-02-15 00:55:46,967][src.model.abstract_components][INFO] - BEST MODEL VALIDATION LOSS IS 0.3844195306301117\n",
      "[2025-02-15 00:55:46,967][src.model.abstract_components][INFO] - BEST MODEL SAVED AT ./mlruns/672490144989501938/48e5916abd64410f9bf66d28967f9154/checkpoints/epoch=6375-step=6376.ckpt\n",
      "[2025-02-15 00:55:55,220][src.model.predictors][INFO] - Moving embeddings to device: cuda\n",
      "[2025-02-15 00:55:55,353][src.model.predictors][INFO] - Optimal cutoff is: 0.68 with MCC: 0.6076783679096256\n",
      "[2025-02-15 00:55:55,370][src.model.predictors][INFO] - Moving embeddings to device: cuda\n",
      "[2025-02-15 00:55:55,376][src.model.predictors][INFO] - Moving embeddings to device: cuda\n",
      "[2025-02-15 00:55:55,377][src.model.composite_model][INFO] - This is the updated predictor name: TODO\n",
      "[2025-02-15 00:55:55,378][src.model.composite_model][INFO] - Composite model name: esm2t68MUR50D_LightAttention_sbxwfibrillationpeptidewaltzdb-train-valserrano-test\n",
      "[2025-02-15 00:55:55,378][src.model.composite_model][INFO] - Best model is: \n",
      "[2025-02-15 00:55:55,378][src.model.composite_model][INFO] - Moving to test mode\n",
      "[2025-02-15 00:55:55,378][src.model.composite_model][INFO] - Composite model name: esm2t68MUR50D_LightAttention_sbxwfibrillationpeptidewaltzdb-train-valserrano-test\n",
      "[2025-02-15 00:55:55,378][src.model.composite_model][INFO] - Saving model: esm2t68MUR50D_LightAttention_sbxwfibrillationpeptidewaltzdb-train-valserrano-test\n",
      "<RunInfo: artifact_uri='file:///novo/projects/departments/cdd/public/users/ehec/sbxw_files_2/mlruns/672490144989501938/48e5916abd64410f9bf66d28967f9154/artifacts', end_time=None, experiment_id='672490144989501938', lifecycle_stage='active', run_id='48e5916abd64410f9bf66d28967f9154', run_name='dapper-trout-29', run_uuid='48e5916abd64410f9bf66d28967f9154', start_time=1739580074990, status='RUNNING', user_id='sbxw'>\n",
      "[2025-02-15 00:55:55,465][src.model.abstract_components][INFO] - Total memory: 23.58378496GB\n",
      "Memory already allocated: 0.046892032GB\n",
      "[2025-02-15 00:55:55,565][src.model.embedders][INFO] - Final results len: 248\n",
      "[2025-02-15 00:55:55,565][src.model.composite_model][INFO] - Residue embeddings\n",
      "[2025-02-15 00:55:55,577][src.model.predictors][INFO] - Moving embeddings to device: cuda\n",
      "/nfs_home/users/sbxw/mambaforge/envs/mlbp/lib/python3.10/site-packages/torch/nn/modules/conv.py:306: UserWarning: Plan failed with a cudnnException: CUDNN_BACKEND_EXECUTION_PLAN_DESCRIPTOR: cudnnFinalize Descriptor Failed cudnn_status: CUDNN_STATUS_NOT_SUPPORTED (Triggered internally at ../aten/src/ATen/native/cudnn/Conv_v8.cpp:919.)\n",
      "  return F.conv1d(input, weight, bias, self.stride,\n",
      "sequences: (1122,)\n",
      "sequence_embeddings: 1122\n",
      "predictions: (1122,)\n",
      "data_split: train\n",
      "labels: (1122,)\n",
      "predictions_probability: (1122,)\n",
      "sequences: (277,)\n",
      "sequence_embeddings: 277\n",
      "predictions: (277,)\n",
      "data_split: val\n",
      "labels: (277,)\n",
      "predictions_probability: (277,)\n",
      "sequences: (248,)\n",
      "sequence_embeddings: 248\n",
      "predictions: (248,)\n",
      "data_split: test\n",
      "labels: (248,)\n",
      "predictions_probability: (248,)\n",
      "[2025-02-15 00:55:56,959][src.model.composite_model][INFO] - Composite model name: esm2t68MUR50D_LightAttention_sbxwfibrillationpeptidewaltzdb-train-valserrano-test\n",
      "[2025-02-15 00:55:56,995][__main__][INFO] - Done!\n",
      "run_id: 48e5916abd64410f9bf66d28967f9154\n",
      "artifacts: ['model/MLmodel', 'model/conda.yaml', 'model/data', 'model/metadata', 'model/python_env.yaml', 'model/requirements.txt']\n",
      "params: {'general.random_state': '42', 'embedder.class_name': 'ESM', 'mlflow.experiment_name': 'ML-BP-Domino', 'predictor.mem_per_job': 'None', 'predictor.hparams.max_epochs': '10000', 'dataset.data_columns_standard': 'False', 'general.abs_repo_path': 'None', 'dataset.rbf_encoder': 'RadialBasisFunctionGaussian', 'predictor.hparams.kernel_two_size': '5', 'predictor.hparams.optimal_cutoff': '0.5', 'maximize': 'False', 'predictor.hparams.linear_post_concat': 'True', 'persistence.data_root_folder': '/novo/projects/departments/cdd/molecular_ai/mlbp/data', 'mlflow.tracking_uri': 'http://0.0.0.0:5001', 'predictor.hparams.learning_rate': '0.0005', 'learning_rate': '0.0005', 'general.composite_model_name': 'esm2t68MUR50D_LightAttention_sbxwfibrillationpeptidewaltzdb-train-valserrano-test', 'predictor.hparams.kernel_size': '5', 'persistence.training_data': 'static_input_data', 'predictor.model_type': 'classification_binary', 'dataset.data_split.test': '0.2', 'kernel_two_size': '5', 'dimred.fraction_variance_explained': 'None', 'nesterov': 'False', 'dataset.data_scaler': 'RobustScaler', 'plain_LA': 'False', 'embedder.model_path': 'None', 'embedder.max_batch_size': '400', 'dataset.data_split.train': '0.8', 'momentum': '0', 'multi_conv': 'False', 'embedder.chain_break': 'poly-gly-linker', 'dataset.data_columns_dimred': 'False', 'predictor.class_name': 'LightAttention', 'conv_dropout': '0.25', 'weight_decay': '0', 'general.precomputed_embeddings_path': 'None', 'dampening': '0', 'differentiable': 'False', 'predictor.hparams.patience': '200', 'embedder.hparams': 'None', 'kernel_size': '5', 'embedder.mean_pool': 'False', 'dimred.class_name': 'NoReduction', 'conv1d_downsizing_factor': '256', 'predictor.hparams.plain_LA': 'False', 'embedder.standardize': 'False', 'dataset.data_split.val': '0.0', 'general.composite_model_path': 'None', 'embedder.strict': 'True', 'dataset.use_predefined_split': 'True', 'embedder.scalar_type': 'StandardScaler', 'dimred.transform_name': 'None', 'dataset.rbf_n_kernels': '10', 'foreach': 'None', 'predictor.hparams.batch_size': '5000', 'predictor.hparams.multi_conv': 'False', 'dataset.task': 'classification_binary', 'predictor.model_name': 'None', 'persistence.pretrained_weights': 'static_pretrained_weights', 'plots.generate_plots': 'False', 'lr': '0.0005', 'embedder.n_copies': '1', 'persistence.type': 'lovelace', 'embedder.buffer_scale_factor': '2.0', 'linear_post_concat': 'True', 'embedder.verbose': 'False', 'embedder.simple_batching': 'False', 'predictor.hparams.dropout': '0.25', 'output_dim': '1', 'optimizer_name': 'SGD', 'general.run_mode': 'train', 'embeddings_dim': '320', 'dataset.data_name': 'sbxw_fibrillation_peptide_waltzdb-train-val_serrano-test', 'persistence.artifacts_root_folder': '/novo/projects/departments/cdd/molecular_ai/mlbp/artifacts', 'predictor.hparams.conv_dropout': '0.25', 'dropout': '0.25', 'model_type': 'classification_binary', 'fused': 'None', 'dataset.add_data_columns': 'False', 'embedder.model_name': 'esm2_t6_8M_UR50D', 'epochs': '10000', 'predictor.hparams.conv1d_downsizing_factor': '256'}\n",
      "metrics: {'train.precision': 0.8987730061349694, 'val.recall': 0.59, 'train_loss': 0.29890140891075134, 'train_loss_step': 0.29890140891075134, 'val.ROCAUC': 0.8959887005649717, 'train.balanced_accuracy': 0.8368739368739369, 'test.recall': 0.3684210526315789, 'test.specificity': 0.8372093023255814, 'val_loss': 0.3865044414997101, 'test.f_score': 0.42424242424242425, 'train_loss_epoch': 0.29890140891075134, 'train.matthews_corr_coef': 0.7134808141835781, 'test.accuracy': 0.6935483870967742, 'test.ROCAUC': 0.7236842105263158, 'val.specificity': 0.9378531073446328, 'test.balanced_accuracy': 0.6028151774785802, 'val.accuracy': 0.8122743682310469, 'test.matthews_corr_coef': 0.22673241660444166, 'val.f_score': 0.6941176470588235, 'test.precision': 0.5, 'train.specificity': 0.9538461538461539, 'val.balanced_accuracy': 0.7639265536723163, 'val.matthews_corr_coef': 0.5833987885146541, 'val.precision': 0.8428571428571429, 'train.f_score': 0.7994542974079127, 'train.ROCAUC': 0.9439150530059621, 'train.recall': 0.7199017199017199, 'epoch': 6575.0, 'train.accuracy': 0.8689839572192514}\n",
      "tags: {'Mode': 'training'}\n",
      "results stored in /novo/projects/departments/cdd/molecular_ai/mlbp/artifacts/2025-02-15-0041_dapper-trout-29/stats_metrics.yaml\n",
      "file:///novo/projects/departments/cdd/public/users/ehec/sbxw_files_2/mlruns/672490144989501938/48e5916abd64410f9bf66d28967f9154/artifacts\n",
      "\u001b[34mSystem information\u001b[0m: Linux #70~20.04.1-Ubuntu SMP Fri Jun 14 15:42:13 UTC 2024\n",
      "\u001b[34mPython version\u001b[0m: 3.10.14\n",
      "\u001b[34mMLflow version\u001b[0m: 2.13.0\n",
      "\u001b[34mMLflow module location\u001b[0m: /nfs_home/users/sbxw/mambaforge/envs/mlbp/lib/python3.10/site-packages/mlflow/__init__.py\n",
      "\u001b[34mTracking URI\u001b[0m: http://0.0.0.0:5001\n",
      "\u001b[34mRegistry URI\u001b[0m: http://0.0.0.0:5001\n",
      "\u001b[34mActive experiment ID\u001b[0m: 672490144989501938\n",
      "\u001b[34mActive run ID\u001b[0m: 48e5916abd64410f9bf66d28967f9154\n",
      "\u001b[34mActive run artifact URI\u001b[0m: file:///novo/projects/departments/cdd/public/users/ehec/sbxw_files_2/mlruns/672490144989501938/48e5916abd64410f9bf66d28967f9154/artifacts\n",
      "\u001b[34mMLflow dependencies\u001b[0m: \n",
      "  Flask: 2.2.5\n",
      "  Jinja2: 3.1.4\n",
      "  aiohttp: 3.9.5\n",
      "  alembic: 1.13.1\n",
      "  cachetools: 5.3.3\n",
      "  click: 8.1.7\n",
      "  cloudpickle: 3.0.0\n",
      "  docker: 7.0.0\n",
      "  entrypoints: 0.4\n",
      "  gitpython: 3.1.43\n",
      "  graphene: 3.3\n",
      "  gunicorn: 22.0.0\n",
      "  importlib-metadata: 7.1.0\n",
      "  markdown: 3.6\n",
      "  matplotlib: 3.9.0\n",
      "  numpy: 1.26.4\n",
      "  opentelemetry-api: 1.16.0\n",
      "  opentelemetry-sdk: 1.16.0\n",
      "  packaging: 24.0\n",
      "  pandas: 2.2.2\n",
      "  protobuf: 4.25.3\n",
      "  pyarrow: 15.0.2\n",
      "  pydantic: 2.7.1\n",
      "  pytz: 2024.1\n",
      "  pyyaml: 6.0.1\n",
      "  querystring-parser: 1.2.4\n",
      "  requests: 2.32.1\n",
      "  scikit-learn: 1.4.2\n",
      "  scipy: 1.13.0\n",
      "  sqlalchemy: 2.0.30\n",
      "  sqlparse: 0.5.0\n",
      "  virtualenv: 20.26.2\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "repo_dir = '/novo/projects/departments/cdd/molecular_ai/sbxw/repos/ML-BP-Domino'\n",
    "conda_env_name = 'mlbp'\n",
    "\n",
    "# Create command (single set of params)\n",
    "cmd = [\n",
    "    f\"/nfs_home/users/sbxw/mambaforge/condabin/conda run --no-capture-output -n {conda_env_name} python\",\n",
    "    f\"{repo_dir}/src/cli/training.py\",\n",
    "    \"mlflow=lovelace\", \"persistence=lovelace\",\n",
    "    \"dataset.use_predefined_split=true\",\n",
    "    \"dataset.data_name=sbxw_fibrillation_peptide_waltzdb-train-val_serrano-test\", \"dataset.task=classification_binary\", \n",
    "    \"embedder=esm2_t6_8M\",\"embedder.mean_pool=false\",\n",
    "    \"dimred=noreduction\",\n",
    "    \"predictor=lightattention\", \n",
    "    \"predictor.hparams.kernel_size=5\", \"predictor.hparams.max_epochs=10000\", \"predictor.hparams.patience=200\",\n",
    "    \"predictor.hparams.batch_size=5000\", \"predictor.hparams.learning_rate=0.0005\", \"predictor.hparams.linear_post_concat=true\",\n",
    "    \"predictor.hparams.conv1d_downsizing_factor=256\",\n",
    "    \"mlflow.experiment_name=ML-BP-Domino\",\n",
    "    \"plots.generate_plots=false\",\n",
    "]\n",
    "\n",
    "command_str = \" \".join(cmd)\n",
    "print(command_str)\n",
    "!PYTHONPATH=repo_dir; $command_str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d32907c3-b947-44a2-84ba-92e8dd34cd5d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/nfs_home/users/sbxw/mambaforge/condabin/conda run --no-capture-output -n mlbp python /novo/projects/departments/cdd/molecular_ai/sbxw/repos/ML-BP-Domino/src/cli/training.py mlflow=lovelace persistence=lovelace dataset.use_predefined_split=true dataset.data_name=sbxw_fibrillation_peptide_waltzdb-train-val_serrano-test dataset.task=classification_binary embedder=esm2_t6_8M embedder.mean_pool=false dimred=noreduction predictor=lightattention predictor.hparams.kernel_size=5 predictor.hparams.max_epochs=10000 predictor.hparams.patience=200 predictor.hparams.batch_size=5000 predictor.hparams.learning_rate=0.0005 predictor.hparams.linear_post_concat=true predictor.hparams.conv1d_downsizing_factor=256 mlflow.experiment_name=ML-BP-Domino plots.generate_plots=false\n",
      "[2025-02-15 15:53:22,730][__main__][INFO] - Workflow configuration:\n",
      "\n",
      "general:\n",
      "  run_mode: train\n",
      "  abs_repo_path: null\n",
      "  composite_model_name: null\n",
      "  composite_model_path: null\n",
      "  precomputed_embeddings_path: null\n",
      "  random_state: 42\n",
      "dataset:\n",
      "  data_name: sbxw_fibrillation_peptide_waltzdb-train-val_serrano-test\n",
      "  add_data_columns: false\n",
      "  data_columns_dimred: false\n",
      "  data_columns_standard: false\n",
      "  data_scaler: RobustScaler\n",
      "  rbf_encoder: RadialBasisFunctionGaussian\n",
      "  rbf_n_kernels: 10\n",
      "  task: classification_binary\n",
      "  use_predefined_split: true\n",
      "  data_split:\n",
      "    train: 0.8\n",
      "    val: 0.0\n",
      "    test: 0.2\n",
      "embedder:\n",
      "  class_name: ESM\n",
      "  model_name: esm2_t6_8M_UR50D\n",
      "  model_path: null\n",
      "  standardize: false\n",
      "  scalar_type: StandardScaler\n",
      "  hparams: null\n",
      "  n_copies: 1\n",
      "  chain_break: poly-gly-linker\n",
      "  buffer_scale_factor: 2.0\n",
      "  max_batch_size: 400\n",
      "  simple_batching: false\n",
      "  strict: true\n",
      "  verbose: false\n",
      "  mean_pool: false\n",
      "dimred:\n",
      "  class_name: NoReduction\n",
      "  transform_name: null\n",
      "  fraction_variance_explained: null\n",
      "predictor:\n",
      "  class_name: LightAttention\n",
      "  model_name: null\n",
      "  model_type: classification_binary\n",
      "  mem_per_job: null\n",
      "  hparams:\n",
      "    kernel_size: 5\n",
      "    dropout: 0.25\n",
      "    conv_dropout: 0.25\n",
      "    learning_rate: 0.0005\n",
      "    batch_size: 5000\n",
      "    max_epochs: 10000\n",
      "    patience: 200\n",
      "    linear_post_concat: true\n",
      "    conv1d_downsizing_factor: 256\n",
      "    plain_LA: false\n",
      "    kernel_two_size: 5\n",
      "    multi_conv: false\n",
      "    optimal_cutoff: 0.5\n",
      "persistence:\n",
      "  type: lovelace\n",
      "  data_root_folder: /novo/projects/departments/cdd/molecular_ai/mlbp/data\n",
      "  artifacts_root_folder: /novo/projects/departments/cdd/molecular_ai/mlbp/artifacts\n",
      "  training_data: static_input_data\n",
      "  pretrained_weights: static_pretrained_weights\n",
      "mlflow:\n",
      "  tracking_uri: DOMINO_TRACKING_URI\n",
      "  experiment_name: ML-BP-Domino\n",
      "plots:\n",
      "  generate_plots: false\n",
      "\n",
      "2025-02-15 15:53:23.499745: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2025-02-15 15:53:23.499791: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2025-02-15 15:53:23.501318: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2025-02-15 15:53:23.508802: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2025-02-15 15:53:27.088060: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "[2025-02-15 15:53:31,805][src.model.composite_model][INFO] - Amorprot: <class 'src.model.embedders.Amorprot'>\n",
      "[2025-02-15 15:53:31,805][src.model.composite_model][INFO] - Ankh: <class 'src.model.embedders.Ankh'>\n",
      "[2025-02-15 15:53:31,805][src.model.composite_model][INFO] - Biophys: <class 'src.model.embedders.Biophys'>\n",
      "[2025-02-15 15:53:31,805][src.model.composite_model][INFO] - ESM: <class 'src.model.embedders.ESM'>\n",
      "[2025-02-15 15:53:31,805][src.model.composite_model][INFO] - Kmer: <class 'src.model.embedders.Kmer'>\n",
      "[2025-02-15 15:53:31,805][src.model.composite_model][INFO] - PrecomputedDescriptors: <class 'src.model.embedders.PrecomputedDescriptors'>\n",
      "[2025-02-15 15:53:31,805][src.model.composite_model][INFO] - ProtT5: <class 'src.model.embedders.ProtT5'>\n",
      "[2025-02-15 15:53:31,807][src.model.composite_model][INFO] - NoReduction: <class 'src.model.dimred.NoReduction'>\n",
      "[2025-02-15 15:53:31,807][src.model.composite_model][INFO] - PCADimReduction: <class 'src.model.dimred.PCADimReduction'>\n",
      "[2025-02-15 15:53:31,878][src.model.composite_model][INFO] - KNearestNeighbors: <class 'src.model.predictors.KNearestNeighbors'>\n",
      "[2025-02-15 15:53:31,878][src.model.composite_model][INFO] - LightAttention: <class 'src.model.predictors.LightAttention'>\n",
      "[2025-02-15 15:53:31,878][src.model.composite_model][INFO] - LogisticRegression: <class 'src.model.predictors.LogisticRegression'>\n",
      "[2025-02-15 15:53:31,879][src.model.composite_model][INFO] - MLP: <class 'src.model.predictors.MLP'>\n",
      "[2025-02-15 15:53:31,879][src.model.composite_model][INFO] - RandomForest: <class 'src.model.predictors.RandomForest'>\n",
      "[2025-02-15 15:53:31,879][src.model.composite_model][INFO] - RidgeRegression: <class 'src.model.predictors.RidgeRegression'>\n",
      "[2025-02-15 15:53:31,879][src.model.composite_model][INFO] - XGBoost: <class 'src.model.predictors.XGBoost'>\n",
      "[2025-02-15 15:53:31,879][src.model.dimred][INFO] - Load class (NoReduction): NoReduction\n",
      "[2025-02-15 15:53:31,879][src.model.abstract_components][INFO] - Load class (DimRed Model): NoReduction\n",
      "[2025-02-15 15:53:31,879][src.model.predictors][INFO] - Load class (LightAttention): LightAttention\n",
      "[2025-02-15 15:53:31,880][src.model.abstract_components][INFO] - Load class (TorchPredictorModel): LightAttention\n",
      "[2025-02-15 15:53:31,880][src.model.abstract_components][INFO] - Load class (Predictor Model): LightAttention\n",
      "[2025-02-15 15:53:31,880][src.model.composite_model][INFO] - Composite model name: esm2t68MUR50D_LightAttention_sbxwfibrillationpeptidewaltzdb-train-valserrano-test\n",
      "[2025-02-15 15:53:31,880][src.model.composite_model][INFO] - Initialized model: esm2t68MUR50D_LightAttention_sbxwfibrillationpeptidewaltzdb-train-valserrano-test in run_mode = train\n",
      "[2025-02-15 15:53:31,880][src.helpers.dataset][INFO] - Loading csv file: /novo/projects/departments/cdd/molecular_ai/mlbp/data/static_input_data/sbxw_fibrillation_peptide_waltzdb-train-val_serrano-test.csv\n",
      "[2025-02-15 15:53:31,886][src.helpers.dataset][INFO] - No additional data columns found while parsing.\n",
      "[2025-02-15 15:53:31,888][src.helpers.dataset][INFO] - Select data according to predetermined splits in the dataframe, train (N = 1122), validation (N = 277), test (N = 248)\n",
      "[2025-02-15 15:53:31,888][src.helpers.dataset][INFO] - Loaded columns: {}\n",
      "[2025-02-15 15:53:31,889][src.helpers.mlflow_helpers][INFO] - Setting up MLflow...\n",
      "[2025-02-15 15:53:31,889][src.helpers.mlflow_helpers][INFO] - Experiment name: ML-BP-Domino\n",
      "[2025-02-15 15:53:31,919][src.helpers.mlflow_helpers][INFO] - Setting MLflow experiment to ML-BP-Domino\n",
      "[2025-02-15 15:53:32,816][__main__][INFO] - Compute embeddings on-the-fly and train model\n",
      "[2025-02-15 15:53:32,817][src.model.abstract_components][INFO] - Load class (LLMEmbedderModel): ESM\n",
      "[2025-02-15 15:53:32,817][src.model.abstract_components][INFO] - Load class (Embedder Model): ESM\n",
      "[2025-02-15 15:53:32,817][src.model.embedders][INFO] - Using existing cache directory: /novo/projects/departments/cdd/molecular_ai/mlbp/data/static_pretrained_weights\n",
      "Using cache found in /novo/projects/departments/cdd/molecular_ai/mlbp/data/static_pretrained_weights/facebookresearch_esm_main\n",
      "[2025-02-15 15:53:32,967][src.model.embedders][INFO] - moving model to cuda\n",
      "[2025-02-15 15:53:33,453][src.model.abstract_components][INFO] - Total memory: 23.58378496GB\n",
      "Memory already allocated: 0.030069248GB\n",
      "[2025-02-15 15:53:34,013][src.model.embedders][INFO] - Final results len: 1122\n",
      "[2025-02-15 15:53:34,013][src.model.composite_model][INFO] - Residue embeddings\n",
      "[2025-02-15 15:53:34,013][src.model.abstract_components][INFO] - Total memory: 23.58378496GB\n",
      "Memory already allocated: 0.038758912GB\n",
      "[2025-02-15 15:53:34,051][src.model.embedders][INFO] - Final results len: 277\n",
      "/nfs_home/users/sbxw/mambaforge/envs/mlbp/lib/python3.10/site-packages/lightning/fabric/plugins/environments/slurm.py:204: The `srun` command is available on your system but is not used. HINT: If your intention is to run Lightning on SLURM, prepend your python command with `srun` like so: srun python /novo/projects/departments/cdd/molecular_ai/sbxw/rep ...\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "You are using a CUDA device ('NVIDIA L4') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name                    | Type       | Params | Mode \n",
      "---------------------------------------------------------------\n",
      "0 | feature_convolution     | Conv1d     | 409 K  | train\n",
      "1 | attention_convolution   | Conv1d     | 409 K  | train\n",
      "2 | feature_convolution_2   | Conv1d     | 409 K  | train\n",
      "3 | attention_convolution_2 | Conv1d     | 409 K  | train\n",
      "4 | softmax                 | Softmax    | 0      | train\n",
      "5 | dropout                 | Dropout    | 0      | train\n",
      "6 | dropout_2               | Dropout    | 0      | train\n",
      "7 | sigmoid                 | Sigmoid    | 0      | train\n",
      "8 | mlp                     | Sequential | 149 K  | train\n",
      "9 | loss_fxn                | BCELoss    | 0      | train\n",
      "---------------------------------------------------------------\n",
      "1.8 M     Trainable params\n",
      "0         Non-trainable params\n",
      "1.8 M     Total params\n",
      "7.158     Total estimated model params size (MB)\n",
      "20        Modules in train mode\n",
      "0         Modules in eval mode\n",
      "/nfs_home/users/sbxw/mambaforge/envs/mlbp/lib/python3.10/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:424: The 'val_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=7` in the `DataLoader` to improve performance.\n",
      "/nfs_home/users/sbxw/mambaforge/envs/mlbp/lib/python3.10/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:424: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=7` in the `DataLoader` to improve performance.\n",
      "/nfs_home/users/sbxw/mambaforge/envs/mlbp/lib/python3.10/site-packages/lightning/pytorch/loops/fit_loop.py:298: The number of training batches (1) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.\n",
      "[2025-02-15 16:01:55,842][src.model.abstract_components][INFO] - MODEL STOPPED BY EARLY STOPPER AT EPOCH 7565\n",
      "[2025-02-15 16:01:55,842][src.model.abstract_components][INFO] - BEST MODEL VALIDATION LOSS IS 0.36467278003692627\n",
      "[2025-02-15 16:01:55,842][src.model.abstract_components][INFO] - BEST MODEL SAVED AT ./mlruns/672490144989501938/fec109d3885b49999ceb0c6ee37bde7e/checkpoints/epoch=7365-step=7366.ckpt\n",
      "[2025-02-15 16:01:57,142][src.model.predictors][INFO] - Moving embeddings to device: cuda\n",
      "Error executing job with overrides: ['mlflow=lovelace', 'persistence=lovelace', 'dataset.use_predefined_split=true', 'dataset.data_name=sbxw_fibrillation_peptide_waltzdb-train-val_serrano-test', 'dataset.task=classification_binary', 'embedder=esm2_t6_8M', 'embedder.mean_pool=false', 'dimred=noreduction', 'predictor=lightattention', 'predictor.hparams.kernel_size=5', 'predictor.hparams.max_epochs=10000', 'predictor.hparams.patience=200', 'predictor.hparams.batch_size=5000', 'predictor.hparams.learning_rate=0.0005', 'predictor.hparams.linear_post_concat=true', 'predictor.hparams.conv1d_downsizing_factor=256', 'mlflow.experiment_name=ML-BP-Domino', 'plots.generate_plots=false']\n",
      "Traceback (most recent call last):\n",
      "  File \"/novo/projects/departments/cdd/molecular_ai/sbxw/repos/ML-BP-Domino/src/cli/training.py\", line 70, in my_app\n",
      "    model_output_train, model_output_val = composite_model.train_predictor_model()\n",
      "  File \"/novo/projects/departments/cdd/molecular_ai/sbxw/repos/ML-BP-Domino/src/model/composite_model.py\", line 365, in train_predictor_model\n",
      "    self.predictor.train_model(sequences_embedded_train,labels['train'],sequences_embedded_val,labels['val'])\n",
      "  File \"/novo/projects/departments/cdd/molecular_ai/sbxw/repos/ML-BP-Domino/src/model/abstract_components.py\", line 570, in train_model\n",
      "  File \"/novo/projects/departments/cdd/molecular_ai/sbxw/repos/ML-BP-Domino/src/model/predictors.py\", line 1014, in post_train_model\n",
      "    predicted_probabilities = predicted_probabilities.compressed()\n",
      "AttributeError: 'numpy.ndarray' object has no attribute 'compressed'. Did you mean: 'compress'?\n",
      "\n",
      "Set the environment variable HYDRA_FULL_ERROR=1 for a complete stack trace.\n",
      "ERROR conda.cli.main_run:execute(47): `conda run python /novo/projects/departments/cdd/molecular_ai/sbxw/repos/ML-BP-Domino/src/cli/training.py mlflow=lovelace persistence=lovelace dataset.use_predefined_split=true dataset.data_name=sbxw_fibrillation_peptide_waltzdb-train-val_serrano-test dataset.task=classification_binary embedder=esm2_t6_8M embedder.mean_pool=false dimred=noreduction predictor=lightattention predictor.hparams.kernel_size=5 predictor.hparams.max_epochs=10000 predictor.hparams.patience=200 predictor.hparams.batch_size=5000 predictor.hparams.learning_rate=0.0005 predictor.hparams.linear_post_concat=true predictor.hparams.conv1d_downsizing_factor=256 mlflow.experiment_name=ML-BP-Domino plots.generate_plots=false` failed. (See above for error)\n"
     ]
    }
   ],
   "source": [
    "repo_dir = '/novo/projects/departments/cdd/molecular_ai/sbxw/repos/ML-BP-Domino'\n",
    "conda_env_name = 'mlbp'\n",
    "\n",
    "# Create command (single set of params)\n",
    "cmd = [\n",
    "    f\"/nfs_home/users/sbxw/mambaforge/condabin/conda run --no-capture-output -n {conda_env_name} python\",\n",
    "    f\"{repo_dir}/src/cli/training.py\",\n",
    "    \"mlflow=lovelace\", \"persistence=lovelace\",\n",
    "    \"dataset.use_predefined_split=true\",\n",
    "    \"dataset.data_name=sbxw_fibrillation_peptide_waltzdb-train-val_serrano-test\", \"dataset.task=classification_binary\", \n",
    "    \"embedder=esm2_t6_8M\",\"embedder.mean_pool=false\",\n",
    "    \"dimred=noreduction\",\n",
    "    \"predictor=lightattention\", \n",
    "    \"predictor.hparams.kernel_size=5\", \"predictor.hparams.max_epochs=10000\", \"predictor.hparams.patience=200\",\n",
    "    \"predictor.hparams.batch_size=5000\", \"predictor.hparams.learning_rate=0.0005\", \"predictor.hparams.linear_post_concat=true\",\n",
    "    \"predictor.hparams.conv1d_downsizing_factor=256\",\n",
    "    \"mlflow.experiment_name=ML-BP-Domino\",\n",
    "    \"plots.generate_plots=false\",\n",
    "]\n",
    "\n",
    "command_str = \" \".join(cmd)\n",
    "print(command_str)\n",
    "!PYTHONPATH=repo_dir; $command_str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "caec9598-969b-47fd-bdd1-81fc71305db7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mlbp",
   "language": "python",
   "name": "mlbp"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
