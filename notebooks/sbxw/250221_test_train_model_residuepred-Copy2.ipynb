{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6700587c-0f29-44a9-a230-fcaa6b9ba861",
   "metadata": {},
   "source": [
    "# Run test with pytorch reduction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "80f2b571-ff0d-4a25-9ea5-974fa352d8d8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: AWS_ACCESS_KEY_ID=ASIATIJCHR3KPDQBE3ZK\n",
      "env: AWS_SECRET_ACCESS_KEY=g5uRXxNkC+F4wcsxo8pGzFLKq7d03Dy/81a6Dypa\n",
      "env: AWS_SESSION_TOKEN=FwoGZXIvYXdzECkaDFQAQqAzDjzkjIikWiL0A1lDrO09XvK1CDnfVAbQlHyFOQi0YEW8t20xe9bDVTv63riG0RyaENE819V+Ep5zF703rUFu8q6jzow4AvHSXM5upyiXZgs3+MiO4sFbzs/TmFLq0t2qGXZerGVbHqFzGtHtZAaoU0zy3jxmCKu6YCb1tzBVPVhSAamN3L3wo997OvZqDwb0M+soWFDAI/9ZoPb02dZK/gsrEfc8BRmPnurze6HkW4OVHFFZXnWjMBmdl4gRw1c1AuYmjT21ajeTRTmdGSFfQ0GdP9PlV8HC7zr8E28aADZAHdLsLp7slN6FDqnGFF5y4TqPrrAmij8ZFYOqoUBPEf+qxtff9mnfxVFOSmF/E4B7Xczf0Uhd300X57Vi/aB6XmPr5vkgGbjNhpaUf40PG7rhJ4sDSV5gJhqlPGT1u3B4hyI60t2Wzzv+iTovF8btjRm/GND5NPRo4LUfS2J2mfyqZ8HbX+gbgHw6FsW28POBv1loT/2VRhzLoBZ71L5CB4sS6vhfbXwySffV3Ev/Eply1T2MYEkQGMpA6vCnT6SnWWGxFd+oR94dKlpmMZThWYfCVNJtI3qu8a9iwfT/w7AQanSCHIY1I6+RYCUa+BDcOedygc3AS8DS3QW4jtK2jshqIkJEMu2nF2twhCbz0lAlBirBPMA6XihUcQMvKIGt+b0GMpQBT6lr0cifUVvnV6L9/CGMkJIbwks6PztNkVnsDjU0nzcvTzOYrTFLSR4nVI/4mHw8rSzhs1OQfqJVGIgqZ642ZxfuUsu7VLG2HokUzAAlje+bdnLtc6SoJJDloPLfnkjajTCzM1al2qlwAgy5OhLf+WAzqderIfbVqnHCDebFGnR1sLJEICRVCJyi/2n8pbTJaXmD1Q==\n",
      "/nfs_home/users/sbxw/mambaforge/condabin/conda run --no-capture-output -n mlbp python /novo/projects/departments/cdd/molecular_ai/sbxw/repos/ML-BP-Domino/src/cli/training.py mlflow=datalab persistence=lovelace persistence.training_data=fibrillation_data dataset.use_predefined_split=true dataset.data_name=sbxw_fibrillation_peptide_waltzdb-train-val_serrano-test dataset.task=classification_binary embedder=esm2_t6_8M embedder.mean_pool=false dimred=noreduction predictor=lightattention predictor.hparams.kernel_size=1 predictor.hparams.max_epochs=10 predictor.hparams.patience=200 predictor.hparams.batch_size=1000 predictor.hparams.learning_rate=0.0005 predictor.hparams.reduction_mode=mean mlflow.experiment_name=ML-BP-Domino plots.generate_plots=false\n",
      "2025-02-26 00:08:26.882992: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2025-02-26 00:08:26.883037: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2025-02-26 00:08:26.884562: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2025-02-26 00:08:26.892063: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2025-02-26 00:08:29.901227: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "[2025-02-26 00:08:39,554][__main__][INFO] - Workflow configuration:\n",
      "\n",
      "general:\n",
      "  run_mode: train\n",
      "  abs_repo_path: null\n",
      "  composite_model_name: null\n",
      "  composite_model_path: null\n",
      "  precomputed_embeddings_path: null\n",
      "  random_state: 42\n",
      "dataset:\n",
      "  data_name: sbxw_fibrillation_peptide_waltzdb-train-val_serrano-test\n",
      "  add_data_columns: false\n",
      "  data_columns_dimred: false\n",
      "  data_columns_standard: false\n",
      "  group_column: null\n",
      "  data_scaler: RobustScaler\n",
      "  target_scaling: null\n",
      "  rbf_encoder: RadialBasisFunctionGaussian\n",
      "  rbf_n_kernels: 10\n",
      "  task: classification_binary\n",
      "  use_predefined_split: true\n",
      "  use_sample_weights: false\n",
      "  residue_prediction_labels: null\n",
      "  data_split_column: data_split\n",
      "  data_split:\n",
      "    train: 0.8\n",
      "    val: 0.0\n",
      "    test: 0.2\n",
      "embedder:\n",
      "  class_name: ESM\n",
      "  model_name: esm2_t6_8M_UR50D\n",
      "  model_path: null\n",
      "  standardize: false\n",
      "  scalar_type: StandardScaler\n",
      "  hparams: null\n",
      "  n_copies: 1\n",
      "  chain_break: poly-gly-linker\n",
      "  buffer_scale_factor: 2.0\n",
      "  max_batch_size: 400\n",
      "  simple_batching: false\n",
      "  strict: true\n",
      "  verbose: false\n",
      "  mean_pool: false\n",
      "  output_hidden_states: false\n",
      "dimred:\n",
      "  class_name: NoReduction\n",
      "  transform_name: null\n",
      "  fraction_variance_explained: null\n",
      "predictor:\n",
      "  class_name: LightAttention\n",
      "  model_name: null\n",
      "  model_type: classification_binary\n",
      "  mem_per_job: null\n",
      "  residue_prediction_mode: false\n",
      "  hparams:\n",
      "    kernel_size: 1\n",
      "    dropout: 0.25\n",
      "    conv_dropout: 0.25\n",
      "    learning_rate: 0.0005\n",
      "    batch_size: 1000\n",
      "    max_epochs: 10\n",
      "    patience: 200\n",
      "    post_attention: mlp\n",
      "    conv1d_output_dim: -1\n",
      "    optimal_cutoff: 0.5\n",
      "    reduction_mode: mean\n",
      "persistence:\n",
      "  type: lovelace\n",
      "  data_root_folder: /novo/projects/departments/cdd/molecular_ai/mlbp/data\n",
      "  artifacts_root_folder: /novo/projects/departments/cdd/molecular_ai/mlbp/artifacts\n",
      "  training_data: fibrillation_data\n",
      "  pretrained_weights: static_pretrained_weights\n",
      "mlflow:\n",
      "  tracking_uri: https://datalab.corp.novocorp.net/mlflow/\n",
      "  experiment_name: ML-BP-Domino\n",
      "plots:\n",
      "  generate_plots: false\n",
      "\n",
      "[2025-02-26 00:08:39,555][src.model.dimred][INFO] - Load class (NoReduction): NoReduction\n",
      "[2025-02-26 00:08:39,555][src.model.abstract_components][INFO] - Load class (DimRed Model): NoReduction\n",
      "[2025-02-26 00:08:39,556][src.model.predictors][INFO] - Load class (LightAttention): LightAttention\n",
      "[2025-02-26 00:08:39,556][src.model.abstract_components][INFO] - Load class (TorchPredictorModel): LightAttention\n",
      "[2025-02-26 00:08:39,556][src.model.abstract_components][INFO] - Load class (Predictor Model): LightAttention\n",
      "[2025-02-26 00:08:39,556][src.model.composite_model][INFO] - Composite model name: esm2t68MUR50D_LightAttention_sbxwfibrillationpeptidewaltzdb-train-valserrano-test\n",
      "[2025-02-26 00:08:39,556][src.model.composite_model][INFO] - Initialized model: esm2t68MUR50D_LightAttention_sbxwfibrillationpeptidewaltzdb-train-valserrano-test in run_mode = train\n",
      "[2025-02-26 00:08:39,560][src.helpers.dataset][INFO] - Loading file: /novo/projects/departments/cdd/molecular_ai/mlbp/data/fibrillation_data/sbxw_fibrillation_peptide_waltzdb-train-val_serrano-test.csv\n",
      "[2025-02-26 00:08:39,561][src.helpers.dataset][INFO] - Using group_column \"None\".\n",
      "[2025-02-26 00:08:39,562][src.helpers.dataset][INFO] - No additional data columns found while parsing.\n",
      "[2025-02-26 00:08:39,563][src.helpers.dataset][INFO] - Select data according to predetermined splits in the dataframe, train (N = 1122), validation (N = 277), test (N = 248)\n",
      "[2025-02-26 00:08:39,564][src.helpers.dataset][INFO] - Loaded columns: {}\n",
      "[2025-02-26 00:08:39,564][src.helpers.mlflow_helpers][INFO] - Setting up MLflow...\n",
      "[2025-02-26 00:08:39,565][src.helpers.mlflow_helpers][INFO] - Experiment name: ML-BP-Domino\n",
      "[2025-02-26 00:08:39,565][src.helpers.mlflow_helpers][INFO] - Setting MLflow tracking URI to https://datalab.corp.novocorp.net/mlflow/\n",
      "[2025-02-26 00:08:40,507][src.helpers.mlflow_helpers][INFO] - Setting MLflow experiment to ML-BP-Domino\n",
      "[2025-02-26 00:08:40,955][__main__][INFO] - <RunInfo: artifact_uri='s3://nnedl-core-prd-eu-central-1-curated/mlops/378/2dcf9519cb4f492980c632e70f12ce4c/artifacts', end_time=None, experiment_id='378', lifecycle_stage='active', run_id='2dcf9519cb4f492980c632e70f12ce4c', run_name='', run_uuid='2dcf9519cb4f492980c632e70f12ce4c', start_time=1740528520711, status='RUNNING', user_id='sbxw'>\n",
      "[2025-02-26 00:08:41,634][__main__][INFO] - Compute embeddings on-the-fly and train model\n",
      "[2025-02-26 00:08:41,635][src.model.abstract_components][INFO] - Load class (LLMEmbedderModel): ESM\n",
      "[2025-02-26 00:08:41,635][src.model.abstract_components][INFO] - Load class (Embedder Model): ESM\n",
      "[2025-02-26 00:08:41,636][src.model.embedders][INFO] - Loading model: esm2_t6_8M_UR50D, will extract embeddings from 6-th layer\n",
      "Some weights of EsmModel were not initialized from the model checkpoint at facebook/esm2_t6_8M_UR50D and are newly initialized: ['esm.pooler.dense.bias', 'esm.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "[2025-02-26 00:08:42,351][src.model.embedders][INFO] - Moving model to cuda\n",
      "[2025-02-26 00:08:42,515][src.model.abstract_components][INFO] - Total memory: 23.58378496GB\n",
      "Memory already allocated: 0.031387648GB\n",
      "[2025-02-26 00:08:42,997][src.model.embedders][INFO] - Per-residue embeddings count: 1122\n",
      "[2025-02-26 00:08:42,997][src.model.composite_model][INFO] - Residue embeddings\n",
      "[2025-02-26 00:08:42,998][src.model.abstract_components][INFO] - Total memory: 23.58378496GB\n",
      "Memory already allocated: 0.043664896GB\n",
      "[2025-02-26 00:08:43,021][src.model.embedders][INFO] - Per-residue embeddings count: 277\n",
      "[2025-02-26 00:08:43,021][src.model.scalers][INFO] - Fitted scaler: PassThroughScaler\n",
      "[2025-02-26 00:08:43,021][src.model.scalers][INFO] - Before standardization - min: 0.0, max: 1.0\n",
      "[2025-02-26 00:08:43,021][src.model.scalers][INFO] - After standardization - min: 0.0, max: 1.0\n",
      "[2025-02-26 00:08:43,021][src.model.scalers][INFO] - Before standardization - min: 0.0, max: 1.0\n",
      "[2025-02-26 00:08:43,021][src.model.scalers][INFO] - After standardization - min: 0.0, max: 1.0\n",
      "[2025-02-26 00:08:43,021][src.model.scalers][INFO] - Before standardization - min: 0.0, max: 1.0\n",
      "[2025-02-26 00:08:43,021][src.model.scalers][INFO] - After standardization - min: 0.0, max: 1.0\n",
      "/nfs_home/users/sbxw/mambaforge/envs/mlbp/lib/python3.10/site-packages/lightning/fabric/plugins/environments/slurm.py:204: The `srun` command is available on your system but is not used. HINT: If your intention is to run Lightning on SLURM, prepend your python command with `srun` like so: srun python /novo/projects/departments/cdd/molecular_ai/sbxw/rep ...\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/nfs_home/users/sbxw/mambaforge/envs/mlbp/lib/python3.10/site-packages/lightning/fabric/plugins/environments/slurm.py:204: The `srun` command is available on your system but is not used. HINT: If your intention is to run Lightning on SLURM, prepend your python command with `srun` like so: srun python /novo/projects/departments/cdd/molecular_ai/sbxw/rep ...\n",
      "[2025-02-26 00:08:44,331][pytorch_lightning.utilities.rank_zero][INFO] - You are using a CUDA device ('NVIDIA L4') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name                  | Type       | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | feature_convolution   | Conv1d     | 102 K  | train\n",
      "1 | attention_convolution | Conv1d     | 102 K  | train\n",
      "2 | softmax               | Softmax    | 0      | train\n",
      "3 | dropout               | Dropout    | 0      | train\n",
      "4 | sigmoid               | Sigmoid    | 0      | train\n",
      "5 | mlp                   | Sequential | 10.4 K | train\n",
      "6 | loss_fxn              | BCELoss    | 0      | train\n",
      "-------------------------------------------------------------\n",
      "215 K     Trainable params\n",
      "0         Non-trainable params\n",
      "215 K     Total params\n",
      "0.863     Total estimated model params size (MB)\n",
      "12        Modules in train mode\n",
      "0         Modules in eval mode\n",
      "/nfs_home/users/sbxw/mambaforge/envs/mlbp/lib/python3.10/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:424: The 'val_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=7` in the `DataLoader` to improve performance.\n",
      "/nfs_home/users/sbxw/mambaforge/envs/mlbp/lib/python3.10/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:424: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=7` in the `DataLoader` to improve performance.\n",
      "[2025-02-26 00:08:48,466][botocore.credentials][INFO] - Found credentials in environment variables.\n",
      "[2025-02-26 00:09:06,036][pytorch_lightning.utilities.rank_zero][INFO] - `Trainer.fit` stopped: `max_epochs=10` reached.\n",
      "üèÉ View run  at: https://datalab.corp.novocorp.net/mlflow/#/experiments/378/runs/2dcf9519cb4f492980c632e70f12ce4c\n",
      "üß™ View experiment at: https://datalab.corp.novocorp.net/mlflow/#/experiments/378\n",
      "\u001b[31m2025/02/26 00:09:28 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\u001b[0m\n",
      "[2025-02-26 00:09:34,963][src.model.abstract_components][INFO] - MODEL STOPPED BY EARLY STOPPER AT EPOCH 0\n",
      "[2025-02-26 00:09:34,964][src.model.abstract_components][INFO] - BEST MODEL VALIDATION LOSS IS 0.7150794863700867\n",
      "[2025-02-26 00:09:34,964][src.model.abstract_components][INFO] - BEST MODEL SAVED AT /novo/projects/departments/cdd/public/users/ehec/sbxw_files_2/378/2dcf9519cb4f492980c632e70f12ce4c/checkpoints/epoch=0-step=2.ckpt\n",
      "[2025-02-26 00:09:34,964][src.model.abstract_components][INFO] - FINAL MODEL SAVED AT None\n",
      "[2025-02-26 00:09:35,234][src.model.predictors][INFO] - Moving embeddings to device: cuda\n",
      "[2025-02-26 00:09:35,336][src.model.predictors][INFO] - Optimal cutoff is: 0.0 with MCC: 0.0\n",
      "[2025-02-26 00:09:35,347][src.model.predictors][INFO] - Moving embeddings to device: cuda\n",
      "[2025-02-26 00:09:35,353][src.model.predictors][INFO] - Moving embeddings to device: cuda\n",
      "[2025-02-26 00:09:35,355][src.model.composite_model][INFO] - This is the updated predictor name: lightattention_kernel_size_1_dropout_0.25_conv_dropout_0.25_learning_rate_0.0005_batch_size_1000_max_epochs_10_patience_200_post_attention_mlp_conv1d_output_dim_-1_optimal_cutoff_0.0_reduction_mode_mean\n",
      "[2025-02-26 00:09:35,355][src.model.composite_model][INFO] - Composite model name: esm2t68MUR50D_LightAttention_sbxwfibrillationpeptidewaltzdb-train-valserrano-test\n",
      "[2025-02-26 00:09:35,355][src.model.composite_model][INFO] - Best model is: kernel_size_1_dropout_0.25_conv_dropout_0.25_learning_rate_0.0005_batch_size_1000_max_epochs_10_patience_200_post_attention_mlp_conv1d_output_dim_-1_optimal_cutoff_0.0_reduction_mode_mean\n",
      "[2025-02-26 00:09:35,355][src.model.composite_model][INFO] - Moving to test mode\n",
      "[2025-02-26 00:09:35,356][src.model.composite_model][INFO] - Composite model name: esm2t68MUR50D_LightAttention_sbxwfibrillationpeptidewaltzdb-train-valserrano-test\n",
      "[2025-02-26 00:09:35,356][src.model.composite_model][INFO] - Saving model: esm2t68MUR50D_LightAttention_sbxwfibrillationpeptidewaltzdb-train-valserrano-test\n",
      "<RunInfo: artifact_uri='s3://nnedl-core-prd-eu-central-1-curated/mlops/378/2dcf9519cb4f492980c632e70f12ce4c/artifacts', end_time=None, experiment_id='378', lifecycle_stage='active', run_id='2dcf9519cb4f492980c632e70f12ce4c', run_name='', run_uuid='2dcf9519cb4f492980c632e70f12ce4c', start_time=1740528520711, status='RUNNING', user_id='sbxw'>\n",
      "[2025-02-26 00:09:41,827][src.model.abstract_components][INFO] - Total memory: 23.58378496GB\n",
      "Memory already allocated: 0.05357568GB\n",
      "[2025-02-26 00:09:41,898][src.model.embedders][INFO] - Per-residue embeddings count: 248\n",
      "[2025-02-26 00:09:41,898][src.model.composite_model][INFO] - Residue embeddings\n",
      "[2025-02-26 00:09:41,902][src.model.predictors][INFO] - Moving embeddings to device: cuda\n",
      "sequences: (1122,)\n",
      "sequence_embeddings: 1122\n",
      "data_split: train\n",
      "labels: (1122,)\n",
      "predictions_probability: (1122,)\n",
      "residue_level_prediction: False\n",
      "sequences: (277,)\n",
      "sequence_embeddings: 277\n",
      "data_split: val\n",
      "labels: (277,)\n",
      "predictions_probability: (277,)\n",
      "residue_level_prediction: False\n",
      "sequences: (248,)\n",
      "sequence_embeddings: 248\n",
      "data_split: test\n",
      "labels: (248,)\n",
      "predictions_probability: (248,)\n",
      "residue_level_prediction: False\n",
      "üèÉ View run  at: https://datalab.corp.novocorp.net/mlflow/#/experiments/378/runs/2dcf9519cb4f492980c632e70f12ce4c\n",
      "üß™ View experiment at: https://datalab.corp.novocorp.net/mlflow/#/experiments/378\n",
      "Error executing job with overrides: ['mlflow=datalab', 'persistence=lovelace', 'persistence.training_data=fibrillation_data', 'dataset.use_predefined_split=true', 'dataset.data_name=sbxw_fibrillation_peptide_waltzdb-train-val_serrano-test', 'dataset.task=classification_binary', 'embedder=esm2_t6_8M', 'embedder.mean_pool=false', 'dimred=noreduction', 'predictor=lightattention', 'predictor.hparams.kernel_size=1', 'predictor.hparams.max_epochs=10', 'predictor.hparams.patience=200', 'predictor.hparams.batch_size=1000', 'predictor.hparams.learning_rate=0.0005', 'predictor.hparams.reduction_mode=mean', 'mlflow.experiment_name=ML-BP-Domino', 'plots.generate_plots=false']\n",
      "Traceback (most recent call last):\n",
      "  File \"/novo/projects/departments/cdd/molecular_ai/sbxw/repos/ML-BP-Domino/src/cli/training.py\", line 82, in my_app\n",
      "    stats_df = calculate_statistics_from_df(\n",
      "  File \"/novo/projects/departments/cdd/molecular_ai/sbxw/repos/ML-BP-Domino/src/helpers/stats_utilities.py\", line 280, in calculate_statistics_from_df\n",
      "    stat_dict = calculate_classification_statistics(\n",
      "  File \"/novo/projects/departments/cdd/molecular_ai/sbxw/repos/ML-BP-Domino/src/helpers/stats_utilities.py\", line 125, in calculate_classification_statistics\n",
      "    if np.isnan(y_pred).any():\n",
      "TypeError: ufunc 'isnan' not supported for the input types, and the inputs could not be safely coerced to any supported types according to the casting rule ''safe''\n",
      "\n",
      "Set the environment variable HYDRA_FULL_ERROR=1 for a complete stack trace.\n",
      "ERROR conda.cli.main_run:execute(47): `conda run python /novo/projects/departments/cdd/molecular_ai/sbxw/repos/ML-BP-Domino/src/cli/training.py mlflow=datalab persistence=lovelace persistence.training_data=fibrillation_data dataset.use_predefined_split=true dataset.data_name=sbxw_fibrillation_peptide_waltzdb-train-val_serrano-test dataset.task=classification_binary embedder=esm2_t6_8M embedder.mean_pool=false dimred=noreduction predictor=lightattention predictor.hparams.kernel_size=1 predictor.hparams.max_epochs=10 predictor.hparams.patience=200 predictor.hparams.batch_size=1000 predictor.hparams.learning_rate=0.0005 predictor.hparams.reduction_mode=mean mlflow.experiment_name=ML-BP-Domino plots.generate_plots=false` failed. (See above for error)\n"
     ]
    }
   ],
   "source": [
    "%env AWS_ACCESS_KEY_ID=ASIATIJCHR3KPDQBE3ZK\n",
    "%env AWS_SECRET_ACCESS_KEY=g5uRXxNkC+F4wcsxo8pGzFLKq7d03Dy/81a6Dypa\n",
    "%env AWS_SESSION_TOKEN=FwoGZXIvYXdzECkaDFQAQqAzDjzkjIikWiL0A1lDrO09XvK1CDnfVAbQlHyFOQi0YEW8t20xe9bDVTv63riG0RyaENE819V+Ep5zF703rUFu8q6jzow4AvHSXM5upyiXZgs3+MiO4sFbzs/TmFLq0t2qGXZerGVbHqFzGtHtZAaoU0zy3jxmCKu6YCb1tzBVPVhSAamN3L3wo997OvZqDwb0M+soWFDAI/9ZoPb02dZK/gsrEfc8BRmPnurze6HkW4OVHFFZXnWjMBmdl4gRw1c1AuYmjT21ajeTRTmdGSFfQ0GdP9PlV8HC7zr8E28aADZAHdLsLp7slN6FDqnGFF5y4TqPrrAmij8ZFYOqoUBPEf+qxtff9mnfxVFOSmF/E4B7Xczf0Uhd300X57Vi/aB6XmPr5vkgGbjNhpaUf40PG7rhJ4sDSV5gJhqlPGT1u3B4hyI60t2Wzzv+iTovF8btjRm/GND5NPRo4LUfS2J2mfyqZ8HbX+gbgHw6FsW28POBv1loT/2VRhzLoBZ71L5CB4sS6vhfbXwySffV3Ev/Eply1T2MYEkQGMpA6vCnT6SnWWGxFd+oR94dKlpmMZThWYfCVNJtI3qu8a9iwfT/w7AQanSCHIY1I6+RYCUa+BDcOedygc3AS8DS3QW4jtK2jshqIkJEMu2nF2twhCbz0lAlBirBPMA6XihUcQMvKIGt+b0GMpQBT6lr0cifUVvnV6L9/CGMkJIbwks6PztNkVnsDjU0nzcvTzOYrTFLSR4nVI/4mHw8rSzhs1OQfqJVGIgqZ642ZxfuUsu7VLG2HokUzAAlje+bdnLtc6SoJJDloPLfnkjajTCzM1al2qlwAgy5OhLf+WAzqderIfbVqnHCDebFGnR1sLJEICRVCJyi/2n8pbTJaXmD1Q==\n",
    "\n",
    "repo_dir = '/novo/projects/departments/cdd/molecular_ai/sbxw/repos/ML-BP-Domino'\n",
    "conda_env_name = 'mlbp'\n",
    "\n",
    "# Create command (single set of params)\n",
    "cmd = [\n",
    "    f\"/nfs_home/users/sbxw/mambaforge/condabin/conda run --no-capture-output -n {conda_env_name} python\",\n",
    "    f\"{repo_dir}/src/cli/training.py\",\n",
    "    \"mlflow=datalab\", \"persistence=lovelace\", \"persistence.training_data=fibrillation_data\",\n",
    "    \"dataset.use_predefined_split=true\",\n",
    "    \"dataset.data_name=sbxw_fibrillation_peptide_waltzdb-train-val_serrano-test\", \"dataset.task=classification_binary\", \n",
    "    \"embedder=esm2_t6_8M\",\"embedder.mean_pool=false\",\n",
    "    \"dimred=noreduction\",\n",
    "    \"predictor=lightattention\",\n",
    "    \"predictor.hparams.kernel_size=1\", \"predictor.hparams.max_epochs=10\", \"predictor.hparams.patience=200\",\n",
    "    \"predictor.hparams.batch_size=1000\", \"predictor.hparams.learning_rate=0.0005\",\n",
    "    \"predictor.hparams.reduction_mode=mean\",\n",
    "    \"mlflow.experiment_name=ML-BP-Domino\",\n",
    "    \"plots.generate_plots=false\",\n",
    "]\n",
    "\n",
    "command_str = \" \".join(cmd)\n",
    "print(command_str)\n",
    "!$command_str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "72bb8acd-51f8-4d23-afdf-db19a1dfa08d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: AWS_ACCESS_KEY_ID=ASIATIJCHR3KPDQBE3ZK\n",
      "env: AWS_SECRET_ACCESS_KEY=g5uRXxNkC+F4wcsxo8pGzFLKq7d03Dy/81a6Dypa\n",
      "env: AWS_SESSION_TOKEN=FwoGZXIvYXdzECkaDFQAQqAzDjzkjIikWiL0A1lDrO09XvK1CDnfVAbQlHyFOQi0YEW8t20xe9bDVTv63riG0RyaENE819V+Ep5zF703rUFu8q6jzow4AvHSXM5upyiXZgs3+MiO4sFbzs/TmFLq0t2qGXZerGVbHqFzGtHtZAaoU0zy3jxmCKu6YCb1tzBVPVhSAamN3L3wo997OvZqDwb0M+soWFDAI/9ZoPb02dZK/gsrEfc8BRmPnurze6HkW4OVHFFZXnWjMBmdl4gRw1c1AuYmjT21ajeTRTmdGSFfQ0GdP9PlV8HC7zr8E28aADZAHdLsLp7slN6FDqnGFF5y4TqPrrAmij8ZFYOqoUBPEf+qxtff9mnfxVFOSmF/E4B7Xczf0Uhd300X57Vi/aB6XmPr5vkgGbjNhpaUf40PG7rhJ4sDSV5gJhqlPGT1u3B4hyI60t2Wzzv+iTovF8btjRm/GND5NPRo4LUfS2J2mfyqZ8HbX+gbgHw6FsW28POBv1loT/2VRhzLoBZ71L5CB4sS6vhfbXwySffV3Ev/Eply1T2MYEkQGMpA6vCnT6SnWWGxFd+oR94dKlpmMZThWYfCVNJtI3qu8a9iwfT/w7AQanSCHIY1I6+RYCUa+BDcOedygc3AS8DS3QW4jtK2jshqIkJEMu2nF2twhCbz0lAlBirBPMA6XihUcQMvKIGt+b0GMpQBT6lr0cifUVvnV6L9/CGMkJIbwks6PztNkVnsDjU0nzcvTzOYrTFLSR4nVI/4mHw8rSzhs1OQfqJVGIgqZ642ZxfuUsu7VLG2HokUzAAlje+bdnLtc6SoJJDloPLfnkjajTCzM1al2qlwAgy5OhLf+WAzqderIfbVqnHCDebFGnR1sLJEICRVCJyi/2n8pbTJaXmD1Q==\n",
      "/nfs_home/users/sbxw/mambaforge/condabin/conda run --no-capture-output -n mlbp python /novo/projects/departments/cdd/molecular_ai/sbxw/repos/ML-BP-Domino/src/cli/training.py mlflow=datalab persistence=lovelace persistence.training_data=fibrillation_data dataset.use_predefined_split=true dataset.data_name=sbxw_fibrillation_peptide_waltzdb-train-val_serrano-test dataset.task=classification_binary embedder=esm2_t6_8M embedder.mean_pool=false dimred=noreduction predictor=lightattention predictor.hparams.kernel_size=1 predictor.hparams.max_epochs=10 predictor.hparams.patience=200 predictor.hparams.batch_size=1000 predictor.hparams.learning_rate=0.0005 predictor.hparams.reduction_mode=max mlflow.experiment_name=ML-BP-Domino plots.generate_plots=false\n",
      "2025-02-25 23:52:41.859175: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2025-02-25 23:52:41.859218: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2025-02-25 23:52:41.860727: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2025-02-25 23:52:41.868377: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2025-02-25 23:52:44.470484: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "[2025-02-25 23:52:52,935][__main__][INFO] - Workflow configuration:\n",
      "\n",
      "general:\n",
      "  run_mode: train\n",
      "  abs_repo_path: null\n",
      "  composite_model_name: null\n",
      "  composite_model_path: null\n",
      "  precomputed_embeddings_path: null\n",
      "  random_state: 42\n",
      "dataset:\n",
      "  data_name: sbxw_fibrillation_peptide_waltzdb-train-val_serrano-test\n",
      "  add_data_columns: false\n",
      "  data_columns_dimred: false\n",
      "  data_columns_standard: false\n",
      "  group_column: null\n",
      "  data_scaler: RobustScaler\n",
      "  target_scaling: null\n",
      "  rbf_encoder: RadialBasisFunctionGaussian\n",
      "  rbf_n_kernels: 10\n",
      "  task: classification_binary\n",
      "  use_predefined_split: true\n",
      "  use_sample_weights: false\n",
      "  residue_prediction_labels: null\n",
      "  data_split_column: data_split\n",
      "  data_split:\n",
      "    train: 0.8\n",
      "    val: 0.0\n",
      "    test: 0.2\n",
      "embedder:\n",
      "  class_name: ESM\n",
      "  model_name: esm2_t6_8M_UR50D\n",
      "  model_path: null\n",
      "  standardize: false\n",
      "  scalar_type: StandardScaler\n",
      "  hparams: null\n",
      "  n_copies: 1\n",
      "  chain_break: poly-gly-linker\n",
      "  buffer_scale_factor: 2.0\n",
      "  max_batch_size: 400\n",
      "  simple_batching: false\n",
      "  strict: true\n",
      "  verbose: false\n",
      "  mean_pool: false\n",
      "  output_hidden_states: false\n",
      "dimred:\n",
      "  class_name: NoReduction\n",
      "  transform_name: null\n",
      "  fraction_variance_explained: null\n",
      "predictor:\n",
      "  class_name: LightAttention\n",
      "  model_name: null\n",
      "  model_type: classification_binary\n",
      "  mem_per_job: null\n",
      "  residue_prediction_mode: false\n",
      "  hparams:\n",
      "    kernel_size: 1\n",
      "    dropout: 0.25\n",
      "    conv_dropout: 0.25\n",
      "    learning_rate: 0.0005\n",
      "    batch_size: 1000\n",
      "    max_epochs: 10\n",
      "    patience: 200\n",
      "    post_attention: mlp\n",
      "    conv1d_output_dim: -1\n",
      "    optimal_cutoff: 0.5\n",
      "    reduction_mode: max\n",
      "persistence:\n",
      "  type: lovelace\n",
      "  data_root_folder: /novo/projects/departments/cdd/molecular_ai/mlbp/data\n",
      "  artifacts_root_folder: /novo/projects/departments/cdd/molecular_ai/mlbp/artifacts\n",
      "  training_data: fibrillation_data\n",
      "  pretrained_weights: static_pretrained_weights\n",
      "mlflow:\n",
      "  tracking_uri: https://datalab.corp.novocorp.net/mlflow/\n",
      "  experiment_name: ML-BP-Domino\n",
      "plots:\n",
      "  generate_plots: false\n",
      "\n",
      "[2025-02-25 23:52:52,936][src.model.dimred][INFO] - Load class (NoReduction): NoReduction\n",
      "[2025-02-25 23:52:52,936][src.model.abstract_components][INFO] - Load class (DimRed Model): NoReduction\n",
      "[2025-02-25 23:52:52,936][src.model.predictors][INFO] - Load class (LightAttention): LightAttention\n",
      "[2025-02-25 23:52:52,936][src.model.abstract_components][INFO] - Load class (TorchPredictorModel): LightAttention\n",
      "[2025-02-25 23:52:52,936][src.model.abstract_components][INFO] - Load class (Predictor Model): LightAttention\n",
      "[2025-02-25 23:52:52,936][src.model.composite_model][INFO] - Composite model name: esm2t68MUR50D_LightAttention_sbxwfibrillationpeptidewaltzdb-train-valserrano-test\n",
      "[2025-02-25 23:52:52,937][src.model.composite_model][INFO] - Initialized model: esm2t68MUR50D_LightAttention_sbxwfibrillationpeptidewaltzdb-train-valserrano-test in run_mode = train\n",
      "[2025-02-25 23:52:52,941][src.helpers.dataset][INFO] - Loading file: /novo/projects/departments/cdd/molecular_ai/mlbp/data/fibrillation_data/sbxw_fibrillation_peptide_waltzdb-train-val_serrano-test.csv\n",
      "[2025-02-25 23:52:52,941][src.helpers.dataset][INFO] - Using group_column \"None\".\n",
      "[2025-02-25 23:52:52,941][src.helpers.dataset][INFO] - No additional data columns found while parsing.\n",
      "[2025-02-25 23:52:52,943][src.helpers.dataset][INFO] - Select data according to predetermined splits in the dataframe, train (N = 1122), validation (N = 277), test (N = 248)\n",
      "[2025-02-25 23:52:52,943][src.helpers.dataset][INFO] - Loaded columns: {}\n",
      "[2025-02-25 23:52:52,944][src.helpers.mlflow_helpers][INFO] - Setting up MLflow...\n",
      "[2025-02-25 23:52:52,944][src.helpers.mlflow_helpers][INFO] - Experiment name: ML-BP-Domino\n",
      "[2025-02-25 23:52:52,944][src.helpers.mlflow_helpers][INFO] - Setting MLflow tracking URI to https://datalab.corp.novocorp.net/mlflow/\n",
      "[2025-02-25 23:52:53,870][src.helpers.mlflow_helpers][INFO] - Setting MLflow experiment to ML-BP-Domino\n",
      "[2025-02-25 23:52:54,297][__main__][INFO] - <RunInfo: artifact_uri='s3://nnedl-core-prd-eu-central-1-curated/mlops/378/6299f4d3c9d1493ca1a0c7f495f24da0/artifacts', end_time=None, experiment_id='378', lifecycle_stage='active', run_id='6299f4d3c9d1493ca1a0c7f495f24da0', run_name='', run_uuid='6299f4d3c9d1493ca1a0c7f495f24da0', start_time=1740527574046, status='RUNNING', user_id='sbxw'>\n",
      "[2025-02-25 23:52:54,986][__main__][INFO] - Compute embeddings on-the-fly and train model\n",
      "[2025-02-25 23:52:54,986][src.model.abstract_components][INFO] - Load class (LLMEmbedderModel): ESM\n",
      "[2025-02-25 23:52:54,987][src.model.abstract_components][INFO] - Load class (Embedder Model): ESM\n",
      "[2025-02-25 23:52:54,987][src.model.embedders][INFO] - Loading model: esm2_t6_8M_UR50D, will extract embeddings from 6-th layer\n",
      "Some weights of EsmModel were not initialized from the model checkpoint at facebook/esm2_t6_8M_UR50D and are newly initialized: ['esm.pooler.dense.bias', 'esm.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "[2025-02-25 23:52:55,915][src.model.embedders][INFO] - Moving model to cuda\n",
      "[2025-02-25 23:52:56,075][src.model.abstract_components][INFO] - Total memory: 23.58378496GB\n",
      "Memory already allocated: 0.031387648GB\n",
      "[2025-02-25 23:52:56,580][src.model.embedders][INFO] - Per-residue embeddings count: 1122\n",
      "[2025-02-25 23:52:56,580][src.model.composite_model][INFO] - Residue embeddings\n",
      "[2025-02-25 23:52:56,581][src.model.abstract_components][INFO] - Total memory: 23.58378496GB\n",
      "Memory already allocated: 0.043664896GB\n",
      "[2025-02-25 23:52:56,605][src.model.embedders][INFO] - Per-residue embeddings count: 277\n",
      "[2025-02-25 23:52:56,605][src.model.scalers][INFO] - Fitted scaler: PassThroughScaler\n",
      "[2025-02-25 23:52:56,605][src.model.scalers][INFO] - Before standardization - min: 0.0, max: 1.0\n",
      "[2025-02-25 23:52:56,605][src.model.scalers][INFO] - After standardization - min: 0.0, max: 1.0\n",
      "[2025-02-25 23:52:56,605][src.model.scalers][INFO] - Before standardization - min: 0.0, max: 1.0\n",
      "[2025-02-25 23:52:56,605][src.model.scalers][INFO] - After standardization - min: 0.0, max: 1.0\n",
      "[2025-02-25 23:52:56,605][src.model.scalers][INFO] - Before standardization - min: 0.0, max: 1.0\n",
      "[2025-02-25 23:52:56,605][src.model.scalers][INFO] - After standardization - min: 0.0, max: 1.0\n",
      "/nfs_home/users/sbxw/mambaforge/envs/mlbp/lib/python3.10/site-packages/lightning/fabric/plugins/environments/slurm.py:204: The `srun` command is available on your system but is not used. HINT: If your intention is to run Lightning on SLURM, prepend your python command with `srun` like so: srun python /novo/projects/departments/cdd/molecular_ai/sbxw/rep ...\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/nfs_home/users/sbxw/mambaforge/envs/mlbp/lib/python3.10/site-packages/lightning/fabric/plugins/environments/slurm.py:204: The `srun` command is available on your system but is not used. HINT: If your intention is to run Lightning on SLURM, prepend your python command with `srun` like so: srun python /novo/projects/departments/cdd/molecular_ai/sbxw/rep ...\n",
      "[2025-02-25 23:52:57,815][pytorch_lightning.utilities.rank_zero][INFO] - You are using a CUDA device ('NVIDIA L4') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name                  | Type       | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | feature_convolution   | Conv1d     | 102 K  | train\n",
      "1 | attention_convolution | Conv1d     | 102 K  | train\n",
      "2 | softmax               | Softmax    | 0      | train\n",
      "3 | dropout               | Dropout    | 0      | train\n",
      "4 | sigmoid               | Sigmoid    | 0      | train\n",
      "5 | mlp                   | Sequential | 10.4 K | train\n",
      "6 | loss_fxn              | BCELoss    | 0      | train\n",
      "-------------------------------------------------------------\n",
      "215 K     Trainable params\n",
      "0         Non-trainable params\n",
      "215 K     Total params\n",
      "0.863     Total estimated model params size (MB)\n",
      "12        Modules in train mode\n",
      "0         Modules in eval mode\n",
      "/nfs_home/users/sbxw/mambaforge/envs/mlbp/lib/python3.10/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:424: The 'val_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=7` in the `DataLoader` to improve performance.\n",
      "/nfs_home/users/sbxw/mambaforge/envs/mlbp/lib/python3.10/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:424: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=7` in the `DataLoader` to improve performance.\n",
      "[2025-02-25 23:53:01,828][botocore.credentials][INFO] - Found credentials in environment variables.\n",
      "[2025-02-25 23:53:33,316][pytorch_lightning.utilities.rank_zero][INFO] - `Trainer.fit` stopped: `max_epochs=10` reached.\n",
      "üèÉ View run  at: https://datalab.corp.novocorp.net/mlflow/#/experiments/378/runs/6299f4d3c9d1493ca1a0c7f495f24da0\n",
      "üß™ View experiment at: https://datalab.corp.novocorp.net/mlflow/#/experiments/378\n",
      "\u001b[31m2025/02/25 23:53:53 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\u001b[0m\n",
      "[2025-02-25 23:54:00,655][src.model.abstract_components][INFO] - MODEL STOPPED BY EARLY STOPPER AT EPOCH 0\n",
      "[2025-02-25 23:54:00,655][src.model.abstract_components][INFO] - BEST MODEL VALIDATION LOSS IS 0.6870864629745483\n",
      "[2025-02-25 23:54:00,655][src.model.abstract_components][INFO] - BEST MODEL SAVED AT /novo/projects/departments/cdd/public/users/ehec/sbxw_files_2/378/6299f4d3c9d1493ca1a0c7f495f24da0/checkpoints/epoch=9-step=20.ckpt\n",
      "[2025-02-25 23:54:00,656][src.model.abstract_components][INFO] - FINAL MODEL SAVED AT None\n",
      "[2025-02-25 23:54:00,928][src.model.predictors][INFO] - Moving embeddings to device: cuda\n",
      "[2025-02-25 23:54:01,033][src.model.predictors][INFO] - Optimal cutoff is: 0.49 with MCC: 0.09660663150758202\n",
      "[2025-02-25 23:54:01,049][src.model.predictors][INFO] - Moving embeddings to device: cuda\n",
      "[2025-02-25 23:54:01,063][src.model.predictors][INFO] - Moving embeddings to device: cuda\n",
      "[2025-02-25 23:54:01,065][src.model.scalers][INFO] - Before standardization - min: False, max: True\n",
      "[2025-02-25 23:54:01,065][src.model.scalers][INFO] - After standardization - min: False, max: True\n",
      "[2025-02-25 23:54:01,065][src.model.scalers][INFO] - Before standardization - min: False, max: True\n",
      "[2025-02-25 23:54:01,065][src.model.scalers][INFO] - After standardization - min: False, max: True\n",
      "[2025-02-25 23:54:01,066][src.model.composite_model][INFO] - This is the updated predictor name: lightattention_kernel_size_1_dropout_0.25_conv_dropout_0.25_learning_rate_0.0005_batch_size_1000_max_epochs_10_patience_200_post_attention_mlp_conv1d_output_dim_-1_optimal_cutoff_0.49_reduction_mode_max\n",
      "[2025-02-25 23:54:01,066][src.model.composite_model][INFO] - Composite model name: esm2t68MUR50D_LightAttention_sbxwfibrillationpeptidewaltzdb-train-valserrano-test\n",
      "[2025-02-25 23:54:01,066][src.model.composite_model][INFO] - Best model is: kernel_size_1_dropout_0.25_conv_dropout_0.25_learning_rate_0.0005_batch_size_1000_max_epochs_10_patience_200_post_attention_mlp_conv1d_output_dim_-1_optimal_cutoff_0.49_reduction_mode_max\n",
      "[2025-02-25 23:54:01,066][src.model.composite_model][INFO] - Moving to test mode\n",
      "[2025-02-25 23:54:01,066][src.model.composite_model][INFO] - Composite model name: esm2t68MUR50D_LightAttention_sbxwfibrillationpeptidewaltzdb-train-valserrano-test\n",
      "[2025-02-25 23:54:01,067][src.model.composite_model][INFO] - Saving model: esm2t68MUR50D_LightAttention_sbxwfibrillationpeptidewaltzdb-train-valserrano-test\n",
      "<RunInfo: artifact_uri='s3://nnedl-core-prd-eu-central-1-curated/mlops/378/6299f4d3c9d1493ca1a0c7f495f24da0/artifacts', end_time=None, experiment_id='378', lifecycle_stage='active', run_id='6299f4d3c9d1493ca1a0c7f495f24da0', run_name='', run_uuid='6299f4d3c9d1493ca1a0c7f495f24da0', start_time=1740527574046, status='RUNNING', user_id='sbxw'>\n",
      "[2025-02-25 23:54:06,477][src.model.abstract_components][INFO] - Total memory: 23.58378496GB\n",
      "Memory already allocated: 0.05357568GB\n",
      "[2025-02-25 23:54:06,549][src.model.embedders][INFO] - Per-residue embeddings count: 248\n",
      "[2025-02-25 23:54:06,549][src.model.composite_model][INFO] - Residue embeddings\n",
      "[2025-02-25 23:54:06,559][src.model.predictors][INFO] - Moving embeddings to device: cuda\n",
      "[2025-02-25 23:54:06,565][src.model.scalers][INFO] - Before standardization - min: False, max: True\n",
      "[2025-02-25 23:54:06,565][src.model.scalers][INFO] - After standardization - min: False, max: True\n",
      "sequences: (1122,)\n",
      "sequence_embeddings: 1122\n",
      "predictions: (1122,)\n",
      "predictions_scaled: (1122,)\n",
      "data_split: train\n",
      "labels: (1122,)\n",
      "predictions_probability: (1122,)\n",
      "residue_level_prediction: False\n",
      "sequences: (277,)\n",
      "sequence_embeddings: 277\n",
      "predictions: (277,)\n",
      "predictions_scaled: (277,)\n",
      "data_split: val\n",
      "labels: (277,)\n",
      "predictions_probability: (277,)\n",
      "residue_level_prediction: False\n",
      "sequences: (248,)\n",
      "sequence_embeddings: 248\n",
      "predictions: (248,)\n",
      "predictions_scaled: (248,)\n",
      "data_split: test\n",
      "labels: (248,)\n",
      "predictions_probability: (248,)\n",
      "residue_level_prediction: False\n",
      "[2025-02-25 23:54:07,875][src.model.composite_model][INFO] - Composite model name: esm2t68MUR50D_LightAttention_sbxwfibrillationpeptidewaltzdb-train-valserrano-test\n",
      "[2025-02-25 23:54:08,728][__main__][INFO] - Done!\n",
      "run_id: 6299f4d3c9d1493ca1a0c7f495f24da0\n",
      "artifacts: ['model/MLmodel', 'model/checkpoints', 'model/conda.yaml', 'model/data', 'model/python_env.yaml', 'model/requirements.txt']\n",
      "params: {'epochs': '10', 'optimizer_name': 'SGD', 'lr': '0.0005', 'momentum': '0', 'dampening': '0', 'weight_decay': '0', 'nesterov': 'False', 'maximize': 'False', 'foreach': 'None', 'general.run_mode': 'train', 'general.abs_repo_path': 'None', 'general.composite_model_name': 'esm2t68MUR50D_LightAttention_sbxwfibrillationpeptidewaltzdb-train-valserrano-test', 'general.composite_model_path': 'None', 'general.precomputed_embeddings_path': 'None', 'general.random_state': '42', 'dataset.data_name': 'sbxw_fibrillation_peptide_waltzdb-train-val_serrano-test', 'dataset.add_data_columns': 'False', 'dataset.data_columns_dimred': 'False', 'dataset.data_columns_standard': 'False', 'dataset.group_column': 'None', 'dataset.data_scaler': 'RobustScaler', 'dataset.target_scaling': 'None', 'dataset.rbf_encoder': 'RadialBasisFunctionGaussian', 'dataset.rbf_n_kernels': '10', 'dataset.task': 'classification_binary', 'dataset.use_predefined_split': 'True', 'dataset.use_sample_weights': 'False', 'dataset.residue_prediction_labels': 'None', 'dataset.data_split_column': 'data_split', 'dataset.data_split.train': '0.8', 'differentiable': 'False', 'fused': 'None', 'model_type': 'classification_binary', 'embeddings_dim': '320', 'output_dim': '1', 'kernel_size': '1', 'dropout': '0.25', 'conv_dropout': '0.25', 'learning_rate': '0.0005', 'post_attention': 'mlp', 'conv1d_output_dim': '-1', 'residue_prediction_mode': 'False', 'reduction_mode': 'max', 'dataset.data_split.val': '0.0', 'dataset.data_split.test': '0.2', 'embedder.class_name': 'ESM', 'embedder.model_name': 'esm2_t6_8M_UR50D', 'embedder.model_path': 'None', 'embedder.standardize': 'False', 'embedder.scalar_type': 'StandardScaler', 'embedder.hparams': 'None', 'embedder.n_copies': '1', 'embedder.chain_break': 'poly-gly-linker', 'embedder.buffer_scale_factor': '2.0', 'embedder.max_batch_size': '400', 'embedder.simple_batching': 'False', 'embedder.strict': 'True', 'embedder.verbose': 'False', 'embedder.mean_pool': 'False', 'embedder.output_hidden_states': 'False', 'dimred.class_name': 'NoReduction', 'dimred.transform_name': 'None', 'dimred.fraction_variance_explained': 'None', 'predictor.class_name': 'LightAttention', 'predictor.model_name': 'None', 'predictor.model_type': 'classification_binary', 'predictor.mem_per_job': 'None', 'predictor.residue_prediction_mode': 'False', 'predictor.hparams.kernel_size': '1', 'predictor.hparams.dropout': '0.25', 'predictor.hparams.conv_dropout': '0.25', 'predictor.hparams.learning_rate': '0.0005', 'predictor.hparams.batch_size': '1000', 'predictor.hparams.max_epochs': '10', 'predictor.hparams.patience': '200', 'predictor.hparams.post_attention': 'mlp', 'predictor.hparams.conv1d_output_dim': '-1', 'predictor.hparams.optimal_cutoff': '0.5', 'predictor.hparams.reduction_mode': 'max', 'persistence.type': 'lovelace', 'persistence.data_root_folder': '/novo/projects/departments/cdd/molecular_ai/mlbp/data', 'persistence.artifacts_root_folder': '/novo/projects/departments/cdd/molecular_ai/mlbp/artifacts', 'persistence.training_data': 'fibrillation_data', 'persistence.pretrained_weights': 'static_pretrained_weights', 'mlflow.tracking_uri': 'https://datalab.corp.novocorp.net/mlflow/', 'mlflow.experiment_name': 'ML-BP-Domino', 'plots.generate_plots': 'False'}\n",
      "metrics: {'val.loss': 0.6870864629745483, 'train.loss_step': 0.7701335549354553, 'train.loss': 0.7870007157325745, 'epoch': 9.0, 'train.loss_epoch': 0.7870007157325745, 'val_loss': 0.6870864629745483, 'test.accuracy': 0.6935483870967742, 'test.precision': 0.5, 'test.recall': 0.06578947368421052, 'test.specificity': 0.9709302325581395, 'train.accuracy': 0.5623885918003565, 'train.precision': 0.40186915887850466, 'train.recall': 0.4226044226044226, 'train.specificity': 0.641958041958042, 'train.f_score': 0.4119760479041916, 'train.matthews_corr_coef': 0.06390409756761634, 'train.optimal_mcc': 0.06390409756761634, 'train.optimal_mcc_cutoff': 0.49, 'train.balanced_accuracy': 0.5322812322812323, 'train.roc_auc_score': 0.5732513187058641, 'val.accuracy': 0.5740072202166066, 'val.precision': 0.41818181818181815, 'val.recall': 0.46, 'val.specificity': 0.6384180790960452, 'val.f_score': 0.4380952380952381, 'val.matthews_corr_coef': 0.09660663150758202, 'val.optimal_mcc': 0.09660663150758202, 'val.optimal_mcc_cutoff': 0.49, 'val.balanced_accuracy': 0.5492090395480226, 'val.roc_auc_score': 0.6012429378531073, 'test.f_score': 0.11627906976744186, 'test.matthews_corr_coef': 0.08605611564830219, 'test.optimal_mcc': 0.08605611564830219, 'test.optimal_mcc_cutoff': 0.49, 'test.balanced_accuracy': 0.518359853121175, 'test.roc_auc_score': 0.48492962056303546}\n",
      "tags: {'Mode': 'training'}\n",
      "results stored in /novo/projects/departments/cdd/molecular_ai/mlbp/artifacts/2025-02-25-2352_6299f4d3c9d1493ca1a0c7f495f24da0/esm2t68MUR50D_LightAttention_sbxwfibrillationpeptidewaltzdb-train-valserrano-test_stats.csv\n",
      "s3://nnedl-core-prd-eu-central-1-curated/mlops/378/6299f4d3c9d1493ca1a0c7f495f24da0/artifacts\n",
      "\u001b[34mSystem information\u001b[0m: Linux #70~20.04.1-Ubuntu SMP Fri Jun 14 15:42:13 UTC 2024\n",
      "\u001b[34mPython version\u001b[0m: 3.10.14\n",
      "\u001b[34mMLflow version\u001b[0m: 2.20.2\n",
      "\u001b[34mMLflow module location\u001b[0m: /nfs_home/users/sbxw/mambaforge/envs/mlbp/lib/python3.10/site-packages/mlflow/__init__.py\n",
      "\u001b[34mTracking URI\u001b[0m: https://datalab.corp.novocorp.net/mlflow/\n",
      "\u001b[34mRegistry URI\u001b[0m: https://datalab.corp.novocorp.net/mlflow/\n",
      "\u001b[34mActive experiment ID\u001b[0m: 378\n",
      "\u001b[34mActive run ID\u001b[0m: 6299f4d3c9d1493ca1a0c7f495f24da0\n",
      "\u001b[34mActive run artifact URI\u001b[0m: s3://nnedl-core-prd-eu-central-1-curated/mlops/378/6299f4d3c9d1493ca1a0c7f495f24da0/artifacts\n",
      "\u001b[34mMLflow environment variables\u001b[0m: \n",
      "  MLFLOW_EXPERIMENT_ID: 378\n",
      "  MLFLOW_TRACKING_URI: https://datalab.corp.novocorp.net/mlflow/\n",
      "\u001b[34mMLflow dependencies\u001b[0m: \n",
      "  Flask: 2.2.5\n",
      "  Jinja2: 3.1.4\n",
      "  aiohttp: 3.9.5\n",
      "  alembic: 1.13.1\n",
      "  boto3: 1.36.23\n",
      "  botocore: 1.36.23\n",
      "  docker: 7.0.0\n",
      "  graphene: 3.3\n",
      "  gunicorn: 22.0.0\n",
      "  markdown: 3.6\n",
      "  matplotlib: 3.9.0\n",
      "  mlflow-skinny: 2.20.2\n",
      "  numpy: 1.26.4\n",
      "  pandas: 2.2.2\n",
      "  pyarrow: 15.0.2\n",
      "  scikit-learn: 1.4.2\n",
      "  scipy: 1.13.0\n",
      "  sqlalchemy: 2.0.30\n",
      "  virtualenv: 20.26.2\n",
      "None\n",
      "üèÉ View run  at: https://datalab.corp.novocorp.net/mlflow/#/experiments/378/runs/6299f4d3c9d1493ca1a0c7f495f24da0\n",
      "üß™ View experiment at: https://datalab.corp.novocorp.net/mlflow/#/experiments/378\n"
     ]
    }
   ],
   "source": [
    "%env AWS_ACCESS_KEY_ID=ASIATIJCHR3KPDQBE3ZK\n",
    "%env AWS_SECRET_ACCESS_KEY=g5uRXxNkC+F4wcsxo8pGzFLKq7d03Dy/81a6Dypa\n",
    "%env AWS_SESSION_TOKEN=FwoGZXIvYXdzECkaDFQAQqAzDjzkjIikWiL0A1lDrO09XvK1CDnfVAbQlHyFOQi0YEW8t20xe9bDVTv63riG0RyaENE819V+Ep5zF703rUFu8q6jzow4AvHSXM5upyiXZgs3+MiO4sFbzs/TmFLq0t2qGXZerGVbHqFzGtHtZAaoU0zy3jxmCKu6YCb1tzBVPVhSAamN3L3wo997OvZqDwb0M+soWFDAI/9ZoPb02dZK/gsrEfc8BRmPnurze6HkW4OVHFFZXnWjMBmdl4gRw1c1AuYmjT21ajeTRTmdGSFfQ0GdP9PlV8HC7zr8E28aADZAHdLsLp7slN6FDqnGFF5y4TqPrrAmij8ZFYOqoUBPEf+qxtff9mnfxVFOSmF/E4B7Xczf0Uhd300X57Vi/aB6XmPr5vkgGbjNhpaUf40PG7rhJ4sDSV5gJhqlPGT1u3B4hyI60t2Wzzv+iTovF8btjRm/GND5NPRo4LUfS2J2mfyqZ8HbX+gbgHw6FsW28POBv1loT/2VRhzLoBZ71L5CB4sS6vhfbXwySffV3Ev/Eply1T2MYEkQGMpA6vCnT6SnWWGxFd+oR94dKlpmMZThWYfCVNJtI3qu8a9iwfT/w7AQanSCHIY1I6+RYCUa+BDcOedygc3AS8DS3QW4jtK2jshqIkJEMu2nF2twhCbz0lAlBirBPMA6XihUcQMvKIGt+b0GMpQBT6lr0cifUVvnV6L9/CGMkJIbwks6PztNkVnsDjU0nzcvTzOYrTFLSR4nVI/4mHw8rSzhs1OQfqJVGIgqZ642ZxfuUsu7VLG2HokUzAAlje+bdnLtc6SoJJDloPLfnkjajTCzM1al2qlwAgy5OhLf+WAzqderIfbVqnHCDebFGnR1sLJEICRVCJyi/2n8pbTJaXmD1Q==\n",
    "\n",
    "repo_dir = '/novo/projects/departments/cdd/molecular_ai/sbxw/repos/ML-BP-Domino'\n",
    "conda_env_name = 'mlbp'\n",
    "\n",
    "# Create command (single set of params)\n",
    "cmd = [\n",
    "    f\"/nfs_home/users/sbxw/mambaforge/condabin/conda run --no-capture-output -n {conda_env_name} python\",\n",
    "    f\"{repo_dir}/src/cli/training.py\",\n",
    "    \"mlflow=datalab\", \"persistence=lovelace\", \"persistence.training_data=fibrillation_data\",\n",
    "    \"dataset.use_predefined_split=true\",\n",
    "    \"dataset.data_name=sbxw_fibrillation_peptide_waltzdb-train-val_serrano-test\", \"dataset.task=classification_binary\", \n",
    "    \"embedder=esm2_t6_8M\",\"embedder.mean_pool=false\",\n",
    "    \"dimred=noreduction\",\n",
    "    \"predictor=lightattention\",\n",
    "    \"predictor.hparams.kernel_size=1\", \"predictor.hparams.max_epochs=10\", \"predictor.hparams.patience=200\",\n",
    "    \"predictor.hparams.batch_size=1000\", \"predictor.hparams.learning_rate=0.0005\",\n",
    "    \"predictor.hparams.reduction_mode=max\",\n",
    "    \"mlflow.experiment_name=ML-BP-Domino\",\n",
    "    \"plots.generate_plots=false\",\n",
    "]\n",
    "\n",
    "command_str = \" \".join(cmd)\n",
    "print(command_str)\n",
    "!$command_str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c8004cda-0478-4aa0-8a10-2e1ff3873b5b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: AWS_ACCESS_KEY_ID=ASIATIJCHR3KPDQBE3ZK\n",
      "env: AWS_SECRET_ACCESS_KEY=g5uRXxNkC+F4wcsxo8pGzFLKq7d03Dy/81a6Dypa\n",
      "env: AWS_SESSION_TOKEN=FwoGZXIvYXdzECkaDFQAQqAzDjzkjIikWiL0A1lDrO09XvK1CDnfVAbQlHyFOQi0YEW8t20xe9bDVTv63riG0RyaENE819V+Ep5zF703rUFu8q6jzow4AvHSXM5upyiXZgs3+MiO4sFbzs/TmFLq0t2qGXZerGVbHqFzGtHtZAaoU0zy3jxmCKu6YCb1tzBVPVhSAamN3L3wo997OvZqDwb0M+soWFDAI/9ZoPb02dZK/gsrEfc8BRmPnurze6HkW4OVHFFZXnWjMBmdl4gRw1c1AuYmjT21ajeTRTmdGSFfQ0GdP9PlV8HC7zr8E28aADZAHdLsLp7slN6FDqnGFF5y4TqPrrAmij8ZFYOqoUBPEf+qxtff9mnfxVFOSmF/E4B7Xczf0Uhd300X57Vi/aB6XmPr5vkgGbjNhpaUf40PG7rhJ4sDSV5gJhqlPGT1u3B4hyI60t2Wzzv+iTovF8btjRm/GND5NPRo4LUfS2J2mfyqZ8HbX+gbgHw6FsW28POBv1loT/2VRhzLoBZ71L5CB4sS6vhfbXwySffV3Ev/Eply1T2MYEkQGMpA6vCnT6SnWWGxFd+oR94dKlpmMZThWYfCVNJtI3qu8a9iwfT/w7AQanSCHIY1I6+RYCUa+BDcOedygc3AS8DS3QW4jtK2jshqIkJEMu2nF2twhCbz0lAlBirBPMA6XihUcQMvKIGt+b0GMpQBT6lr0cifUVvnV6L9/CGMkJIbwks6PztNkVnsDjU0nzcvTzOYrTFLSR4nVI/4mHw8rSzhs1OQfqJVGIgqZ642ZxfuUsu7VLG2HokUzAAlje+bdnLtc6SoJJDloPLfnkjajTCzM1al2qlwAgy5OhLf+WAzqderIfbVqnHCDebFGnR1sLJEICRVCJyi/2n8pbTJaXmD1Q==\n",
      "/nfs_home/users/sbxw/mambaforge/condabin/conda run --no-capture-output -n mlbp python /novo/projects/departments/cdd/molecular_ai/sbxw/repos/ML-BP-Domino/src/cli/training.py mlflow=datalab persistence=lovelace persistence.training_data=fibrillation_data dataset.use_predefined_split=true dataset.data_name=sbxw_fibrillation_peptide_waltzdb-train-val_serrano-test dataset.task=classification_binary embedder=esm2_t6_8M embedder.mean_pool=false dimred=noreduction predictor=lightattention predictor.hparams.kernel_size=1 predictor.hparams.max_epochs=10 predictor.hparams.patience=200 predictor.hparams.batch_size=1000 predictor.hparams.learning_rate=0.0005 predictor.hparams.reduction_mode=sum mlflow.experiment_name=ML-BP-Domino plots.generate_plots=false\n",
      "2025-02-26 00:05:44.959403: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2025-02-26 00:05:44.959453: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2025-02-26 00:05:44.960953: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2025-02-26 00:05:44.968628: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2025-02-26 00:05:47.462322: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "[2025-02-26 00:05:55,226][__main__][INFO] - Workflow configuration:\n",
      "\n",
      "general:\n",
      "  run_mode: train\n",
      "  abs_repo_path: null\n",
      "  composite_model_name: null\n",
      "  composite_model_path: null\n",
      "  precomputed_embeddings_path: null\n",
      "  random_state: 42\n",
      "dataset:\n",
      "  data_name: sbxw_fibrillation_peptide_waltzdb-train-val_serrano-test\n",
      "  add_data_columns: false\n",
      "  data_columns_dimred: false\n",
      "  data_columns_standard: false\n",
      "  group_column: null\n",
      "  data_scaler: RobustScaler\n",
      "  target_scaling: null\n",
      "  rbf_encoder: RadialBasisFunctionGaussian\n",
      "  rbf_n_kernels: 10\n",
      "  task: classification_binary\n",
      "  use_predefined_split: true\n",
      "  use_sample_weights: false\n",
      "  residue_prediction_labels: null\n",
      "  data_split_column: data_split\n",
      "  data_split:\n",
      "    train: 0.8\n",
      "    val: 0.0\n",
      "    test: 0.2\n",
      "embedder:\n",
      "  class_name: ESM\n",
      "  model_name: esm2_t6_8M_UR50D\n",
      "  model_path: null\n",
      "  standardize: false\n",
      "  scalar_type: StandardScaler\n",
      "  hparams: null\n",
      "  n_copies: 1\n",
      "  chain_break: poly-gly-linker\n",
      "  buffer_scale_factor: 2.0\n",
      "  max_batch_size: 400\n",
      "  simple_batching: false\n",
      "  strict: true\n",
      "  verbose: false\n",
      "  mean_pool: false\n",
      "  output_hidden_states: false\n",
      "dimred:\n",
      "  class_name: NoReduction\n",
      "  transform_name: null\n",
      "  fraction_variance_explained: null\n",
      "predictor:\n",
      "  class_name: LightAttention\n",
      "  model_name: null\n",
      "  model_type: classification_binary\n",
      "  mem_per_job: null\n",
      "  residue_prediction_mode: false\n",
      "  hparams:\n",
      "    kernel_size: 1\n",
      "    dropout: 0.25\n",
      "    conv_dropout: 0.25\n",
      "    learning_rate: 0.0005\n",
      "    batch_size: 1000\n",
      "    max_epochs: 10\n",
      "    patience: 200\n",
      "    post_attention: mlp\n",
      "    conv1d_output_dim: -1\n",
      "    optimal_cutoff: 0.5\n",
      "    reduction_mode: sum\n",
      "persistence:\n",
      "  type: lovelace\n",
      "  data_root_folder: /novo/projects/departments/cdd/molecular_ai/mlbp/data\n",
      "  artifacts_root_folder: /novo/projects/departments/cdd/molecular_ai/mlbp/artifacts\n",
      "  training_data: fibrillation_data\n",
      "  pretrained_weights: static_pretrained_weights\n",
      "mlflow:\n",
      "  tracking_uri: https://datalab.corp.novocorp.net/mlflow/\n",
      "  experiment_name: ML-BP-Domino\n",
      "plots:\n",
      "  generate_plots: false\n",
      "\n",
      "[2025-02-26 00:05:55,227][src.model.dimred][INFO] - Load class (NoReduction): NoReduction\n",
      "[2025-02-26 00:05:55,227][src.model.abstract_components][INFO] - Load class (DimRed Model): NoReduction\n",
      "[2025-02-26 00:05:55,227][src.model.predictors][INFO] - Load class (LightAttention): LightAttention\n",
      "[2025-02-26 00:05:55,227][src.model.abstract_components][INFO] - Load class (TorchPredictorModel): LightAttention\n",
      "[2025-02-26 00:05:55,227][src.model.abstract_components][INFO] - Load class (Predictor Model): LightAttention\n",
      "[2025-02-26 00:05:55,228][src.model.composite_model][INFO] - Composite model name: esm2t68MUR50D_LightAttention_sbxwfibrillationpeptidewaltzdb-train-valserrano-test\n",
      "[2025-02-26 00:05:55,228][src.model.composite_model][INFO] - Initialized model: esm2t68MUR50D_LightAttention_sbxwfibrillationpeptidewaltzdb-train-valserrano-test in run_mode = train\n",
      "[2025-02-26 00:05:55,232][src.helpers.dataset][INFO] - Loading file: /novo/projects/departments/cdd/molecular_ai/mlbp/data/fibrillation_data/sbxw_fibrillation_peptide_waltzdb-train-val_serrano-test.csv\n",
      "[2025-02-26 00:05:55,233][src.helpers.dataset][INFO] - Using group_column \"None\".\n",
      "[2025-02-26 00:05:55,233][src.helpers.dataset][INFO] - No additional data columns found while parsing.\n",
      "[2025-02-26 00:05:55,234][src.helpers.dataset][INFO] - Select data according to predetermined splits in the dataframe, train (N = 1122), validation (N = 277), test (N = 248)\n",
      "[2025-02-26 00:05:55,235][src.helpers.dataset][INFO] - Loaded columns: {}\n",
      "[2025-02-26 00:05:55,235][src.helpers.mlflow_helpers][INFO] - Setting up MLflow...\n",
      "[2025-02-26 00:05:55,236][src.helpers.mlflow_helpers][INFO] - Experiment name: ML-BP-Domino\n",
      "[2025-02-26 00:05:55,236][src.helpers.mlflow_helpers][INFO] - Setting MLflow tracking URI to https://datalab.corp.novocorp.net/mlflow/\n",
      "[2025-02-26 00:05:56,182][src.helpers.mlflow_helpers][INFO] - Setting MLflow experiment to ML-BP-Domino\n",
      "[2025-02-26 00:05:56,590][__main__][INFO] - <RunInfo: artifact_uri='s3://nnedl-core-prd-eu-central-1-curated/mlops/378/e51dd1ee832a4ae996b93160c0da11b9/artifacts', end_time=None, experiment_id='378', lifecycle_stage='active', run_id='e51dd1ee832a4ae996b93160c0da11b9', run_name='', run_uuid='e51dd1ee832a4ae996b93160c0da11b9', start_time=1740528356345, status='RUNNING', user_id='sbxw'>\n",
      "[2025-02-26 00:05:57,240][__main__][INFO] - Compute embeddings on-the-fly and train model\n",
      "[2025-02-26 00:05:57,240][src.model.abstract_components][INFO] - Load class (LLMEmbedderModel): ESM\n",
      "[2025-02-26 00:05:57,240][src.model.abstract_components][INFO] - Load class (Embedder Model): ESM\n",
      "[2025-02-26 00:05:57,241][src.model.embedders][INFO] - Loading model: esm2_t6_8M_UR50D, will extract embeddings from 6-th layer\n",
      "Some weights of EsmModel were not initialized from the model checkpoint at facebook/esm2_t6_8M_UR50D and are newly initialized: ['esm.pooler.dense.bias', 'esm.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "[2025-02-26 00:05:58,334][src.model.embedders][INFO] - Moving model to cuda\n",
      "[2025-02-26 00:05:58,517][src.model.abstract_components][INFO] - Total memory: 23.58378496GB\n",
      "Memory already allocated: 0.031387648GB\n",
      "[2025-02-26 00:05:59,017][src.model.embedders][INFO] - Per-residue embeddings count: 1122\n",
      "[2025-02-26 00:05:59,018][src.model.composite_model][INFO] - Residue embeddings\n",
      "[2025-02-26 00:05:59,018][src.model.abstract_components][INFO] - Total memory: 23.58378496GB\n",
      "Memory already allocated: 0.043664896GB\n",
      "[2025-02-26 00:05:59,041][src.model.embedders][INFO] - Per-residue embeddings count: 277\n",
      "[2025-02-26 00:05:59,041][src.model.scalers][INFO] - Fitted scaler: PassThroughScaler\n",
      "[2025-02-26 00:05:59,042][src.model.scalers][INFO] - Before standardization - min: 0.0, max: 1.0\n",
      "[2025-02-26 00:05:59,042][src.model.scalers][INFO] - After standardization - min: 0.0, max: 1.0\n",
      "[2025-02-26 00:05:59,042][src.model.scalers][INFO] - Before standardization - min: 0.0, max: 1.0\n",
      "[2025-02-26 00:05:59,042][src.model.scalers][INFO] - After standardization - min: 0.0, max: 1.0\n",
      "[2025-02-26 00:05:59,042][src.model.scalers][INFO] - Before standardization - min: 0.0, max: 1.0\n",
      "[2025-02-26 00:05:59,042][src.model.scalers][INFO] - After standardization - min: 0.0, max: 1.0\n",
      "/nfs_home/users/sbxw/mambaforge/envs/mlbp/lib/python3.10/site-packages/lightning/fabric/plugins/environments/slurm.py:204: The `srun` command is available on your system but is not used. HINT: If your intention is to run Lightning on SLURM, prepend your python command with `srun` like so: srun python /novo/projects/departments/cdd/molecular_ai/sbxw/rep ...\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/nfs_home/users/sbxw/mambaforge/envs/mlbp/lib/python3.10/site-packages/lightning/fabric/plugins/environments/slurm.py:204: The `srun` command is available on your system but is not used. HINT: If your intention is to run Lightning on SLURM, prepend your python command with `srun` like so: srun python /novo/projects/departments/cdd/molecular_ai/sbxw/rep ...\n",
      "[2025-02-26 00:06:00,227][pytorch_lightning.utilities.rank_zero][INFO] - You are using a CUDA device ('NVIDIA L4') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name                  | Type       | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | feature_convolution   | Conv1d     | 102 K  | train\n",
      "1 | attention_convolution | Conv1d     | 102 K  | train\n",
      "2 | softmax               | Softmax    | 0      | train\n",
      "3 | dropout               | Dropout    | 0      | train\n",
      "4 | sigmoid               | Sigmoid    | 0      | train\n",
      "5 | mlp                   | Sequential | 10.4 K | train\n",
      "6 | loss_fxn              | BCELoss    | 0      | train\n",
      "-------------------------------------------------------------\n",
      "215 K     Trainable params\n",
      "0         Non-trainable params\n",
      "215 K     Total params\n",
      "0.863     Total estimated model params size (MB)\n",
      "12        Modules in train mode\n",
      "0         Modules in eval mode\n",
      "/nfs_home/users/sbxw/mambaforge/envs/mlbp/lib/python3.10/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:424: The 'val_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=7` in the `DataLoader` to improve performance.\n",
      "/nfs_home/users/sbxw/mambaforge/envs/mlbp/lib/python3.10/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:424: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=7` in the `DataLoader` to improve performance.\n",
      "[2025-02-26 00:06:04,148][botocore.credentials][INFO] - Found credentials in environment variables.\n",
      "[2025-02-26 00:06:35,867][pytorch_lightning.utilities.rank_zero][INFO] - `Trainer.fit` stopped: `max_epochs=10` reached.\n",
      "üèÉ View run  at: https://datalab.corp.novocorp.net/mlflow/#/experiments/378/runs/e51dd1ee832a4ae996b93160c0da11b9\n",
      "üß™ View experiment at: https://datalab.corp.novocorp.net/mlflow/#/experiments/378\n",
      "\u001b[31m2025/02/26 00:07:01 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\u001b[0m\n",
      "[2025-02-26 00:07:12,086][src.model.abstract_components][INFO] - MODEL STOPPED BY EARLY STOPPER AT EPOCH 0\n",
      "[2025-02-26 00:07:12,086][src.model.abstract_components][INFO] - BEST MODEL VALIDATION LOSS IS 0.652656614780426\n",
      "[2025-02-26 00:07:12,086][src.model.abstract_components][INFO] - BEST MODEL SAVED AT /novo/projects/departments/cdd/public/users/ehec/sbxw_files_2/378/e51dd1ee832a4ae996b93160c0da11b9/checkpoints/epoch=9-step=20.ckpt\n",
      "[2025-02-26 00:07:12,086][src.model.abstract_components][INFO] - FINAL MODEL SAVED AT None\n",
      "[2025-02-26 00:07:12,347][src.model.predictors][INFO] - Moving embeddings to device: cuda\n",
      "[2025-02-26 00:07:12,447][src.model.predictors][INFO] - Optimal cutoff is: 0.41000000000000003 with MCC: 0.27964031846949833\n",
      "[2025-02-26 00:07:12,463][src.model.predictors][INFO] - Moving embeddings to device: cuda\n",
      "[2025-02-26 00:07:12,476][src.model.predictors][INFO] - Moving embeddings to device: cuda\n",
      "[2025-02-26 00:07:12,477][src.model.scalers][INFO] - Before standardization - min: False, max: True\n",
      "[2025-02-26 00:07:12,478][src.model.scalers][INFO] - After standardization - min: False, max: True\n",
      "[2025-02-26 00:07:12,478][src.model.scalers][INFO] - Before standardization - min: False, max: True\n",
      "[2025-02-26 00:07:12,478][src.model.scalers][INFO] - After standardization - min: False, max: True\n",
      "[2025-02-26 00:07:12,478][src.model.composite_model][INFO] - This is the updated predictor name: lightattention_kernel_size_1_dropout_0.25_conv_dropout_0.25_learning_rate_0.0005_batch_size_1000_max_epochs_10_patience_200_post_attention_mlp_conv1d_output_dim_-1_optimal_cutoff_0.41000000000000003_reduction_mode_sum\n",
      "[2025-02-26 00:07:12,479][src.model.composite_model][INFO] - Composite model name: esm2t68MUR50D_LightAttention_sbxwfibrillationpeptidewaltzdb-train-valserrano-test\n",
      "[2025-02-26 00:07:12,479][src.model.composite_model][INFO] - Best model is: kernel_size_1_dropout_0.25_conv_dropout_0.25_learning_rate_0.0005_batch_size_1000_max_epochs_10_patience_200_post_attention_mlp_conv1d_output_dim_-1_optimal_cutoff_0.41000000000000003_reduction_mode_sum\n",
      "[2025-02-26 00:07:12,479][src.model.composite_model][INFO] - Moving to test mode\n",
      "[2025-02-26 00:07:12,479][src.model.composite_model][INFO] - Composite model name: esm2t68MUR50D_LightAttention_sbxwfibrillationpeptidewaltzdb-train-valserrano-test\n",
      "[2025-02-26 00:07:12,479][src.model.composite_model][INFO] - Saving model: esm2t68MUR50D_LightAttention_sbxwfibrillationpeptidewaltzdb-train-valserrano-test\n",
      "<RunInfo: artifact_uri='s3://nnedl-core-prd-eu-central-1-curated/mlops/378/e51dd1ee832a4ae996b93160c0da11b9/artifacts', end_time=None, experiment_id='378', lifecycle_stage='active', run_id='e51dd1ee832a4ae996b93160c0da11b9', run_name='', run_uuid='e51dd1ee832a4ae996b93160c0da11b9', start_time=1740528356345, status='RUNNING', user_id='sbxw'>\n",
      "[2025-02-26 00:07:18,947][src.model.abstract_components][INFO] - Total memory: 23.58378496GB\n",
      "Memory already allocated: 0.05357568GB\n",
      "[2025-02-26 00:07:19,018][src.model.embedders][INFO] - Per-residue embeddings count: 248\n",
      "[2025-02-26 00:07:19,018][src.model.composite_model][INFO] - Residue embeddings\n",
      "[2025-02-26 00:07:19,022][src.model.predictors][INFO] - Moving embeddings to device: cuda\n",
      "[2025-02-26 00:07:19,027][src.model.scalers][INFO] - Before standardization - min: False, max: True\n",
      "[2025-02-26 00:07:19,027][src.model.scalers][INFO] - After standardization - min: False, max: True\n",
      "sequences: (1122,)\n",
      "sequence_embeddings: 1122\n",
      "predictions: (1122,)\n",
      "predictions_scaled: (1122,)\n",
      "data_split: train\n",
      "labels: (1122,)\n",
      "predictions_probability: (1122,)\n",
      "residue_level_prediction: False\n",
      "sequences: (277,)\n",
      "sequence_embeddings: 277\n",
      "predictions: (277,)\n",
      "predictions_scaled: (277,)\n",
      "data_split: val\n",
      "labels: (277,)\n",
      "predictions_probability: (277,)\n",
      "residue_level_prediction: False\n",
      "sequences: (248,)\n",
      "sequence_embeddings: 248\n",
      "predictions: (248,)\n",
      "predictions_scaled: (248,)\n",
      "data_split: test\n",
      "labels: (248,)\n",
      "predictions_probability: (248,)\n",
      "residue_level_prediction: False\n",
      "[2025-02-26 00:07:20,431][src.model.composite_model][INFO] - Composite model name: esm2t68MUR50D_LightAttention_sbxwfibrillationpeptidewaltzdb-train-valserrano-test\n",
      "[2025-02-26 00:07:21,333][__main__][INFO] - Done!\n",
      "run_id: e51dd1ee832a4ae996b93160c0da11b9\n",
      "artifacts: ['model/MLmodel', 'model/checkpoints', 'model/conda.yaml', 'model/data', 'model/python_env.yaml', 'model/requirements.txt']\n",
      "params: {'model_type': 'classification_binary', 'general.run_mode': 'train', 'general.abs_repo_path': 'None', 'general.composite_model_name': 'esm2t68MUR50D_LightAttention_sbxwfibrillationpeptidewaltzdb-train-valserrano-test', 'general.composite_model_path': 'None', 'general.precomputed_embeddings_path': 'None', 'general.random_state': '42', 'dataset.data_name': 'sbxw_fibrillation_peptide_waltzdb-train-val_serrano-test', 'dataset.add_data_columns': 'False', 'dataset.data_columns_dimred': 'False', 'dataset.data_columns_standard': 'False', 'dataset.group_column': 'None', 'dataset.data_scaler': 'RobustScaler', 'dataset.target_scaling': 'None', 'dataset.rbf_encoder': 'RadialBasisFunctionGaussian', 'dataset.rbf_n_kernels': '10', 'dataset.task': 'classification_binary', 'dataset.use_predefined_split': 'True', 'dataset.use_sample_weights': 'False', 'dataset.residue_prediction_labels': 'None', 'dataset.data_split_column': 'data_split', 'dataset.data_split.train': '0.8', 'dataset.data_split.val': '0.0', 'dataset.data_split.test': '0.2', 'embedder.class_name': 'ESM', 'embedder.model_name': 'esm2_t6_8M_UR50D', 'embedder.model_path': 'None', 'embedder.standardize': 'False', 'embedder.scalar_type': 'StandardScaler', 'embedder.hparams': 'None', 'embedder.n_copies': '1', 'embedder.chain_break': 'poly-gly-linker', 'embedder.buffer_scale_factor': '2.0', 'embedder.max_batch_size': '400', 'embedder.simple_batching': 'False', 'embedder.strict': 'True', 'embedder.verbose': 'False', 'embedder.mean_pool': 'False', 'embedder.output_hidden_states': 'False', 'dimred.class_name': 'NoReduction', 'dimred.transform_name': 'None', 'dimred.fraction_variance_explained': 'None', 'predictor.class_name': 'LightAttention', 'predictor.model_name': 'None', 'predictor.model_type': 'classification_binary', 'predictor.mem_per_job': 'None', 'predictor.residue_prediction_mode': 'False', 'predictor.hparams.kernel_size': '1', 'predictor.hparams.dropout': '0.25', 'predictor.hparams.conv_dropout': '0.25', 'predictor.hparams.learning_rate': '0.0005', 'predictor.hparams.batch_size': '1000', 'predictor.hparams.max_epochs': '10', 'predictor.hparams.patience': '200', 'predictor.hparams.post_attention': 'mlp', 'predictor.hparams.conv1d_output_dim': '-1', 'predictor.hparams.optimal_cutoff': '0.5', 'predictor.hparams.reduction_mode': 'sum', 'persistence.type': 'lovelace', 'persistence.data_root_folder': '/novo/projects/departments/cdd/molecular_ai/mlbp/data', 'persistence.artifacts_root_folder': '/novo/projects/departments/cdd/molecular_ai/mlbp/artifacts', 'persistence.training_data': 'fibrillation_data', 'persistence.pretrained_weights': 'static_pretrained_weights', 'mlflow.tracking_uri': 'https://datalab.corp.novocorp.net/mlflow/', 'mlflow.experiment_name': 'ML-BP-Domino', 'plots.generate_plots': 'False', 'embeddings_dim': '320', 'output_dim': '1', 'kernel_size': '1', 'dropout': '0.25', 'conv_dropout': '0.25', 'learning_rate': '0.0005', 'post_attention': 'mlp', 'conv1d_output_dim': '-1', 'residue_prediction_mode': 'False', 'reduction_mode': 'sum', 'epochs': '10', 'optimizer_name': 'SGD', 'lr': '0.0005', 'momentum': '0', 'dampening': '0', 'weight_decay': '0', 'nesterov': 'False', 'maximize': 'False', 'foreach': 'None', 'differentiable': 'False', 'fused': 'None'}\n",
      "metrics: {'test.accuracy': 0.6693548387096774, 'test.precision': 0.125, 'test.recall': 0.013157894736842105, 'test.specificity': 0.9593023255813954, 'test.f_score': 0.023809523809523808, 'test.matthews_corr_coef': -0.07185894996679591, 'test.optimal_mcc': 0.0, 'test.optimal_mcc_cutoff': 0.0, 'test.balanced_accuracy': 0.48623011015911877, 'test.roc_auc_score': 0.29731487148102814, 'val.accuracy': 0.6859205776173285, 'val.precision': 0.5942028985507246, 'val.recall': 0.41, 'val.specificity': 0.8418079096045198, 'val.f_score': 0.48520710059171596, 'val.matthews_corr_coef': 0.27964031846949833, 'val.optimal_mcc': 0.27964031846949833, 'val.optimal_mcc_cutoff': 0.41000000000000003, 'val.balanced_accuracy': 0.6259039548022599, 'val.roc_auc_score': 0.6942937853107344, 'train.accuracy': 0.6684491978609626, 'train.precision': 0.5665399239543726, 'train.recall': 0.36609336609336607, 'train.specificity': 0.8405594405594405, 'train.f_score': 0.44477611940298506, 'train.matthews_corr_coef': 0.23454008455010847, 'train.optimal_mcc': 0.23454008455010847, 'train.optimal_mcc_cutoff': 0.41000000000000003, 'train.balanced_accuracy': 0.6033264033264033, 'train.loss_step': 0.6366236209869385, 'train.roc_auc_score': 0.6556554011099466, 'epoch': 9.0, 'val.loss': 0.652656614780426, 'train.loss': 0.7951897382736206, 'train.loss_epoch': 0.7951897382736206, 'val_loss': 0.652656614780426}\n",
      "tags: {'Mode': 'training'}\n",
      "results stored in /novo/projects/departments/cdd/molecular_ai/mlbp/artifacts/2025-02-26-0005_e51dd1ee832a4ae996b93160c0da11b9/esm2t68MUR50D_LightAttention_sbxwfibrillationpeptidewaltzdb-train-valserrano-test_stats.csv\n",
      "s3://nnedl-core-prd-eu-central-1-curated/mlops/378/e51dd1ee832a4ae996b93160c0da11b9/artifacts\n",
      "\u001b[34mSystem information\u001b[0m: Linux #70~20.04.1-Ubuntu SMP Fri Jun 14 15:42:13 UTC 2024\n",
      "\u001b[34mPython version\u001b[0m: 3.10.14\n",
      "\u001b[34mMLflow version\u001b[0m: 2.20.2\n",
      "\u001b[34mMLflow module location\u001b[0m: /nfs_home/users/sbxw/mambaforge/envs/mlbp/lib/python3.10/site-packages/mlflow/__init__.py\n",
      "\u001b[34mTracking URI\u001b[0m: https://datalab.corp.novocorp.net/mlflow/\n",
      "\u001b[34mRegistry URI\u001b[0m: https://datalab.corp.novocorp.net/mlflow/\n",
      "\u001b[34mActive experiment ID\u001b[0m: 378\n",
      "\u001b[34mActive run ID\u001b[0m: e51dd1ee832a4ae996b93160c0da11b9\n",
      "\u001b[34mActive run artifact URI\u001b[0m: s3://nnedl-core-prd-eu-central-1-curated/mlops/378/e51dd1ee832a4ae996b93160c0da11b9/artifacts\n",
      "\u001b[34mMLflow environment variables\u001b[0m: \n",
      "  MLFLOW_EXPERIMENT_ID: 378\n",
      "  MLFLOW_TRACKING_URI: https://datalab.corp.novocorp.net/mlflow/\n",
      "\u001b[34mMLflow dependencies\u001b[0m: \n",
      "  Flask: 2.2.5\n",
      "  Jinja2: 3.1.4\n",
      "  aiohttp: 3.9.5\n",
      "  alembic: 1.13.1\n",
      "  boto3: 1.36.23\n",
      "  botocore: 1.36.23\n",
      "  docker: 7.0.0\n",
      "  graphene: 3.3\n",
      "  gunicorn: 22.0.0\n",
      "  markdown: 3.6\n",
      "  matplotlib: 3.9.0\n",
      "  mlflow-skinny: 2.20.2\n",
      "  numpy: 1.26.4\n",
      "  pandas: 2.2.2\n",
      "  pyarrow: 15.0.2\n",
      "  scikit-learn: 1.4.2\n",
      "  scipy: 1.13.0\n",
      "  sqlalchemy: 2.0.30\n",
      "  virtualenv: 20.26.2\n",
      "None\n",
      "üèÉ View run  at: https://datalab.corp.novocorp.net/mlflow/#/experiments/378/runs/e51dd1ee832a4ae996b93160c0da11b9\n",
      "üß™ View experiment at: https://datalab.corp.novocorp.net/mlflow/#/experiments/378\n"
     ]
    }
   ],
   "source": [
    "%env AWS_ACCESS_KEY_ID=ASIATIJCHR3KPDQBE3ZK\n",
    "%env AWS_SECRET_ACCESS_KEY=g5uRXxNkC+F4wcsxo8pGzFLKq7d03Dy/81a6Dypa\n",
    "%env AWS_SESSION_TOKEN=FwoGZXIvYXdzECkaDFQAQqAzDjzkjIikWiL0A1lDrO09XvK1CDnfVAbQlHyFOQi0YEW8t20xe9bDVTv63riG0RyaENE819V+Ep5zF703rUFu8q6jzow4AvHSXM5upyiXZgs3+MiO4sFbzs/TmFLq0t2qGXZerGVbHqFzGtHtZAaoU0zy3jxmCKu6YCb1tzBVPVhSAamN3L3wo997OvZqDwb0M+soWFDAI/9ZoPb02dZK/gsrEfc8BRmPnurze6HkW4OVHFFZXnWjMBmdl4gRw1c1AuYmjT21ajeTRTmdGSFfQ0GdP9PlV8HC7zr8E28aADZAHdLsLp7slN6FDqnGFF5y4TqPrrAmij8ZFYOqoUBPEf+qxtff9mnfxVFOSmF/E4B7Xczf0Uhd300X57Vi/aB6XmPr5vkgGbjNhpaUf40PG7rhJ4sDSV5gJhqlPGT1u3B4hyI60t2Wzzv+iTovF8btjRm/GND5NPRo4LUfS2J2mfyqZ8HbX+gbgHw6FsW28POBv1loT/2VRhzLoBZ71L5CB4sS6vhfbXwySffV3Ev/Eply1T2MYEkQGMpA6vCnT6SnWWGxFd+oR94dKlpmMZThWYfCVNJtI3qu8a9iwfT/w7AQanSCHIY1I6+RYCUa+BDcOedygc3AS8DS3QW4jtK2jshqIkJEMu2nF2twhCbz0lAlBirBPMA6XihUcQMvKIGt+b0GMpQBT6lr0cifUVvnV6L9/CGMkJIbwks6PztNkVnsDjU0nzcvTzOYrTFLSR4nVI/4mHw8rSzhs1OQfqJVGIgqZ642ZxfuUsu7VLG2HokUzAAlje+bdnLtc6SoJJDloPLfnkjajTCzM1al2qlwAgy5OhLf+WAzqderIfbVqnHCDebFGnR1sLJEICRVCJyi/2n8pbTJaXmD1Q==\n",
    "\n",
    "repo_dir = '/novo/projects/departments/cdd/molecular_ai/sbxw/repos/ML-BP-Domino'\n",
    "conda_env_name = 'mlbp'\n",
    "\n",
    "# Create command (single set of params)\n",
    "cmd = [\n",
    "    f\"/nfs_home/users/sbxw/mambaforge/condabin/conda run --no-capture-output -n {conda_env_name} python\",\n",
    "    f\"{repo_dir}/src/cli/training.py\",\n",
    "    \"mlflow=datalab\", \"persistence=lovelace\", \"persistence.training_data=fibrillation_data\",\n",
    "    \"dataset.use_predefined_split=true\",\n",
    "    \"dataset.data_name=sbxw_fibrillation_peptide_waltzdb-train-val_serrano-test\", \"dataset.task=classification_binary\", \n",
    "    \"embedder=esm2_t6_8M\",\"embedder.mean_pool=false\",\n",
    "    \"dimred=noreduction\",\n",
    "    \"predictor=lightattention\",\n",
    "    \"predictor.hparams.kernel_size=1\", \"predictor.hparams.max_epochs=10\", \"predictor.hparams.patience=200\",\n",
    "    \"predictor.hparams.batch_size=1000\", \"predictor.hparams.learning_rate=0.0005\",\n",
    "    \"predictor.hparams.reduction_mode=sum\",\n",
    "    \"mlflow.experiment_name=ML-BP-Domino\",\n",
    "    \"plots.generate_plots=false\",\n",
    "]\n",
    "\n",
    "command_str = \" \".join(cmd)\n",
    "print(command_str)\n",
    "!$command_str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "daf8bd07-a67f-4518-9625-f0101e47965a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: AWS_ACCESS_KEY_ID=ASIATIJCHR3KPDQBE3ZK\n",
      "env: AWS_SECRET_ACCESS_KEY=g5uRXxNkC+F4wcsxo8pGzFLKq7d03Dy/81a6Dypa\n",
      "env: AWS_SESSION_TOKEN=FwoGZXIvYXdzECkaDFQAQqAzDjzkjIikWiL0A1lDrO09XvK1CDnfVAbQlHyFOQi0YEW8t20xe9bDVTv63riG0RyaENE819V+Ep5zF703rUFu8q6jzow4AvHSXM5upyiXZgs3+MiO4sFbzs/TmFLq0t2qGXZerGVbHqFzGtHtZAaoU0zy3jxmCKu6YCb1tzBVPVhSAamN3L3wo997OvZqDwb0M+soWFDAI/9ZoPb02dZK/gsrEfc8BRmPnurze6HkW4OVHFFZXnWjMBmdl4gRw1c1AuYmjT21ajeTRTmdGSFfQ0GdP9PlV8HC7zr8E28aADZAHdLsLp7slN6FDqnGFF5y4TqPrrAmij8ZFYOqoUBPEf+qxtff9mnfxVFOSmF/E4B7Xczf0Uhd300X57Vi/aB6XmPr5vkgGbjNhpaUf40PG7rhJ4sDSV5gJhqlPGT1u3B4hyI60t2Wzzv+iTovF8btjRm/GND5NPRo4LUfS2J2mfyqZ8HbX+gbgHw6FsW28POBv1loT/2VRhzLoBZ71L5CB4sS6vhfbXwySffV3Ev/Eply1T2MYEkQGMpA6vCnT6SnWWGxFd+oR94dKlpmMZThWYfCVNJtI3qu8a9iwfT/w7AQanSCHIY1I6+RYCUa+BDcOedygc3AS8DS3QW4jtK2jshqIkJEMu2nF2twhCbz0lAlBirBPMA6XihUcQMvKIGt+b0GMpQBT6lr0cifUVvnV6L9/CGMkJIbwks6PztNkVnsDjU0nzcvTzOYrTFLSR4nVI/4mHw8rSzhs1OQfqJVGIgqZ642ZxfuUsu7VLG2HokUzAAlje+bdnLtc6SoJJDloPLfnkjajTCzM1al2qlwAgy5OhLf+WAzqderIfbVqnHCDebFGnR1sLJEICRVCJyi/2n8pbTJaXmD1Q==\n",
      "/nfs_home/users/sbxw/mambaforge/condabin/conda run --no-capture-output -n mlbp python /novo/projects/departments/cdd/molecular_ai/sbxw/repos/ML-BP-Domino/src/cli/training.py mlflow=datalab persistence=lovelace persistence.training_data=fibrillation_data dataset.use_predefined_split=true dataset.data_name=sbxw_fibrillation_peptide_waltzdb-train-val_serrano-test_randpadded10x dataset.task=classification_binary embedder=esm2_t6_8M embedder.mean_pool=false dimred=noreduction predictor=lightattention predictor.hparams.kernel_size=1 predictor.hparams.max_epochs=10 predictor.hparams.patience=200 predictor.hparams.batch_size=1000 predictor.hparams.learning_rate=0.0005 predictor.hparams.reduction_mode=sum mlflow.experiment_name=ML-BP-Domino plots.generate_plots=false\n",
      "2025-02-26 00:17:19.254038: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2025-02-26 00:17:19.254085: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2025-02-26 00:17:19.255583: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2025-02-26 00:17:19.263028: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2025-02-26 00:17:23.417011: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "[2025-02-26 00:17:39,740][__main__][INFO] - Workflow configuration:\n",
      "\n",
      "general:\n",
      "  run_mode: train\n",
      "  abs_repo_path: null\n",
      "  composite_model_name: null\n",
      "  composite_model_path: null\n",
      "  precomputed_embeddings_path: null\n",
      "  random_state: 42\n",
      "dataset:\n",
      "  data_name: sbxw_fibrillation_peptide_waltzdb-train-val_serrano-test_randpadded10x\n",
      "  add_data_columns: false\n",
      "  data_columns_dimred: false\n",
      "  data_columns_standard: false\n",
      "  group_column: null\n",
      "  data_scaler: RobustScaler\n",
      "  target_scaling: null\n",
      "  rbf_encoder: RadialBasisFunctionGaussian\n",
      "  rbf_n_kernels: 10\n",
      "  task: classification_binary\n",
      "  use_predefined_split: true\n",
      "  use_sample_weights: false\n",
      "  residue_prediction_labels: null\n",
      "  data_split_column: data_split\n",
      "  data_split:\n",
      "    train: 0.8\n",
      "    val: 0.0\n",
      "    test: 0.2\n",
      "embedder:\n",
      "  class_name: ESM\n",
      "  model_name: esm2_t6_8M_UR50D\n",
      "  model_path: null\n",
      "  standardize: false\n",
      "  scalar_type: StandardScaler\n",
      "  hparams: null\n",
      "  n_copies: 1\n",
      "  chain_break: poly-gly-linker\n",
      "  buffer_scale_factor: 2.0\n",
      "  max_batch_size: 400\n",
      "  simple_batching: false\n",
      "  strict: true\n",
      "  verbose: false\n",
      "  mean_pool: false\n",
      "  output_hidden_states: false\n",
      "dimred:\n",
      "  class_name: NoReduction\n",
      "  transform_name: null\n",
      "  fraction_variance_explained: null\n",
      "predictor:\n",
      "  class_name: LightAttention\n",
      "  model_name: null\n",
      "  model_type: classification_binary\n",
      "  mem_per_job: null\n",
      "  residue_prediction_mode: false\n",
      "  hparams:\n",
      "    kernel_size: 1\n",
      "    dropout: 0.25\n",
      "    conv_dropout: 0.25\n",
      "    learning_rate: 0.0005\n",
      "    batch_size: 1000\n",
      "    max_epochs: 10\n",
      "    patience: 200\n",
      "    post_attention: mlp\n",
      "    conv1d_output_dim: -1\n",
      "    optimal_cutoff: 0.5\n",
      "    reduction_mode: sum\n",
      "persistence:\n",
      "  type: lovelace\n",
      "  data_root_folder: /novo/projects/departments/cdd/molecular_ai/mlbp/data\n",
      "  artifacts_root_folder: /novo/projects/departments/cdd/molecular_ai/mlbp/artifacts\n",
      "  training_data: fibrillation_data\n",
      "  pretrained_weights: static_pretrained_weights\n",
      "mlflow:\n",
      "  tracking_uri: https://datalab.corp.novocorp.net/mlflow/\n",
      "  experiment_name: ML-BP-Domino\n",
      "plots:\n",
      "  generate_plots: false\n",
      "\n",
      "[2025-02-26 00:17:39,741][src.model.dimred][INFO] - Load class (NoReduction): NoReduction\n",
      "[2025-02-26 00:17:39,741][src.model.abstract_components][INFO] - Load class (DimRed Model): NoReduction\n",
      "[2025-02-26 00:17:39,742][src.model.predictors][INFO] - Load class (LightAttention): LightAttention\n",
      "[2025-02-26 00:17:39,742][src.model.abstract_components][INFO] - Load class (TorchPredictorModel): LightAttention\n",
      "[2025-02-26 00:17:39,742][src.model.abstract_components][INFO] - Load class (Predictor Model): LightAttention\n",
      "[2025-02-26 00:17:39,743][src.model.composite_model][INFO] - Composite model name: esm2t68MUR50D_LightAttention_sbxwfibrillationpeptidewaltzdb-train-valserrano-testrandpadded10x\n",
      "[2025-02-26 00:17:39,743][src.model.composite_model][INFO] - Initialized model: esm2t68MUR50D_LightAttention_sbxwfibrillationpeptidewaltzdb-train-valserrano-testrandpadded10x in run_mode = train\n",
      "[2025-02-26 00:17:39,767][src.helpers.dataset][INFO] - Loading file: /novo/projects/departments/cdd/molecular_ai/mlbp/data/fibrillation_data/sbxw_fibrillation_peptide_waltzdb-train-val_serrano-test_randpadded10x.csv\n",
      "[2025-02-26 00:17:39,768][src.helpers.dataset][INFO] - Using group_column \"None\".\n",
      "[2025-02-26 00:17:39,768][src.helpers.dataset][INFO] - No additional data columns found while parsing.\n",
      "[2025-02-26 00:17:39,775][src.helpers.dataset][INFO] - Select data according to predetermined splits in the dataframe, train (N = 11220), validation (N = 2770), test (N = 248)\n",
      "[2025-02-26 00:17:39,775][src.helpers.dataset][INFO] - Loaded columns: {}\n",
      "[2025-02-26 00:17:39,777][src.helpers.mlflow_helpers][INFO] - Setting up MLflow...\n",
      "[2025-02-26 00:17:39,777][src.helpers.mlflow_helpers][INFO] - Experiment name: ML-BP-Domino\n",
      "[2025-02-26 00:17:39,777][src.helpers.mlflow_helpers][INFO] - Setting MLflow tracking URI to https://datalab.corp.novocorp.net/mlflow/\n",
      "[2025-02-26 00:17:41,096][src.helpers.mlflow_helpers][INFO] - Setting MLflow experiment to ML-BP-Domino\n",
      "[2025-02-26 00:17:41,669][__main__][INFO] - <RunInfo: artifact_uri='s3://nnedl-core-prd-eu-central-1-curated/mlops/378/b394553796de4802bf530a4bb0f55e17/artifacts', end_time=None, experiment_id='378', lifecycle_stage='active', run_id='b394553796de4802bf530a4bb0f55e17', run_name='', run_uuid='b394553796de4802bf530a4bb0f55e17', start_time=1740529061424, status='RUNNING', user_id='sbxw'>\n",
      "[2025-02-26 00:17:42,388][__main__][INFO] - Compute embeddings on-the-fly and train model\n",
      "[2025-02-26 00:17:42,390][src.model.abstract_components][INFO] - Load class (LLMEmbedderModel): ESM\n",
      "[2025-02-26 00:17:42,390][src.model.abstract_components][INFO] - Load class (Embedder Model): ESM\n",
      "[2025-02-26 00:17:42,391][src.model.embedders][INFO] - Loading model: esm2_t6_8M_UR50D, will extract embeddings from 6-th layer\n",
      "Some weights of EsmModel were not initialized from the model checkpoint at facebook/esm2_t6_8M_UR50D and are newly initialized: ['esm.pooler.dense.bias', 'esm.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "[2025-02-26 00:17:43,574][src.model.embedders][INFO] - Moving model to cuda\n",
      "[2025-02-26 00:17:44,021][src.model.abstract_components][INFO] - Total memory: 23.58378496GB\n",
      "Memory already allocated: 0.031387648GB\n",
      "[2025-02-26 00:17:46,333][src.model.embedders][INFO] - Per-residue embeddings count: 11220\n",
      "[2025-02-26 00:17:46,333][src.model.composite_model][INFO] - Residue embeddings\n",
      "[2025-02-26 00:17:46,335][src.model.abstract_components][INFO] - Total memory: 23.58378496GB\n",
      "Memory already allocated: 0.039919616GB\n",
      "[2025-02-26 00:17:46,823][src.model.embedders][INFO] - Per-residue embeddings count: 2770\n",
      "[2025-02-26 00:17:46,823][src.model.scalers][INFO] - Fitted scaler: PassThroughScaler\n",
      "[2025-02-26 00:17:46,823][src.model.scalers][INFO] - Before standardization - min: 0.0, max: 1.0\n",
      "[2025-02-26 00:17:46,823][src.model.scalers][INFO] - After standardization - min: 0.0, max: 1.0\n",
      "[2025-02-26 00:17:46,823][src.model.scalers][INFO] - Before standardization - min: 0.0, max: 1.0\n",
      "[2025-02-26 00:17:46,824][src.model.scalers][INFO] - After standardization - min: 0.0, max: 1.0\n",
      "[2025-02-26 00:17:46,824][src.model.scalers][INFO] - Before standardization - min: 0.0, max: 1.0\n",
      "[2025-02-26 00:17:46,824][src.model.scalers][INFO] - After standardization - min: 0.0, max: 1.0\n",
      "/nfs_home/users/sbxw/mambaforge/envs/mlbp/lib/python3.10/site-packages/lightning/fabric/plugins/environments/slurm.py:204: The `srun` command is available on your system but is not used. HINT: If your intention is to run Lightning on SLURM, prepend your python command with `srun` like so: srun python /novo/projects/departments/cdd/molecular_ai/sbxw/rep ...\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/nfs_home/users/sbxw/mambaforge/envs/mlbp/lib/python3.10/site-packages/lightning/fabric/plugins/environments/slurm.py:204: The `srun` command is available on your system but is not used. HINT: If your intention is to run Lightning on SLURM, prepend your python command with `srun` like so: srun python /novo/projects/departments/cdd/molecular_ai/sbxw/rep ...\n",
      "[2025-02-26 00:17:48,306][pytorch_lightning.utilities.rank_zero][INFO] - You are using a CUDA device ('NVIDIA L4') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name                  | Type       | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | feature_convolution   | Conv1d     | 102 K  | train\n",
      "1 | attention_convolution | Conv1d     | 102 K  | train\n",
      "2 | softmax               | Softmax    | 0      | train\n",
      "3 | dropout               | Dropout    | 0      | train\n",
      "4 | sigmoid               | Sigmoid    | 0      | train\n",
      "5 | mlp                   | Sequential | 10.4 K | train\n",
      "6 | loss_fxn              | BCELoss    | 0      | train\n",
      "-------------------------------------------------------------\n",
      "215 K     Trainable params\n",
      "0         Non-trainable params\n",
      "215 K     Total params\n",
      "0.863     Total estimated model params size (MB)\n",
      "12        Modules in train mode\n",
      "0         Modules in eval mode\n",
      "/nfs_home/users/sbxw/mambaforge/envs/mlbp/lib/python3.10/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:424: The 'val_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=7` in the `DataLoader` to improve performance.\n",
      "/nfs_home/users/sbxw/mambaforge/envs/mlbp/lib/python3.10/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:424: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=7` in the `DataLoader` to improve performance.\n",
      "[2025-02-26 00:17:55,809][botocore.credentials][INFO] - Found credentials in environment variables.\n",
      "[2025-02-26 00:19:00,479][pytorch_lightning.utilities.rank_zero][INFO] - `Trainer.fit` stopped: `max_epochs=10` reached.\n",
      "üèÉ View run  at: https://datalab.corp.novocorp.net/mlflow/#/experiments/378/runs/b394553796de4802bf530a4bb0f55e17\n",
      "üß™ View experiment at: https://datalab.corp.novocorp.net/mlflow/#/experiments/378\n",
      "\u001b[31m2025/02/26 00:19:28 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\u001b[0m\n",
      "[2025-02-26 00:19:45,197][src.model.abstract_components][INFO] - MODEL STOPPED BY EARLY STOPPER AT EPOCH 0\n",
      "[2025-02-26 00:19:45,198][src.model.abstract_components][INFO] - BEST MODEL VALIDATION LOSS IS 0.5372622013092041\n",
      "[2025-02-26 00:19:45,198][src.model.abstract_components][INFO] - BEST MODEL SAVED AT /novo/projects/departments/cdd/public/users/ehec/sbxw_files_2/378/b394553796de4802bf530a4bb0f55e17/checkpoints/epoch=9-step=120.ckpt\n",
      "[2025-02-26 00:19:45,198][src.model.abstract_components][INFO] - FINAL MODEL SAVED AT None\n",
      "[2025-02-26 00:19:45,524][src.model.predictors][INFO] - Moving embeddings to device: cuda\n",
      "[2025-02-26 00:19:45,802][src.model.predictors][INFO] - Optimal cutoff is: 0.38 with MCC: 0.43069412261721546\n",
      "[2025-02-26 00:19:45,935][src.model.predictors][INFO] - Moving embeddings to device: cuda\n",
      "[2025-02-26 00:19:46,076][src.model.predictors][INFO] - Moving embeddings to device: cuda\n",
      "[2025-02-26 00:19:46,103][src.model.scalers][INFO] - Before standardization - min: False, max: True\n",
      "[2025-02-26 00:19:46,103][src.model.scalers][INFO] - After standardization - min: False, max: True\n",
      "[2025-02-26 00:19:46,103][src.model.scalers][INFO] - Before standardization - min: False, max: True\n",
      "[2025-02-26 00:19:46,103][src.model.scalers][INFO] - After standardization - min: False, max: True\n",
      "[2025-02-26 00:19:46,104][src.model.composite_model][INFO] - This is the updated predictor name: lightattention_kernel_size_1_dropout_0.25_conv_dropout_0.25_learning_rate_0.0005_batch_size_1000_max_epochs_10_patience_200_post_attention_mlp_conv1d_output_dim_-1_optimal_cutoff_0.38_reduction_mode_sum\n",
      "[2025-02-26 00:19:46,104][src.model.composite_model][INFO] - Composite model name: esm2t68MUR50D_LightAttention_sbxwfibrillationpeptidewaltzdb-train-valserrano-testrandpadded10x\n",
      "[2025-02-26 00:19:46,104][src.model.composite_model][INFO] - Best model is: kernel_size_1_dropout_0.25_conv_dropout_0.25_learning_rate_0.0005_batch_size_1000_max_epochs_10_patience_200_post_attention_mlp_conv1d_output_dim_-1_optimal_cutoff_0.38_reduction_mode_sum\n",
      "[2025-02-26 00:19:46,104][src.model.composite_model][INFO] - Moving to test mode\n",
      "[2025-02-26 00:19:46,105][src.model.composite_model][INFO] - Composite model name: esm2t68MUR50D_LightAttention_sbxwfibrillationpeptidewaltzdb-train-valserrano-testrandpadded10x\n",
      "[2025-02-26 00:19:46,105][src.model.composite_model][INFO] - Saving model: esm2t68MUR50D_LightAttention_sbxwfibrillationpeptidewaltzdb-train-valserrano-testrandpadded10x\n",
      "<RunInfo: artifact_uri='s3://nnedl-core-prd-eu-central-1-curated/mlops/378/b394553796de4802bf530a4bb0f55e17/artifacts', end_time=None, experiment_id='378', lifecycle_stage='active', run_id='b394553796de4802bf530a4bb0f55e17', run_name='', run_uuid='b394553796de4802bf530a4bb0f55e17', start_time=1740529061424, status='RUNNING', user_id='sbxw'>\n",
      "[2025-02-26 00:20:18,552][src.model.abstract_components][INFO] - Total memory: 23.58378496GB\n",
      "Memory already allocated: 0.395062784GB\n",
      "[2025-02-26 00:20:18,633][src.model.embedders][INFO] - Per-residue embeddings count: 248\n",
      "[2025-02-26 00:20:18,633][src.model.composite_model][INFO] - Residue embeddings\n",
      "[2025-02-26 00:20:18,636][src.model.predictors][INFO] - Moving embeddings to device: cuda\n",
      "[2025-02-26 00:20:18,640][src.model.scalers][INFO] - Before standardization - min: False, max: True\n",
      "[2025-02-26 00:20:18,641][src.model.scalers][INFO] - After standardization - min: False, max: True\n",
      "sequences: (11220,)\n",
      "sequence_embeddings: 11220\n",
      "predictions: (11220,)\n",
      "predictions_scaled: (11220,)\n",
      "data_split: train\n",
      "labels: (11220,)\n",
      "predictions_probability: (11220,)\n",
      "residue_level_prediction: False\n",
      "sequences: (2770,)\n",
      "sequence_embeddings: 2770\n",
      "predictions: (2770,)\n",
      "predictions_scaled: (2770,)\n",
      "data_split: val\n",
      "labels: (2770,)\n",
      "predictions_probability: (2770,)\n",
      "residue_level_prediction: False\n",
      "sequences: (248,)\n",
      "sequence_embeddings: 248\n",
      "predictions: (248,)\n",
      "predictions_scaled: (248,)\n",
      "data_split: test\n",
      "labels: (248,)\n",
      "predictions_probability: (248,)\n",
      "residue_level_prediction: False\n",
      "[2025-02-26 00:20:20,193][src.model.composite_model][INFO] - Composite model name: esm2t68MUR50D_LightAttention_sbxwfibrillationpeptidewaltzdb-train-valserrano-testrandpadded10x\n",
      "[2025-02-26 00:20:21,675][__main__][INFO] - Done!\n",
      "run_id: b394553796de4802bf530a4bb0f55e17\n",
      "artifacts: ['model/MLmodel', 'model/checkpoints', 'model/conda.yaml', 'model/data', 'model/python_env.yaml', 'model/requirements.txt']\n",
      "params: {'embeddings_dim': '320', 'output_dim': '1', 'kernel_size': '1', 'dropout': '0.25', 'conv_dropout': '0.25', 'epochs': '10', 'optimizer_name': 'SGD', 'lr': '0.0005', 'momentum': '0', 'dampening': '0', 'weight_decay': '0', 'nesterov': 'False', 'maximize': 'False', 'foreach': 'None', 'differentiable': 'False', 'fused': 'None', 'persistence.training_data': 'fibrillation_data', 'persistence.pretrained_weights': 'static_pretrained_weights', 'mlflow.tracking_uri': 'https://datalab.corp.novocorp.net/mlflow/', 'mlflow.experiment_name': 'ML-BP-Domino', 'plots.generate_plots': 'False', 'model_type': 'classification_binary', 'learning_rate': '0.0005', 'post_attention': 'mlp', 'conv1d_output_dim': '-1', 'residue_prediction_mode': 'False', 'reduction_mode': 'sum', 'general.run_mode': 'train', 'general.abs_repo_path': 'None', 'general.composite_model_name': 'esm2t68MUR50D_LightAttention_sbxwfibrillationpeptidewaltzdb-train-valserrano-testrandpadded10x', 'general.composite_model_path': 'None', 'general.precomputed_embeddings_path': 'None', 'general.random_state': '42', 'dataset.data_name': 'sbxw_fibrillation_peptide_waltzdb-train-val_serrano-test_randpadded10x', 'dataset.add_data_columns': 'False', 'dataset.data_columns_dimred': 'False', 'dataset.data_columns_standard': 'False', 'dataset.group_column': 'None', 'dataset.data_scaler': 'RobustScaler', 'dataset.target_scaling': 'None', 'dataset.rbf_encoder': 'RadialBasisFunctionGaussian', 'dataset.rbf_n_kernels': '10', 'dataset.task': 'classification_binary', 'dataset.use_predefined_split': 'True', 'dataset.use_sample_weights': 'False', 'dataset.residue_prediction_labels': 'None', 'dataset.data_split_column': 'data_split', 'dataset.data_split.train': '0.8', 'dataset.data_split.val': '0.0', 'dataset.data_split.test': '0.2', 'embedder.class_name': 'ESM', 'embedder.model_name': 'esm2_t6_8M_UR50D', 'embedder.model_path': 'None', 'embedder.standardize': 'False', 'embedder.scalar_type': 'StandardScaler', 'embedder.hparams': 'None', 'embedder.n_copies': '1', 'embedder.chain_break': 'poly-gly-linker', 'embedder.buffer_scale_factor': '2.0', 'embedder.max_batch_size': '400', 'embedder.simple_batching': 'False', 'embedder.strict': 'True', 'embedder.verbose': 'False', 'embedder.mean_pool': 'False', 'embedder.output_hidden_states': 'False', 'dimred.class_name': 'NoReduction', 'dimred.transform_name': 'None', 'dimred.fraction_variance_explained': 'None', 'predictor.class_name': 'LightAttention', 'predictor.model_name': 'None', 'predictor.model_type': 'classification_binary', 'predictor.mem_per_job': 'None', 'predictor.residue_prediction_mode': 'False', 'predictor.hparams.kernel_size': '1', 'predictor.hparams.dropout': '0.25', 'predictor.hparams.conv_dropout': '0.25', 'predictor.hparams.learning_rate': '0.0005', 'predictor.hparams.batch_size': '1000', 'predictor.hparams.max_epochs': '10', 'predictor.hparams.patience': '200', 'predictor.hparams.post_attention': 'mlp', 'predictor.hparams.conv1d_output_dim': '-1', 'predictor.hparams.optimal_cutoff': '0.5', 'predictor.hparams.reduction_mode': 'sum', 'persistence.type': 'lovelace', 'persistence.data_root_folder': '/novo/projects/departments/cdd/molecular_ai/mlbp/data', 'persistence.artifacts_root_folder': '/novo/projects/departments/cdd/molecular_ai/mlbp/artifacts'}\n",
      "metrics: {'val.loss': 0.5372622013092041, 'train.loss': 0.6569092869758606, 'test.accuracy': 0.5, 'test.precision': 0.3787878787878788, 'test.recall': 0.9868421052631579, 'test.specificity': 0.28488372093023256, 'test.f_score': 0.5474452554744526, 'test.matthews_corr_coef': 0.31223698178116316, 'test.optimal_mcc': 0.43848772111085343, 'test.optimal_mcc_cutoff': 0.51, 'test.balanced_accuracy': 0.6358629130966952, 'train.loss_epoch': 0.6569092869758606, 'epoch': 9.0, 'test.roc_auc_score': 0.7693925948592412, 'train.accuracy': 0.7027629233511586, 'train.precision': 0.5683466617072717, 'train.recall': 0.7508599508599508, 'train.specificity': 0.6753846153846154, 'train.f_score': 0.646977876574574, 'train.matthews_corr_coef': 0.41022405173409854, 'train.optimal_mcc': 0.4169410630346802, 'train.optimal_mcc_cutoff': 0.34, 'train.balanced_accuracy': 0.7131222831222831, 'train.roc_auc_score': 0.7731085204721568, 'val.accuracy': 0.7115523465703971, 'val.precision': 0.575168287210172, 'val.recall': 0.769, 'val.specificity': 0.6790960451977401, 'val.f_score': 0.6581086863500214, 'val.matthews_corr_coef': 0.43069412261721546, 'val.optimal_mcc': 0.43069412261721546, 'val.optimal_mcc_cutoff': 0.38, 'val.balanced_accuracy': 0.7240480225988701, 'val.roc_auc_score': 0.7800437853107345, 'train.loss_step': 0.6847636103630066, 'val_loss': 0.5693650245666504}\n",
      "tags: {'Mode': 'training'}\n",
      "results stored in /novo/projects/departments/cdd/molecular_ai/mlbp/artifacts/2025-02-26-0017_b394553796de4802bf530a4bb0f55e17/esm2t68MUR50D_LightAttention_sbxwfibrillationpeptidewaltzdb-train-valserrano-testrandpadded10x_stats.csv\n",
      "s3://nnedl-core-prd-eu-central-1-curated/mlops/378/b394553796de4802bf530a4bb0f55e17/artifacts\n",
      "\u001b[34mSystem information\u001b[0m: Linux #70~20.04.1-Ubuntu SMP Fri Jun 14 15:42:13 UTC 2024\n",
      "\u001b[34mPython version\u001b[0m: 3.10.14\n",
      "\u001b[34mMLflow version\u001b[0m: 2.20.2\n",
      "\u001b[34mMLflow module location\u001b[0m: /nfs_home/users/sbxw/mambaforge/envs/mlbp/lib/python3.10/site-packages/mlflow/__init__.py\n",
      "\u001b[34mTracking URI\u001b[0m: https://datalab.corp.novocorp.net/mlflow/\n",
      "\u001b[34mRegistry URI\u001b[0m: https://datalab.corp.novocorp.net/mlflow/\n",
      "\u001b[34mActive experiment ID\u001b[0m: 378\n",
      "\u001b[34mActive run ID\u001b[0m: b394553796de4802bf530a4bb0f55e17\n",
      "\u001b[34mActive run artifact URI\u001b[0m: s3://nnedl-core-prd-eu-central-1-curated/mlops/378/b394553796de4802bf530a4bb0f55e17/artifacts\n",
      "\u001b[34mMLflow environment variables\u001b[0m: \n",
      "  MLFLOW_EXPERIMENT_ID: 378\n",
      "  MLFLOW_TRACKING_URI: https://datalab.corp.novocorp.net/mlflow/\n",
      "\u001b[34mMLflow dependencies\u001b[0m: \n",
      "  Flask: 2.2.5\n",
      "  Jinja2: 3.1.4\n",
      "  aiohttp: 3.9.5\n",
      "  alembic: 1.13.1\n",
      "  boto3: 1.36.23\n",
      "  botocore: 1.36.23\n",
      "  docker: 7.0.0\n",
      "  graphene: 3.3\n",
      "  gunicorn: 22.0.0\n",
      "  markdown: 3.6\n",
      "  matplotlib: 3.9.0\n",
      "  mlflow-skinny: 2.20.2\n",
      "  numpy: 1.26.4\n",
      "  pandas: 2.2.2\n",
      "  pyarrow: 15.0.2\n",
      "  scikit-learn: 1.4.2\n",
      "  scipy: 1.13.0\n",
      "  sqlalchemy: 2.0.30\n",
      "  virtualenv: 20.26.2\n",
      "None\n",
      "üèÉ View run  at: https://datalab.corp.novocorp.net/mlflow/#/experiments/378/runs/b394553796de4802bf530a4bb0f55e17\n",
      "üß™ View experiment at: https://datalab.corp.novocorp.net/mlflow/#/experiments/378\n"
     ]
    }
   ],
   "source": [
    "%env AWS_ACCESS_KEY_ID=ASIATIJCHR3KPDQBE3ZK\n",
    "%env AWS_SECRET_ACCESS_KEY=g5uRXxNkC+F4wcsxo8pGzFLKq7d03Dy/81a6Dypa\n",
    "%env AWS_SESSION_TOKEN=FwoGZXIvYXdzECkaDFQAQqAzDjzkjIikWiL0A1lDrO09XvK1CDnfVAbQlHyFOQi0YEW8t20xe9bDVTv63riG0RyaENE819V+Ep5zF703rUFu8q6jzow4AvHSXM5upyiXZgs3+MiO4sFbzs/TmFLq0t2qGXZerGVbHqFzGtHtZAaoU0zy3jxmCKu6YCb1tzBVPVhSAamN3L3wo997OvZqDwb0M+soWFDAI/9ZoPb02dZK/gsrEfc8BRmPnurze6HkW4OVHFFZXnWjMBmdl4gRw1c1AuYmjT21ajeTRTmdGSFfQ0GdP9PlV8HC7zr8E28aADZAHdLsLp7slN6FDqnGFF5y4TqPrrAmij8ZFYOqoUBPEf+qxtff9mnfxVFOSmF/E4B7Xczf0Uhd300X57Vi/aB6XmPr5vkgGbjNhpaUf40PG7rhJ4sDSV5gJhqlPGT1u3B4hyI60t2Wzzv+iTovF8btjRm/GND5NPRo4LUfS2J2mfyqZ8HbX+gbgHw6FsW28POBv1loT/2VRhzLoBZ71L5CB4sS6vhfbXwySffV3Ev/Eply1T2MYEkQGMpA6vCnT6SnWWGxFd+oR94dKlpmMZThWYfCVNJtI3qu8a9iwfT/w7AQanSCHIY1I6+RYCUa+BDcOedygc3AS8DS3QW4jtK2jshqIkJEMu2nF2twhCbz0lAlBirBPMA6XihUcQMvKIGt+b0GMpQBT6lr0cifUVvnV6L9/CGMkJIbwks6PztNkVnsDjU0nzcvTzOYrTFLSR4nVI/4mHw8rSzhs1OQfqJVGIgqZ642ZxfuUsu7VLG2HokUzAAlje+bdnLtc6SoJJDloPLfnkjajTCzM1al2qlwAgy5OhLf+WAzqderIfbVqnHCDebFGnR1sLJEICRVCJyi/2n8pbTJaXmD1Q==\n",
    "\n",
    "repo_dir = '/novo/projects/departments/cdd/molecular_ai/sbxw/repos/ML-BP-Domino'\n",
    "conda_env_name = 'mlbp'\n",
    "\n",
    "# Create command (single set of params)\n",
    "cmd = [\n",
    "    f\"/nfs_home/users/sbxw/mambaforge/condabin/conda run --no-capture-output -n {conda_env_name} python\",\n",
    "    f\"{repo_dir}/src/cli/training.py\",\n",
    "    \"mlflow=datalab\", \"persistence=lovelace\", \"persistence.training_data=fibrillation_data\",\n",
    "    \"dataset.use_predefined_split=true\",\n",
    "    \"dataset.data_name=sbxw_fibrillation_peptide_waltzdb-train-val_serrano-test_randpadded10x\", \"dataset.task=classification_binary\", \n",
    "    \"embedder=esm2_t6_8M\",\"embedder.mean_pool=false\",\n",
    "    \"dimred=noreduction\",\n",
    "    \"predictor=lightattention\",\n",
    "    \"predictor.hparams.kernel_size=1\", \"predictor.hparams.max_epochs=10\", \"predictor.hparams.patience=200\",\n",
    "    \"predictor.hparams.batch_size=1000\", \"predictor.hparams.learning_rate=0.0005\",\n",
    "    \"predictor.hparams.reduction_mode=sum\",\n",
    "    \"mlflow.experiment_name=ML-BP-Domino\",\n",
    "    \"plots.generate_plots=false\",\n",
    "]\n",
    "\n",
    "command_str = \" \".join(cmd)\n",
    "print(command_str)\n",
    "!$command_str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cbe830f-e653-4eba-899c-182b7e734ef1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mlbp",
   "language": "python",
   "name": "mlbp"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
